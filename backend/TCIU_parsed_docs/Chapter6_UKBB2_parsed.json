{
  "metadata": {
    "created_at": "2025-05-15T17:01:01.399637",
    "total_sections": 2,
    "total_code_chunks": 4,
    "total_tables": 1,
    "r_libraries": [
      "EBImage",
      "caret",
      "doParallel",
      "foreach",
      "mi",
      "mice",
      "plotly",
      "randomForest",
      "rattle",
      "rpart"
    ]
  },
  "sections": [
    {
      "title": "Main",
      "content": "---\ntitle: \"Spacekime Analytics (Time Complexity and Inferential Uncertainty)\"\nsubtitle: \"Structured Big Data Analytics Case-Study (UKBB)\"\nauthor: \"SOCR Team \"\ndate: \"`r format(Sys.time(),'%m/%d/%Y')`\"\noutput: \n  html_document:\n    theme: spacelab\n    highlight: tango\n    includes:\n      before_body: TCIU_header.html\n    toc: true\n    number_sections: true\n    toc_depth: 2\n    toc_float:\n      collapsed: false\n      smooth_scroll: true",
      "word_count": 43
    },
    {
      "title": "Structured Big Data Analytics Case-Study",
      "content": "Next, we will look at another interesting example of a large structured tabular dataset. The goal remains the same - examine the effects of indexing complex data only using kime-order (time) and comparing the data representations as well as the subsequent data analytics. In this case-study, we will use the [UK Biobank (UKBB) data](https://www.ukbiobank.ac.uk/data-showcase).\n\nA previous investigation [Predictive Big Data Analytics using the UK Biobank Data](https://doi.org/10.1038/s41598-019-41634-y), based on $7,614$ imaging, clinical, and phenotypic features and neuroimaging data of $9,914$ UKBB subjects reported the twenty most salient derived imaging biomarkers. By jointly representing and modeling the significant clinical and demographic variables along with specific salient neuroimaging features, the researchers predicted the presence and progression of depression and mental health of participating volunteers. We will explore the effects of kime-direction on the findings based on the same data and methods. For ease of demonstration, efficient calculations, and direct interpretation, we start by transforming the data into a tighter computable object of dimensions $9,914\\times 107$.\n\n\nWe can investigate the effects of the *kime-phase* on the resulting data analytic inference obtained using the UKBB data.\n\n\nAs we have the benefit of hind-side, the prior study [Predictive Big Data Analytics using the UK Biobank Data](https://doi.org/10.1038/s41598-019-41634-y) had identified the most salient derived neuroimaging and clinical biomarkers ($k=107$) in this study, including the physician identified clinical outcomes and the computed phenotypes using unsupervised machine learning methods. Therefore, for simplicity, this demonstration only focuses on these features, without a previous feature-selection preprocessing step. We are examining the effects of the kime phase on the scientific inference.\n\nNote that averaging the phases in the Fourier domain assumes that either we have a very large number of samples that effectively span the range of kime-angles, or that the sampling is uniform on the kime-angles space. When these assumptions are violated, other phase-aggregation or phase-ensembling methods (e.g., weighted mean, non-parametric measures of centrality, or Bayesian strategies) may need to utilized to ensure the reliability of the final inference.\n\n\n\n<!--html_preserve-->\n<div>\n    \t<footer><center>\n\t\t\t<a href=\"https://www.socr.umich.edu/\">SOCR Resource</a>\n\t\t\t\tVisitor number <img class=\"statcounter\" src=\"https://c.statcounter.com/5714596/0/038e9ac4/0/\" alt=\"Web Analytics\" align=\"middle\" border=\"0\">\n\t\t\t\t<script type=\"text/javascript\">\n\t\t\t\t\tvar d = new Date();\n\t\t\t\t\tdocument.write(\" | \" + d.getFullYear() + \" | \");\n\t\t\t\t</script> \n\t\t\t\t<a href=\"https://socr.umich.edu/img/SOCR_Email.png\"><img alt=\"SOCR Email\"\n\t \t\t\ttitle=\"SOCR Email\" src=\"https://socr.umich.edu/img/SOCR_Email.png\"\n\t \t\t\tstyle=\"border: 0px solid ;\"></a>\n\t \t\t </center>\n\t \t</footer>\n\n\t<!-- Start of StatCounter Code -->\n\t\t<script type=\"text/javascript\">\n\t\t\tvar sc_project=5714596; \n\t\t\tvar sc_invisible=1; \n\t\t\tvar sc_partition=71; \n\t\t\tvar sc_click_stat=1; \n\t\t\tvar sc_security=\"038e9ac4\"; \n\t\t</script>\n\t\t\n\t\t<script type=\"text/javascript\" src=\"https://www.statcounter.com/counter/counter.js\"></script>\n\t<!-- End of StatCounter Code -->\n\t\n\t<!-- GoogleAnalytics -->\n\t\t<script src=\"https://www.google-analytics.com/urchin.js\" type=\"text/javascript\"> </script>\n\t\t<script type=\"text/javascript\"> _uacct = \"UA-676559-1\"; urchinTracker(); </script>\n\t<!-- End of GoogleAnalytics Code -->\n</div>\n<!--/html_preserve-->",
      "word_count": 422
    }
  ],
  "tables": [
    {
      "section": "Main",
      "content": "    code_folding: hide\n---",
      "row_count": 2
    }
  ],
  "r_code": [
    {
      "section": "Main",
      "code": "knitr::opts_chunk$set(echo = TRUE, warings = FALSE)",
      "line_count": 1
    },
    {
      "section": "Main",
      "code": "\n# Get this figure: fig <- get_figure(\"MattSundquist\", 4064)\n# Get this figure's data: data <- get_figure(\"MattSundquist\", 4064)$data\n# Add data to this figure: p <- add_trace(p, x=c(4, 5), y=c(4, 5), kwargs=list(filename=\"Klein bottle\", fileopt=\"extend\"))\n# Get y data of first trace: y1 <- get_figure(\"MattSundquist\", 4064)$data[[1]]$y\n\nlibrary(plotly)",
      "line_count": 7
    },
    {
      "section": "Structured Big Data Analytics Case-Study",
      "code": "UKBB_data <- get(load(\"E:/Ivo.dir/Research/UMichigan/Publications_Books/2019/DataScience_Book_Value_Uncertainty_Kime_2019/other/UKBB_data_cluster_label.Rdata\")) \n# str(UKBB_data)\nUKBB_Colnames <- colnames(UKBB_data); View(UKBB_Colnames); dim(UKBB_data)   # 9914 7615\n\n# Extract the top-50 derived NI biomarkers (data_summary_cluster_2.xlsx), per\n# https://drive.google.com/drive/folders/1SdAtefp_taabNL70JvwJZSexTkzXiEKD \ntop50_NI_Biomarkers <- c(\"lh_BA_exvivo_area__lh_WhiteSurfArea_area\", \"rh_BA_exvivo_area__rh_WhiteSurfArea_area\", \"rh_aparc.a2009s_area__rh_WhiteSurfArea_area\", \"rh_aparc_area__rh_WhiteSurfArea_area\", \"lh_aparc_area__lh_WhiteSurfArea_area\", \"lh_aparc.a2009s_area__lh_WhiteSurfArea_area\", \"aseg__SupraTentorialVol\", \"aseg__SupraTentorialVolNotVent\", \"aseg__SupraTentorialVolNotVentVox\", \"aseg__BrainSegVol\", \"aseg__BrainSegVolNotVentSurf\", \"aseg__BrainSegVolNotVent\", \"aseg__CortexVol\", \"aseg__rhCortexVol\", \"aseg__lhCortexVol\", \"aseg__TotalGrayVol\", \"aseg__MaskVol\", \"rh_aparc.DKTatlas_area__rh_superiortemporal_area\", \"rh_aparc.DKTatlas_area__rh_superiorfrontal_area\", \"lh_aparc.DKTatlas_area__lh_superiorfrontal_area\", \"lh_aparc.DKTatlas_area__lh_lateralorbitofrontal_area\", \"lh_aparc.DKTatlas_area__lh_superiortemporal_area\", \"aseg__EstimatedTotalIntraCranialVol\", \"lh_aparc_area__lh_lateralorbitofrontal_area\", \"rh_aparc.DKTatlas_area__rh_lateralorbitofrontal_area\", \"lh_aparc_area__lh_superiorfrontal_area\", \"rh_aparc_area__rh_superiortemporal_area\", \"rh_aparc.a2009s_area__rh_G.S_cingul.Ant_area\", \"rh_aparc_area__rh_superiorfrontal_area\", \"lh_aparc_area__lh_rostralmiddlefrontal_area\", \"wmparc__wm.lh.lateralorbitofrontal\", \"wmparc__wm.lh.insula\", \"rh_aparc_area__rh_medialorbitofrontal_area\", \"lh_BA_exvivo_area__lh_BA3b_exvivo_area\", \"lh_aparc.DKTatlas_area__lh_postcentral_area\", \"lh_aparc.DKTatlas_volume__lh_lateralorbitofrontal_volume\", \"lh_aparc.DKTatlas_area__lh_insula_area\", \"aseg__SubCortGrayVol\", \"lh_aparc.a2009s_area__lh_G_orbital_area\", \"lh_aparc_area__lh_superiortemporal_area\", \"rh_aparc.DKTatlas_area__rh_insula_area\", \"lh_aparc.DKTatlas_area__lh_precentral_area\", \"lh_aparc.pial_area__lh_lateralorbitofrontal_area\", \"lh_aparc.DKTatlas_area__lh_rostralmiddlefrontal_area\", \"lh_aparc_area__lh_postcentral_area\", \"lh_aparc.pial_area__lh_superiorfrontal_area\", \"rh_aparc_area__rh_rostralmiddlefrontal_area\", \"wmparc__wm.lh.superiortemporal\", \"lh_aparc.pial_area__lh_rostralmiddlefrontal_area\", \"rh_aparc.DKTatlas_volume__rh_lateralorbitofrontal_volume\")\n\n# Extract the main clinical features (binary/dichotomous and categorical/polytomous)\n#### binary\ntop25_BinaryClinical_Biomarkers <- c(\"X1200.0.0\", \"X1200.2.0\", \"X1170.0.0\", \"X1190.2.0\", \"X1170.2.0\", \"X2080.0.0\", \"X6138.2.2\", \"X20117.0.0\", \"X6138.0.2\", \"X2877.0.0\", \"X20117.2.0\", \"X2877.2.0\", \"X1190.0.0\", \"X4968.2.0\", \"X1249.2.0\", \"X1190.1.0\", \"X1170.1.0\", \"X2080.2.0\", \"X4292.2.0\", \"X2050.0.0\", \"X1628.0.0\", \"X1200.1.0\", \"X20018.2.0\", \"X4292.0.0\", \"X3446.0.0\")\n#### polytomous\ntop31_PolytomousClinical_Biomarkers <- c(\"X31.0.0\", \"X22001.0.0\", \"X1950.0.0\", \"X1950.2.0\", \"X1980.0.0\", \"X2040.2.0\", \"X1980.2.0\", \"X2030.0.0\", \"X2090.0.0\", \"X2040.0.0\", \"X1618.2.0\", \"X1618.0.0\", \"X1210.0.0\", \"X2030.2.0\", \"X2000.0.0\", \"X1930.0.0\", \"X2090.2.0\", \"X2000.2.0\", \"X1210.2.0\", \"X1618.1.0\", \"X4653.2.0\", \"X1970.2.0\", \"X1970.0.0\", \"X1980.1.0\", \"X1930.2.0\", \"X4598.2.0\", \"X4598.0.0\", \"X4653.0.0\", \"X2090.1.0\", \"X2040.1.0\", \"X4631.2.0\")\n\n# Extract derived computed phenotype \nderivedComputedPhenotype <- UKBB_Colnames[length(UKBB_Colnames)]\n\n# Construct the Computable data object including all salient predictors and derived cluster phenotype\nColNameList <- c(top50_NI_Biomarkers, top25_BinaryClinical_Biomarkers, \n                     top31_PolytomousClinical_Biomarkers, derivedComputedPhenotype); length(ColNameList)\ncol.index <- which(colnames(UKBB_data) %in% ColNameList); length(col.index)\ntight107_UKBB_data <- UKBB_data[ , col.index]; dim(tight107_UKBB_data)\n## View(tight107_UKBB_data[1:10, ])   # Confirm the tight data object organization ",
      "line_count": 23
    },
    {
      "section": "Structured Big Data Analytics Case-Study",
      "code": "library(caret)\n################################\n#  1. First deal with the missing values  # summary(tight107_UKBB_data)\n##### \"mi\" imputation - LONG\n#library(mi) # use pmm (predictive mean matching) imputation method for the missing variables.\n#mdf <- missing_data.frame(tight107_UKBB_data)\n#show(mdf)   # ; head(mdf); dim(mdf)\n#options(mc.cores = 4)\n#imputations <- mi(mdf, n.iter=4, n.chains=1, verbose=T)\n#imp.data.frames <- complete(imputations, 1)\n#imp_tight107_UKBB_data <- imp.data.frames[[1]]\n\n# split-off the computed phenotype (avoid manipulationg hte outcome that will be predicted during analysis phase\ncolnames(tight107_UKBB_data)[length(tight107_UKBB_data)] <- \"cluster_2_cluster\"\ncolnames(tight107_UKBB_data)[length(tight107_UKBB_data)]   # fix the problem with $ in variable name\ny_pheno  <- tight107_UKBB_data[ , length(tight107_UKBB_data)]\ntight106_UKBB_data <- tight107_UKBB_data[, -length(tight107_UKBB_data)]; dim(tight106_UKBB_data)\n\n# MICE imputation (With parallel core computing)\n# all predictors with absolute correlation over 0.4 AND at least 30% usable cases\nlibrary(mice)\nlibrary(foreach)\nlibrary(doParallel)\n# set-up local parallel cluster\nnumber_cores <- detectCores() - 2\nclustUKBB <- makeCluster(number_cores)\nclusterSetRNGStream(clustUKBB, 1234)\nregisterDoParallel(clustUKBB)\n\nimp_tight106_UKBB_data <-\n  foreach(no = 1:number_cores, \n          .combine = ibind, \n          .export = \"tight106_UKBB_data\",\n          .packages = \"mice\") %dopar%\n{\n  mice(tight106_UKBB_data, m=2,maxit=3, printFlag=T, seed=1234, method = 'cart')\n}\n\nstr(imp_tight106_UKBB_data)\n\n# save(imp_tight106_UKBB_data, file = \"C:/Users/Dinov/Desktop/imp_tight106_UKBB_data.Rdata\")\n# test <- load(file = \"C:/Users/Dinov/Desktop/imp_tight106_UKBB_data.Rdata\")\n\n# imp_tight106_UKBB_data <- mice(tight106_UKBB_data, m=2,maxit=3, printFlag=T, seed=1234, method = 'cart')\n### MICE NOTE: When the column features have a number of unbalanced factors, these categorical variables are transformed into dummy indicator-variables.\n### There is a high probability that the resulting columns may be linear combinations of one-another. \n### The default MICE imputation methods, linear regression, may not be able to solve the linear matrix equations due to matrix low rank, i.e., matrices may cannot be inverted causing errors like \"system is computationally singular\". RTo solve that problem, we can change the method to \"cart\". \n### Also use seed before/during imputation for reproducible results.\ncomp_imp_tight106_UKBB_data <- as.matrix(complete(imp_tight106_UKBB_data), \n                                         dimnames = list(NULL, colnames(tight106_UKBB_data)))\n\n################################################\n##  2. Split the UKBB into 9 epochs\n# First normalize all 50 derived NI biomarkers *using scale* as the NI biomarkers have vastly different distributions\nfor (i in 1:50) {\n  comp_imp_tight106_UKBB_data[, i] <- scale(comp_imp_tight106_UKBB_data[, i])\n}\n\n# Next configure the 11 epochs\ncomp_imp_tight106_UKBB_data <- comp_imp_tight106_UKBB_data[1:9900, ] # remove the last 14 cases to make the 11 epochs of size 900 observations yeach\nis.matrix(comp_imp_tight106_UKBB_data); dim(comp_imp_tight106_UKBB_data)\ndim(comp_imp_tight106_UKBB_data) <- c(11, 900, dim(comp_imp_tight106_UKBB_data)[2])\ndim(comp_imp_tight106_UKBB_data)\n# double check epoch split worked \n# identical(comp_imp_tight106_UKBB_data[10, 900, 12], as.matrix(complete(imp_tight106_UKBB_data))[10*900, 12])\nepochs_tight106_UKBB_data_1 <- comp_imp_tight106_UKBB_data[1, , ]; dim(epochs_tight106_UKBB_data_1)\n\n# 3. Transform all 9 epochs (Big datasets/signals) to k-space (Fourier domain)\nx1 <- c(1:900)\nFT_epochs_tight106_UKBB <- array(complex(), c(11, 900, dim(comp_imp_tight106_UKBB_data)[3]))\nmag_FT_epochs_tight106_UKBB <- array(complex(), c(11, 900, dim(comp_imp_tight106_UKBB_data)[3]))\nphase_FT_epochs_tight106_UKBB <- array(complex(), c(11, 900, dim(comp_imp_tight106_UKBB_data)[3]))\nfor (i in 1:11) {\n  FT_epochs_tight106_UKBB[i, , ] <- fft(comp_imp_tight106_UKBB_data[i, , ])\n  X2 <- FT_epochs_tight106_UKBB[i, , ]\n  # plot(fftshift1D(log(Re(X2)+2)), main = \"log(fftshift1D(Re(FFT(tight106_UKBB))))\") \n  mag_FT_epochs_tight106_UKBB[i, , ] <- sqrt(Re(X2)^2+Im(X2)^2); \n  # plot(log(fftshift1D(Re(X2_mag))), main = \"log(Magnitude(FFT(tight106_UKBB)))\") \n  phase_FT_epochs_tight106_UKBB[i, , ] <- atan2(Im(X2), Re(X2)); \n  # plot(fftshift1D(X2_phase), main = \"Shift(Phase(FFT(tight106_UKBB)))\")\n}\n\n# Compute the Average Phase of all 11 epochs (this will be needed later to confirm better data analytics)\navgPhase_FT_epochs_tight106_UKBB <- apply(phase_FT_epochs_tight106_UKBB, c(2,3), mean)\ndim(avgPhase_FT_epochs_tight106_UKBB)\n\n### Test the process to confirm calculations\n# X2<-FT_epochs_tight106_UKBB[1,,];X2_mag<-mag_FT_epochs_tight106_UKBB[1,,];X2_phase<-phase_FT_epochs_tight106_UKBB[1,,]\n# Real2 = X2_mag * cos(X2_phase)\n# Imaginary2 = X2_mag * sin(X2_phase)\n# man_hat_X2 = Re(fft(Real2 + 1i*Imaginary2, inverse = T)/length(X2))\n# ifelse(abs(man_hat_X2[5,10] - comp_imp_tight106_UKBB_data[1, 5, 10]) < 0.001, \"Perfect Syntesis\", \"Problems!!!\")\n#######\n\n##### 4. Invert back to spacetime the epochs_tight106_UKBB_data_1 signal with NIL and Average phase\n# Start with Nil Phase\nReal = mag_FT_epochs_tight106_UKBB[1, , ] * cos(0)  # cos(mag_FT_epochs_tight106_UKBB[1, , ])\nImaginary = mag_FT_epochs_tight106_UKBB[1, , ] * sin(0)   # sin(mag_FT_epochs_tight106_UKBB[1, , ])\nift_NilPhase_X2mag = Re(fft(Real+1i*Imaginary, inverse = T)/length(mag_FT_epochs_tight106_UKBB[1,,]))\n# display(ift_NilPhase_X2mag, method = \"raster\")\n# dim(ift_NilPhase_X2mag); View(ift_NilPhase_X2mag); # compare to View(comp_imp_tight106_UKBB_data[1, , ])\n\n# Next, synthesize the data using Average Phase\nReal_Avg = mag_FT_epochs_tight106_UKBB[1, , ] * cos(avgPhase_FT_epochs_tight106_UKBB)\nImaginary_Avg = mag_FT_epochs_tight106_UKBB[1, , ] * sin(avgPhase_FT_epochs_tight106_UKBB)\nift_AvgPhase_X2mag = Re(fft(Real_Avg+1i*Imaginary_Avg, inverse = T)/length(mag_FT_epochs_tight106_UKBB[1,,]))\n# is.complex(ift_AvgPhase_X2mag); dim(ift_AvgPhase_X2mag)\n\n# To Transform the entire UKBB data to k-space (Fourier domain)\n# library(EBImage)\n#FT_UKBB_data <- fft(comp_imp_tight106_UKBB_data)\n#X2 <- FT_UKBB_data  # display(FT_UKBB_data, method = \"raster\") \n#mag_FT_UKBB_data <- sqrt(Re(X2)^2+Im(X2)^2) \n###  # plot(log(fftshift1D(Re(X2_mag))), main = \"log(Magnitude(FFT(timeseries)))\") \n#phase_FT_UKBB_data <- atan2(Im(X2), Re(X2)) \n### Test the process to confirm calculations\n# X2<-FT_UKBB_data; X2_mag <- mag_FT_UKBB_data; X2_phase<-phase_FT_UKBB_data\n# Real2 = X2_mag * cos(X2_phase)\n# Imaginary2 = X2_mag * sin(X2_phase)\n# man_hat_X2 = Re(fft(Real2 + 1i*Imaginary2, inverse = T)/length(X2))\n# ifelse(abs(man_hat_X2[5,10] - comp_imp_tight106_UKBB_data[5, 10]) < 0.001, \"Perfect Syntesis\", \"Problems!!!\")\n#######\n# Then we can Invert back the complete UKBB FT data into spacetime using nil phase\n#Real = mag_FT_UKBB_data * cos(0)  # cos(phase_FT_UKBB_data)\n#Imaginary = mag_FT_UKBB_data * sin(0)   # sin(phase_FT_UKBB_data)\n#ift_NilPhase_X2mag = Re(fft(Real+1i*Imaginary, inverse = T)/length(FT_UKBB_data))\n# display(ift_NilPhase_X2mag, method = \"raster\")\n# dim(ift_NilPhase_X2mag); View(ift_NilPhase_X2mag); # compare to View(aqi_data1)\n#summary(comp_imp_tight106_UKBB_data); summary(ift_NilPhase_X2mag)\n\n# 5. Epoch 1: Perform Random Forest prediction (based on ift_TruePhase_X2mag==Original==epochs_tight106_UKBB_data_1) of:\n##### Ever depressed for a whole week 1 #########################################\nlibrary(\"randomForest\")\n# y_pheno <- comp_imp_tight106_UKBB_data[,\"X4598.2.0\"] ### Ever depressed for a whole week 1\n# y_pheno <- as.factor(y_pheno)\ncolnames(epochs_tight106_UKBB_data_1) <- colnames(tight106_UKBB_data)\nset.seed(1234)\nrf_depressed <- randomForest(as.factor(epochs_tight106_UKBB_data_1[ ,\"X4598.2.0\"]) ~ . , \n          data=epochs_tight106_UKBB_data_1[ , !(colnames(epochs_tight106_UKBB_data_1) %in% c(\"X4598.0.0\", \"X4598.2.0\"))])\nrf_depressed\npred1 = predict(rf_depressed, type=\"class\")\nconfusionMatrix(pred1, as.factor(epochs_tight106_UKBB_data_1[ ,\"X4598.2.0\"]))\n############## Accuracy : 0.7911 #############################\n\n##### plot a simple decision tree\nlibrary(rpart); library(rpart.plot)\n## there is an error in installing the rattle package\nlibrary(rattle)  ## this is for the fancyRpartPlot\nlabel <- as.factor(epochs_tight106_UKBB_data_1[ ,\"X4598.2.0\"])\ndata1 <- as.data.frame(epochs_tight106_UKBB_data_1[ , !(colnames(epochs_tight106_UKBB_data_1) %in%\n                      c(\"X4598.0.0\", \"X4598.2.0\", \"cluster_2_cluster\"))])\ndata1$label <- label\ndepress_tree <- rpart(label ~ ., control=rpart.control(minsplit=30, cp=0.001, maxdepth=30), data=data1) \nrpart.plot(depress_tree, type = 4, extra = 1, clip.right.labs = F, tweak=4)\npred1 = predict(depress_tree, type=\"class\")\n# table(pred1, label)\nlibrary(caret)\nconfusionMatrix(pred1, label)\n########################### Accuracy : 0.8511  ##############################\n\n### Prune decision tree\nprune_depress_tree <- prune(depress_tree,\n                            cp=depress_tree$cptable[which.min(depress_tree$cptable[,\"xerror\"]),\"CP\"])\n\n# plot the pruned tree\nplot(prune_depress_tree, uniform=TRUE, main=\"Pruned UKBB Decision Tree\")\ntext(prune_depress_tree, use.n=TRUE, all=TRUE, cex=.8)\nrpart.plot(prune_depress_tree, type = 4, extra = 1, clip.right.labs = F, tweak=2)\npred2 = predict(prune_depress_tree, type=\"class\")\nconfusionMatrix(pred2, label)\n######################### Accuracy : 0.7867 ###############################\n\n\n###### 6. FOR the COMPLETE UKBB data: plot a simple decision tree\n#library(rpart); library(rpart.plot)\n#library(rattle)  ## this is for the fancyRpartPlot\ndim(comp_imp_tight106_UKBB_data) <- c(11*900, dim(comp_imp_tight106_UKBB_data)[3])\ncolnames(comp_imp_tight106_UKBB_data) <- colnames(tight106_UKBB_data)\nlabel3 <- as.factor(comp_imp_tight106_UKBB_data[ ,\"X4598.2.0\"])\ndata3 <- as.data.frame(comp_imp_tight106_UKBB_data[ , !(colnames(comp_imp_tight106_UKBB_data) %in%\n                      c(\"X4598.0.0\", \"X4598.2.0\", \"cluster_2_cluster\"))])\ndepress_tree3 <- rpart(label3 ~ ., control=rpart.control(minsplit=30, cp=0.001, maxdepth=30), data=data3) \nrpart.plot(depress_tree3, type = 4, extra = 1, clip.right.labs = F, tweak=2)\npred3 = predict(depress_tree3, type=\"class\")\nconfusionMatrix(pred3, label3)\n#################### Accuracy : 0.8238 ###########################\n\n### Prune decision tree\nprune_depress_tree3 <- prune(depress_tree3,\n                            cp=depress_tree3$cptable[which.min(depress_tree3$cptable[,\"xerror\"]),\"CP\"])\nrpart.plot(prune_depress_tree3, type = 4, extra = 1, clip.right.labs = F, tweak=2,  main=\"Pruned UKBB Decision Tree\")\npred3 = predict(prune_depress_tree3, type=\"class\")\nconfusionMatrix(pred3, label3)\n#################### Accuracy : 0.8132 ###########################\n\n# RF\nrf_depressed_Complete <- randomForest(label3 ~ . ,  data=data3)\nrf_depressed_Complete\npred3 = predict(rf_depressed_Complete, type=\"class\")\nconfusionMatrix(pred3, label3)\n# In random forests, there is no need for cross-validation or a separate test set to get an unbiased estimate of the test set error. The out-of-bag (oob) error estimate is internally computed during the run... In particular, when newdata is not provided, the *predict.randomForest()==predict()* method automatically returns the out-of-bag prediction.\n##################### Accuracy : 0.808 #########################\n\n\n# 7. Perform Random Forest prediction (based on ift_AvgPhase_X2mag) of:\n##### Ever depressed for a whole week 1 #########################################\n# library(\"randomForest\")\n# y_pheno <- comp_imp_tight106_UKBB_data[,\"X4598.2.0\"] ### Ever depressed for a whole week 1\n# y_pheno <- as.factor(y_pheno)\nlabel2 <- as.factor(epochs_tight106_UKBB_data_1[ ,\"X4598.2.0\"]) \n# use the real outcome not synthesized (as.factor(epochs_tight106_UKBB_data_1[ ,\"X4598.2.0\"]))\ncolnames(ift_AvgPhase_X2mag) <- colnames(tight106_UKBB_data)\ndata2 <- as.data.frame(ift_AvgPhase_X2mag[ , !(colnames(ift_AvgPhase_X2mag) %in%\n                      c(\"X4598.0.0\", \"X4598.2.0\", \"cluster_2_cluster\"))])\nset.seed(1234)\nrf_depressed_AvgPhase <- randomForest(label2 ~ . , importance=T, nodesize=30, mtry=100, ntree= 1000, data=data2)\nrf_depressed_AvgPhase\npred1_AvgPhase <- predict(rf_depressed_AvgPhase, type=\"class\")\nconfusionMatrix(pred1_AvgPhase, label2)\n\n##### plot a simple decision tree\n# library(rpart); library(rpart.plot)\n## there is an error in installing the rattle package\n# library(rattle)  ## this is for the fancyRpartPlot\nset.seed(1234)\ndepress_tree_AvgPhase <- rpart(label2 ~ ., control=rpart.control(minsplit=30,cp=0.001,maxdepth=30),data=data2) \npred1_AvgPhase <- predict(depress_tree_AvgPhase, type=\"class\")\n# library(caret)\nconfusionMatrix(pred1_AvgPhase, label2)\nrpart.plot(depress_tree_AvgPhase, type = 2, extra = 1, clip.right.labs = F, varlen=5, faclen=5, tweak=4)\n################### Accuracy : 0.7956 #############################\n\n### Prune decision tree\nprune_depress_tree_AvgPhase <- prune(depress_tree_AvgPhase,\n        cp=depress_tree_AvgPhase$cptable[which.min(depress_tree_AvgPhase$cptable[,\"xerror\"]),\"CP\"]/(1.5))\n# plot the pruned tree\n#plot(prune_depress_tree_AvgPhase, uniform=TRUE, main=\"Pruned UKBB Decision Tree (Avg-Phase Synthesis)\")\n#text(prune_depress_tree_AvgPhase, use.n=TRUE, all=TRUE, cex=.8)\nrpart.plot(prune_depress_tree_AvgPhase, type = 4, extra = 1, clip.right.labs = F, varlen=5, faclen=5, tweak=1.5)\npred2_AvgPhase = predict(prune_depress_tree_AvgPhase, type=\"class\")\nconfusionMatrix(pred2_AvgPhase, label2)\n\n\n\n# 8. Perform Random Forest prediction (based on ift_NilPhase_X2mag) of:\n##### Ever depressed for a whole week 1 #########################################\n# library(\"randomForest\")\n# y_pheno <- comp_imp_tight106_UKBB_data[,\"X4598.2.0\"] ### Ever depressed for a whole week 1\n# y_pheno <- as.factor(y_pheno)\nlabel2 <- as.factor(epochs_tight106_UKBB_data_1[ ,\"X4598.2.0\"]) \n# use the real outcome not synthesized (as.factor(epochs_tight106_UKBB_data_1[ ,\"X4598.2.0\"]))\ncolnames(ift_NilPhase_X2mag) <- colnames(tight106_UKBB_data)\ndata2 <- as.data.frame(ift_NilPhase_X2mag[ , !(colnames(ift_NilPhase_X2mag) %in%\n                      c(\"X4598.0.0\", \"X4598.2.0\", \"cluster_2_cluster\"))])\nset.seed(1234)\nrf_depressed_NilPhase <- randomForest(label2 ~ . , importance=T, nodesize=30, mtry=100, ntree= 1000, data=data2)\nrf_depressed_NilPhase\npred1_NilPhase <- predict(rf_depressed_NilPhase, type=\"class\")\nconfusionMatrix(pred1_NilPhase, label2)\n\n##### plot a simple decision tree\n# library(rpart); library(rpart.plot)\n## there is an error in installing the rattle package\n# library(rattle)  ## this is for the fancyRpartPlot\nset.seed(1234)\ndepress_tree_NilPhase <- rpart(label2 ~ ., control=rpart.control(minsplit=30,cp=0.001,maxdepth=30),data=data2) \npred1_NilPhase <- predict(depress_tree_NilPhase, type=\"class\")\n# library(caret)\nconfusionMatrix(pred1_NilPhase, label2)\nrpart.plot(depress_tree_NilPhase, type = 2, extra = 1, clip.right.labs = F, varlen=5, faclen=5, tweak=2)\n################### Accuracy : 0.79  #############################\n\n### Prune decision tree\nprune_depress_tree_NilPhase <- prune(depress_tree_NilPhase,\n            cp=depress_tree_NilPhase$cptable[which.min(depress_tree_NilPhase$cptable[,\"xerror\"]),\"CP\"]/(1.5))\n# plot the pruned tree\n#plot(prune_depress_tree_NilPhase, uniform=TRUE, main=\"Pruned UKBB Decision Tree (Nil-Phase Synthesis)\")\n#text(prune_depress_tree_NilPhase, use.n=TRUE, all=TRUE, cex=.8)\nrpart.plot(prune_depress_tree_NilPhase, type = 4, extra = 1, clip.right.labs = F, varlen=5, faclen=5, tweak=2)\npred2_NilPhase = predict(prune_depress_tree_AvgPhase, type=\"class\")\nconfusionMatrix(pred2_NilPhase, label2)\n\n\n# 9. Compare the analytics results from #3, ..., #8!\n# Compare the original against nil-phase and avg-phase synthesized data\norigNilNil_6rows_Compare <- rbind(head(epochs_tight106_UKBB_data_1), head(ift_NilPhase_X2mag), head(ift_AvgPhase_X2mag))\nx1 <- 1:dim(epochs_tight106_UKBB_data_1)[2]\norig.mean <- apply(epochs_tight106_UKBB_data_1, 2, mean)\nnilPhase.mean <- apply(ift_NilPhase_X2mag, 2, mean)\navgPhase.mean <- apply(ift_AvgPhase_X2mag, 2, mean)\n\nplot(x1, orig.mean, main = \"Comparing original UKBB against nil-phase and avg-phase synthesized data\",\n     col=\"green\", lwd = 3, type=\"l\", lty=1, xlab = \"Features\", ylab = \"Averages across cases\")\nlines(x1, nilPhase.mean, col = \"red\", lwd = 3, lty=1)\nlines(x1, avgPhase.mean, col = \"blue\", lwd = 3, lty=1)\nlegend(\"top\", bty=\"n\", legend=c(\n  sprintf(\"Original\"), sprintf(\"Nil-Phase Reconstruction\"), \n  sprintf(\"Average-Phase Reconstruction\")), \n  col=c(\"green\", \"red\", \"blue\"), lty=c(1,1,1), lwd=c(3,3,3), cex=0.9)\n\nstopCluster(clustUKBB)\n\n################### Plot_ly Figure 6.15\ntime <- x1[1:length(orig.mean)]\np <- plot_ly()\np <- add_lines(p, x=~time,  y=~orig.mean, \n               name = \"Original.Mean\", type = 'scatter', mode = 'lines', \n               hoverinfo = 'name', line=list(color='green', width=4))\np <- add_lines(p, x=~time, y=~nilPhase.mean, \n               name = \"ift_NilPhase.Mean\", type = 'scatter', mode = 'lines', \n               hoverinfo = 'name', \n               line=list(color='red', width = 2))\np <- add_lines(p, x=~time, y=~avgPhase.mean, \n               name = \"ift_AvgPhase.Mean\", type = 'scatter', mode = 'lines', \n               hoverinfo = 'name', \n               line=list(color='blue', width = 2)) %>%\n  layout(xaxis = list(range = c(0,108), title=\"Features\"),\n    yaxis = list(range = c(0,6), title=\"Averages across cases\"),\n    title=sprintf('Comparison:  Corr(Real, NilPhase) = %s; Comparison:  Corr(Real, AvgPhase) = %s',\n                  format(cor(orig.mean, nilPhase.mean), digits=3),\n                  format(cor(orig.mean, avgPhase.mean), digits=3)),\n    legend = list(orientation = \"h\",   # show entries horizontally\n                     xanchor = \"center\",  # use center of legend as anchor\n                     x = 0.5, y=-0.1,\n                     size = 30))      \np\n",
      "line_count": 327
    }
  ]
}