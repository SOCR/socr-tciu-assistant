{
  "metadata": {
    "created_at": "2025-05-15T17:01:01.121459",
    "total_sections": 12,
    "total_code_chunks": 7,
    "total_tables": 1,
    "r_libraries": [
      "plotly"
    ]
  },
  "sections": [
    {
      "title": "Main",
      "content": "---\ntitle: \"Spacekime Analytics (Time Complexity and Inferential Uncertainty)\"\nsubtitle: \"Complex-Valued Wavefunctions, Complex-time and Inference Functions\"\nauthor: \"SOCR Team (Yueyang Shen, Milen V. Velev, Ivo D. Dinov)\"\ndate: \"`r format(Sys.time(),'%m/%d/%Y')`\"\noutput:\n  html_document:\n    theme: spacelab\n    highlight: tango\n    includes:\n      before_body: TCIU_header.html\n    toc: yes\n    number_sections: yes\n    toc_depth: 3\n    toc_float:\n      collapsed: no\n      smooth_scroll: yes\n    code_folding: hide\n  word_document:\n    toc: yes\n\nThis [TCIU section](https://http://tciu.predictive.space/) outlines the synergies \nbetween *wavefunctions*, probability *distributions*, probability *densities*, \ncomplex-time *(kime) representations* of repeated-measurement\nspatiotemporal data, and *inference functions*. There is a direct duality between (1) the quantum mechanics interpretation that *measurements collapse wavefunctions*, bringing *quantum* reality into *physical* existence; and (2) the spacekime interpretation that *measurements represent random draws* (samples) from the kime-phase distribution. Just like geodesic curves (generally nonlinear twisted lines) in spacetime represent the shortest paths traversed by light, in a multiverse, 4D hyperplanes foliating the 5D spacekime represent alternative (\"parallel\") curvilinear spacetime projections (rather than continuously branching and bifurcating universes at each time point).",
      "word_count": 156
    },
    {
      "title": "Manifold Foliation",
      "content": "A *foliation* $\\mathcal{F}$ of *dimension* (or *rank*) $r$ of a differentiable manifold\n$M^n$ is a decomposition of $M^n$ into a *disjoint union* of immersed \nsub-manifolds (*leaves* or *plaques*) of dimension $r\\lt n$ that locally and jointly \ncover $M^n$, like fibers of a *submersion.* Symbolically, the *foliation* $\\mathcal{F}$\nis defined by an atlas $\\{\\psi_{\\alpha} : U_{\\alpha}\\to M^n\\},$ such that the *charts* are\n\n$$U_{\\alpha}\\subset \\underbrace{\\mathbb{R}^r}_{leaves}\\times \\underbrace{\\mathbb{R}^{n-r}}_{foliation\\\\ co-dimension\\\\ leaf-parametrization}$$\nand the *differentiable transition functions* are\n\n$$\\psi_{\\alpha}: \\mathbb{R}^n\\longrightarrow {M}^n \\ \\ \\ \n\\psi_{\\alpha}(x,y)\\equiv \\left (f(x,y),g(y)\\right ),\\ \\ \\forall (x,y)\\in \n\\mathbb{R}^r \\times  \\mathbb{R}^{n-r}$$\n\nThe *foliation leaves* are locally given by the fibers of the projection \n$U_i\\to\\mathbb{R}^{n-r}$. When the transition functions $\\psi_{\\alpha}(x,y)\\in C^{\\infty},$\nthe $\\mathcal{F}$ is a $C^{\\infty}$-foliation.\n\nThe simplest foliation example is the [foliation of the complex plane](https://www.ams.org/notices/202207/rnoti-p1137.pdf) where lower-dimensional real lines or non-intersecting curves (*leaves*) are parameterized by a co-dimension $1$ *foliation parameter* (*foils*) $\\left(\\mathbb{C} \\cong \\underbrace{\\mathbb{R}}_{leaves}\\times \\underbrace{\\mathbb{R}}_{foils}\\right)$. Similarly, in aggregate, the infinite set of all lower dimensional *4D Minkowski spacetime leaves* forms a co-dimension $1$ foliation of *5D spacekime.*\n\nThe figure below shows 2D examples of three foliations including:\n\n - A flat *complex plane* $\\mathbb{C}$, a lower-dimensional mock up of the flat 4D Minkowski spacetime, \n - And a pair of curved manifolds, *sphere* ($\\mathbb{S}^2$) and a *torus* ($\\mathbb{T}^2\\cong \\mathbb{R}^2/\\mathbb{Z}^2$), as mock ups of a more realistic 4D spacetime manifold, curved by matter (mass or energy).",
      "word_count": 222
    },
    {
      "title": "Probability Density (Mass) Functions",
      "content": "The relation between *probability density* (or for discrete processes, \n*probability mass*) *functions* and *probability distributions* resemble the\ndichotomy between solid *density* (mass per unit volume) and\n*mass* (integral over the density), which are related by\n\n$$mass= density \\times volume\\ .$$\n\nSuppose the density $\\rho(x,y,z, t):\\mathbb{R}^3\\times \\mathbb{R}^+ \\to \\mathbb{R}^+$ \nis a function of position and time, i.e., the density is spatiotemporally dependent. At a\ngiven time $t_o\\in \\mathbb{R}^+$, a tiny cube (solid volume in $\\mathbb{R}^3$) \nwith sides $dx$, $dy$ and $dz$ will correspond to a volume $dV=dx\\times dy\\times dz$ of *mass*  \n\n$$dm(t_o)=\\rho(x,y,z, t_o)\\times dV \\equiv \\rho(x,y,z, t_o)\\times dx\\times dy\\times dz, \\ \n\\forall\\ t_o \\in \\mathbb{R}^+\\ .$$\n\nTo estimate the total mass for any volume $V$, we integrate the mass against\nthe density over the spatial extent of the volume $V$\n\n$$m(t_o)=\\int_V { \\rho(x,y,z,t_o) dx dy dz} $$\n\nThe relation between *probability density* and *probability* resembles the \nrelation between *density* and *mass.*\nGiven a probability *density*, $p(x,y,z, t):\\mathbb{R}^3\\times \\mathbb{R}^+ \\to \\mathbb{R}^+$\nas the probability per unit 3D solid volume, the *probability*, $P$ of finding \nthe particle in the *tiny solid cube* of size $dx\\times dy\\times dz$ at time $t_o$ is:\n\n$$dP(t_o) =p(x,y,z, t_o) dx dy dz, $$\n\nand in general, the probability of finding the particle in any finite volume $V$\nis also estimated by integrating against the density over the spatial region\n\n$$P(t_o)=\\int_V{ p(x,y,z, t_o) dx dy dz} .$$\n\n**Note**: At any given time $t_o$, the *probability density* is typically estimated \nusing the (complex-valued) *wavefunction* of the system, which can be defined \nover different coordinates, e.g., position space, momentum space, etc. \n\n$$\\psi(x,y,z, t): \\mathbb{R}^3\\times \\mathbb{R}^+ \\to \\mathbb{C} \\ .$$\n\nThe wavefunction assigns a complex number to each spacetime location and \nthe [Born rule](https://en.wikipedia.org/wiki/Born_rule) allows us to map its \n*complex probability amplitude values* into actual *probability values* \nin $[0,1]\\subseteq \\mathbb{R}$. This mapping squares the modulus \nof the wavefunction to produce the *probability density* of observing\na particle in a given spatiotemporal region. Symbolically, using the \n*complex conjugation* notation \n$\\left (z=x+iy\\in \\mathbb{C}, z^*\\equiv \\bar{z}=x-iy\\right )$, \nthe *probability density* is defined by\n\n$$p(x,y,z,t)=\\psi^*(x,y,z,t)\\ \\psi(x,y,z,t)\\ .$$\n\nAnd the corresponding *probability* of finding the particle in a solid volume $V$ is\n\n$$P(t)=\\int_V {p(x,y,z,t) dx dy dz} =\\int_V {\\psi^*(x,y,z,t)\\psi(x,y,z,t) dx dy dz}\\ .$$\nProbability density functions arise when we model likelihoods, chances, or probabilities\nof events connected with experimental observations of continuous or discrete variables, \ne.g., particle positions, momenta, spins, energies, etc. In situations with discrete probability \nmass functions, we have a finite number of outcomes, each with non-trivial chances \nof being observed. In continuous outcomes with infinitely many non-trivial possibilities\nit is impractical to directly assign a probability value to each individual outcome. \n\nRecall the [three axioms of probability](https://en.wikipedia.org/wiki/Probability_axioms)\n\n - All probabilities are in $[0,1]\\subset \\mathbb{R}$, \n - All probabilities integrate to $1$, and \n - Probabilities are additive. \n \nIn the continuous outcome case, there are infinitely many \npossible states of the particle (e.g., positions) and generally, observing the particle\nin most specific points in spacetime would be trivial. \n\nTherefore, in general, its most interesting to quantify the chance of finding the \nparticle within some non-trivial spacetime *hypervolume*, and we expect\nto compute or associate a nonzero probability with such an event.",
      "word_count": 524
    },
    {
      "title": "Wavefunctions",
      "content": "## Matter waves\n\nIn [Chapter 3 (Time Complexity)](https://www.socr.umich.edu/TCIU/HTMLs/Chapter3_Introduction.html), we show examples of 1D and 2D matter waves. Below is an example of a complex wave function of constant amplitude.\n\n\n\n## General QM wavefunctions\n\nIn quantum mechanics, we often estimate the probability density for a particle's \nposition (or momentum, energy, spin, etc.) by using a dynamical model equation \ndescribing how $p(x,y,z, t)$ changes over time. Despite being highly quantitative, \nprobabilities are always associated with uncertainty, i.e., they are stochastic\nrepresentations of event likelihoods. In general, probabilistic models represent\n*lossy information compression*, as they do not contain all information \nneeded to completely reconstruct, describe, or predict the exact past and future \nof a particle system. There will be situations where particles start with \nidentical densities $p(x,y,z, t)$ under fixed initial conditions, however\nthe systems evolve over time into completely different states.\n\n**Note**: Much like the duality between time-limited and band-limited functions\ndescribe different characterizations of the same signals via the Fourier transform,\nparticle systems are completely described by their corresponding *wavefunctions*, \nwhich may be difficult to work with. Wavefunctions are *approximately described* by \ntheir corresponding *probability functions* - squared magnitudes of the wavefunctions.\n\nUsing the probability functions we have sufficient information to predict likelihoods\nby using the system's complex-valued *wavefunction* $\\psi(x)$ to express\nthe corresponding *probability density* $p(x,y,z, t)=\\psi^*(x,y,z,t)\\psi(x,y,z,t)$.\n\nIn essence, even though both are descriptors of the same particle system,\nthe *wavefunctions are richer information theoretic objects*, whereas the \n*probability densities are more computationally efficient (realistic) object representations*.\nThe complex phase of $\\psi(x,y,z,t)$\nvaries dynamically across spacetime and captures the complete\ninformation about the particle's placement, momentum, spin, energy, etc.,\nwhich are useful to characterize and predict its future behavior. \n\nThe measuring unit of a wavefunction can be thought of as \n*square root of a probability density*, and the particle system wavefunction \nis a solution the [Schrödinger equation](https://en.wikipedia.org/wiki/Schr%C3%B6dinger_equation)\n\n$$i\\hbar {\\frac {\\partial }{\\partial t}}\\psi (x,t)=\\left[\n\\underbrace{-{\\frac {\\hbar ^{2}}{2m}}{\\frac {\\partial ^{2}}{\\partial x^{2}}}}_{kinetic}+\\underbrace{V(x,t)}_{potential}\\right]\\psi (x,t)\\ ,$$\n\nwhere in this one-spatial dimension example, $\\psi (x,t)$ is a wavefunction\nassigning a complex number to each spatial location $x$ and each time point $t$,\n$m$ is the mass of the particle, and $V( x , t )$ is the *potential energy*\nof the system environment, $i$ is the imaginary unit, and $\\hbar$ is the reduced \n[Planck constant](https://en.wikipedia.org/wiki/Planck_constant) measured\nin units of action ($energy \\times time$).\n\nThe physical interpretation of a single spatial dimension wavefunction \n$\\psi(x,t)$ may be explicated in diffraction patterns of electromagnetic waves\nobserved in two-slit interference of monochromatic light. \nThe *wavefunction* $\\psi(x,t)$ of a light wave represents the electric field strength\nwith an *energy density* $\\psi^*(x,t)\\psi(x,t)$. Since the \n[Planck constant](https://en.wikipedia.org/wiki/Planck_constant) $h$ is fixed,\nthe energy of an individual photon $\\epsilon_{photon}=hf$ only depends \non the *light frequency* $f$. Hence, $|\\psi(x,t)|^2=\\psi^*(x,t)\\psi(x,t)$ \nis proportional to the number of photons. When light waves travel through two\nspace-separated slits, there is *interference* reflecting the superposition of the \nwaves that shows on the diffraction screen used to observe (collect) the \nmeasurements. Patterns of *bright fringes* correspond to points of *constructive* \n(*agglomerative*) light wave interference, whereas *dark fringes* correspond \nto points in the diffraction plane reflecting *destructive* (discriminative)\ninterference of the light waves.\n\nWhen the image detection screen where the wave image is projected is exposed to \nvery weak light (few photons at a time), the observed interference pattern \nappears random, and less characteristic of light wave interference. \nEach individual photon hitting the detection screen appears as a single point. \nThe overall *point density* is expected to be *high* at locations of \n*constructive* wave interference, whereas correspondingly *low (point density)* \nat locations of *destructive* wave interference. \n\nPer unit area, the probability that a single photon will strike a particular \nspot $(x)$, on the screen is proportional to the *square of the total electric field*, \n$|\\psi(x,t)|^2=\\psi^*(x,t)\\psi(x,t)$.\n\n[This PHET interactive demonstration shows the light waves passing through the slits\nand forming overlapping circular waves that interact and project on the detection screen](https://phet.colorado.edu/sims/cheerpj/quantum-wave-interference/latest/quantum-wave-interference.html?simulation=quantum-wave-interference). \nHigh-density points (*maxima*) correspond to overlapping wave crests, whereas low-density\npoints (*minima*) correspond to locations where the *crests* of the wave from one slit\noverlap the *troughs*, which cancels them. \n\nThe interpretations of *square of the matter waves* $|\\psi(x,t)|^2=\\psi^*(x,t)\\psi(x,t)$ \nis similar to the interpretation of the *square of the electric field* $|E(x,t)|^2$, where $E(x,t)$ is the *electric field strength.* Specifically, the probability density\n$|\\psi(x,t)|^2$ is the probability that a particle will be found at a particular \nspatial position ($x$) and time ($t$) per unit length.\n\nMore generally, the probability that at time $t$ a particle is located in a \nnarrow interval $(x, x + dx)$ is\n\n$$P(x,x+dx)=|\\psi(x,t)|^2dx\\ .$$\n\nFor *smooth wavefunctions*, which vary slowly over the spatial interval, we can \napproximate the probability that a particle is found in the interval $\\Delta x$ by\n\n$$P(x,x+\\Delta x)\\approx |\\psi(x,t)|^2 \\Delta x\\ .$$\n\nThe square of the complex-valued wavefunction guarantees the resulting probability\nis in $\\mathbb{R}^+$, even though the wavefunction is complex-valued, $\\psi(x,t):\\mathbb{R}\\times \\mathbb{R}^+\\to \\mathbb{C}$. \n\nFor *rapidly changing wavefunctions* over the interval, we use \n[integration to estimate\nthe same probability](https://socr.umich.edu/BPAD/BPAD_notes/Biophysics430_Chap01_MathFoundations.html) that that a particle is found in the interval $\\Delta x$\n\n$$P(x,x+\\Delta x)=\\int_{x}^{x+\\Delta x} |\\psi(x',t)|^2\\ dx'\\ .$$\n\nThis probability is just the area under the function $|\\psi(x,t)|^2$ between $x$ and\n$x+\\Delta x$. Clearly, to satisfy the unitarity axiom of probability, we need\na *normalization condition*.\n\n$$P(-\\infty, +\\infty)=\\int_{-\\infty}^{\\infty} |\\psi(x',t)|^2\\ dx'=1\\ .$$\n\nOf course, for particles in 3D spatial dimensions the integration extends to cover a\nhypervolume (solid volume) of interest.\n\n## Example 1: Linear Density\n\nSuppose a *particle*, i.e., a *moving ball*, is constrained along a linear tube of length $L$.\nAssume at some time $t$, the probability of finding the ball increases linearly from \n$0$ (at the start of the tube $0$) to $1$ (at the end of the tube $L$). \nFind the probability of finding the ball in the left half of the tube at that time $t$.\n\n*Solution*: Using the probabilistic interpretation of the quantum mechanical \nwavefunction we can express the wavefunction as a function of spacetime $(x,t)$. \n\n\nThe wave function of the ball can be expressed as\n\n$$\\psi \\, (x,t) = \\overbrace{C}^{const.} \\times \\overbrace{x}^{linear} \\times \n\\overbrace{\\mathbb{I}_{\\{0\\leq x \\leq L\\}}(x)}^{support}, \\ \n\\forall (x,t)\\in\\mathbb{R}\\times\\mathbb{R}^+ \\ .$$\n\nUsing the probability normalization condition (total probability must be $1$),\nwe can estimate the constant $C=\\frac{\\sqrt{3}}{L^{3/2}}$, \n\n$$1=P(\\infty, +\\infty) = \\int_{-\\infty}^{\\infty} |C\\times x \\times \n\\mathbb{I}_{0\\leq x \\leq L}(x)|^2 dx = \\\\\n\\int_{0}^{L} |C\\ x |^2 dx = C^2 \\frac{x^3}{3}\\bigg |_{0}^{L/2}=\n\\frac{C^2 L^3}3 = 1\\ \\ \\Longrightarrow C=\\frac{\\sqrt{3}}{L^{3/2}}.$$\n\n\nNext, we can integrate the *squared wavefunction magnitude* over the *left-half* of \nthe tube to obtain the *probability* that the particle is in that left-half of the tube. The graph shows that the probability increases linearly with the position $x$.\nHence, the chance that the particle is in the left-half is much smaller than the \nprobability that the particle is in the right-half of the tube\n\n$$P\\left (x = 0, \\frac{L}{2}\\right ) = \\int_{0}^{L/2} \\left| C x \\right| ^2 dx\n= C^2\\frac{x^3}{3} \\bigg |_{x=0}^{L/2} = \\frac{3}{L^{3}}\\ \\frac{L^3}{24}\n=\\frac{1}{8}= 0.125\\ . $$\n\nClearly the odds that the particle is in the *left half* of the tube $p=0.125$\nare much smaller than finding the particle in the *right half* of the biased (loaded)\ntube, $p=1 - 0.125 = 0.875$.\n\n\n## Example 2: Non-linear density\n\nSuppose now the a moving ball is constrained along a linear tube of length $L$, where \ninstead of the linear density we saw in the prior example, we have a trigonometric $\\sin()$ \ndensity function. In this case, we will compute the probability of finding the \nparticle in the *first one-quarter of the tube*, $[0,L/4]$.\n\n*Solution*: A similar strategy to the earlier linear density *Example 1*, however, now the wavefunction has *two unknown parameters*, instead of a sole *scaling* parameter $C$ corresponding to *amplitude* of the wavefunction. The second parameter is associated with the *wavelength* ($\\kappa$) of the `sine` wave. The amplitude parameter can be estimated using the given boundary conditions. Whereas the estimation of the wavelength parameter can be accomplished by normalizing the wavefunction to ensure the resulting probability is unitary. \n\nTo compute the probability that the particle is in the *first one-quarter of the tube*, \nwe again integrate the square of the wavefunction over the first quarter of the tube.\n\nThe wavefunction of the ball can be written\n\n$$\\psi(x,t)=C\\ \\sin(\\kappa x)\\ \\mathbb{I}_{\\{0\\leq x \\leq L\\} }(x), \n\\forall (x,t)\\in\\mathbb{R}\\times\\mathbb{R}^+ \\ , $$\n\nwhere the parameters $C$ and $\\kappa=\\frac{2\\pi}{\\lambda}$ represent the \nwavefunction *amplitude* and *wavenumber*. As the particle is restricted inside\nthe tube, the amplitude of the wavefunction is trivial outside the tube of length $L$\n\n$$\\psi(x=0,t=0)\\equiv \\psi(x=L,t=0) =0 \\Longrightarrow \\\\\n\\underbrace{C \\sin(\\kappa L)}_{\\psi(x,t)} = 0 \\Longrightarrow \n\\kappa L= m\\pi, \\ \\forall m\\in \\mathbb{Z} \\ .$$\n\nFor $m=1$, one solution for the *wavenumber* is $\\kappa=\\frac{\\pi}{L}$.\n\nFor estimating the wavefunction *amplitude* we use the normalization \ncondition \n\n$$\\begin{align} 1=P(x\\in [0, L]) &= \\int_0^{L} \\left|\n\\underbrace{C \\sin(\\overbrace{\\kappa}^{\\frac{\\pi}{L}} x)}_{\\psi(x,t)}\\right|^2dx \\\\[5pt] &\\underbrace{=}_{x'=\\kappa x} \\frac{C^2}{\\kappa}\n\\int_0^{\\pi} \\sin^2(x')dx' = \\frac{C^2}{\\kappa}\\ \\frac{\\pi}{2}\\approx 1.5708\n\\ \\frac{C^2}{\\kappa}\\\\[5pt] &\n\\underbrace{\\Longrightarrow}_{\\kappa=\\frac{\\pi}{L}} C=\\sqrt{\\frac{2}{L}} . \\end{align} $$\n\nTherefore, the wavefunction describing the spatiotemporal\nbehavior of the particle is\n\n$$\\psi(x,t)= \\sqrt{\\frac{2}{L}} \\sin\\left (\\frac{\\pi}{L} x\\right )\\ .$$\n\nFinally, we can compute the probability of finding the particle in the *first one-quarter of the tube* by squaring the wavefunction amplitude and integrating over the interval $[0,L/4]$\n\n$$\\begin{align} P(x\\in [0, L/4]) &= \\frac{2}{L} \\int_0^{L/4} \n \\sin^2\\left (\\frac{\\pi}{L} x\\right ) dx =\n\\frac{\\pi -2}{4\\pi}\\approx 0.090845\\ . \\end{align} $$\n\n\nHence, the probability of finding the particle in the *first quarter of the tube* \nis $\\approx 9.1\\%$. According the periodicity of the\ntrigonometric function $\\sin()$, the particle wavelength is $\\lambda=2 L$. \nFor [matter waves, the relationship](https://labs.phys.utk.edu/mbreinig/phys222core/modules/m10/matter_waves.html) between *momentum* $p$ and *wavelength* \n$\\lambda$ is $p = \\frac{h}{\\lambda}$ and the relationship between *energy* $E$ and \n*frequency* $f$ is $E = hf$. For our *macroscopic tube* of length $L=1m$ ($1$ meter), \nwe can estimate the *momentum* of the particle \n\n$$p=\\frac{h}{\\lambda}=\\frac{h}{2 L}\\approx 10^{-36}m/s\\ ,$$\nwhich is too tiny to be *directly* sensed, detected, or observed using currently available instruments or technologies.",
      "word_count": 1633
    },
    {
      "title": "Copenhagen Quantum Mechanics Interpretation of Wavefunctions",
      "content": "Suppose we are modeling the dynamics of a propagating sound wave whose *wavefunction*, $\\phi(x,t)=C \\sin(\\kappa x - \\omega t)$, is a mathematical function modeling the spatial extents and temporal dynamics of the particle\nand quantify the likelihood of the particle to be within certain spacetime\ndomain. A [harmonic wavefunction of the particle *position*](https://socr.umich.edu/BPAD/BPAD_notes/Biophysics430_Chap02_PhysicsMechanics.html) $x$ and *time* $t$ can be used to a model for the particle displacement $\\psi(x, t)= C \\sin(\\kappa x - \\omega t)$, where the model parameters $\\kappa  = \\frac{2\\pi}{\\lambda}$ is the *wavenumber* and $\\omega$ is the *frequency* of the sound wave propagating in the horizontal direction. \n\nThis harmonic wave function represents a solution of the 1D wave equation \n\n$${\\frac {\\partial^{2} \\psi}{\\partial t^{2}}} = c^{2} {\\frac {\\partial^{2} \\psi}{\\partial x^{2}}},$$\n\nwhere $c=\\frac{\\omega}{\\kappa}\\equiv \\sqrt{\\frac{E}{\\rho}}$ is the *phase velocity* (speed) of the sound wave, $E$ is Young's modulus (compression modulus), $\\rho$ is the density of the ambient material. \n\n\nThis sound wave *wavefunction model* can also be used for *predictions.*\nIn other words, *data-driven predictions* can be complemented by *model-based predictions* via the wavefunction $\\psi (x,t)$ without assuming the availability of observations or measurements of the process. \n\nThis theoretical-model based inference scheme avoids potential measurement-intervening\neffects on the actual physical particle spatiotemporal dynamics. The particle model\nprovides a rigorous quantification of the spatial localization \nof the particle using the probabilistic interpretation of the wavefunction.\n\nIn quantum mechanical reality, the particle is in a superposition of all of its base states and simultaneously occupies each position, everywhere all the time, $(x,t)\\in\\mathbb{R}^3\\times \\mathbb{R}^+$. It's just\nthat its probabilistic localization is *stochastic.* During the process of *instantaneously*\nmeasuring or detecting observations, the *wavefunction collapse interpretation*\nsuggests that the particle may be in one specific\nfixed position state $(x,x+dx)$ with a corresponding *probability*\n\n$$P([x,x+\\Delta x], t)=|\\psi(x,t)|^2 \\Delta x\\ .$$\n\n## Example 3: Quantum Computing and Qubits\n\nA binary two-state systems, such as $\\pm$, $left/right$, $\\uparrow\\ /\\ \\downarrow$, etc., \nare used to illustrate basic quantum mechanics principles. Applications of two-state \nsystem models include *electron spin* and *mixed states of particles*, *atoms*, *molecules*, and *quantum computing.* Contemporary digital computers store, encode, \nand compute information in *binary digits* ($0$'s and $1$'s).\n\n*Quantum computers* store, encode, and process information and data in \nthe form of *quantum bits* (**qubits**). Qubits are more than a binary\ntwo-state system. They encode information using superposition of mixed\n$0$'s and $1$'s states. This duality between binary and quantum systems is reminiscent to the duality between *arithmetic* over the reals $x,y, (x+y)\\in\\mathbb{R}$ and *complex-arithmetic*\nover the significantly *enriched complex plane*\n$(\\alpha x+i\\beta y)\\in\\mathbb{C}\\cong \\mathbb{R}\\times \\mathbb{R}$. \n\n\nIn general, the form of the wavefunction depends on the specifics of the physical system. \nMost *wavefunctions are complex-valued*, whereas all *physical reality experimental measurements* only produce real number outcomes. The probability that a particle is found in the \nnarrow interval $(x,x+\\Delta x)$ at time $t$ is\n\n$$P(x,x+\\Delta x)=|\\psi(x,t)|^2dx=\\underbrace{\\psi^*(x,t)}_{complex\\\\ conjugate}\n\\psi(x,t)\\Delta x\\ .$$\n\nFor instance, if the value of the wavefunction at a fixed spatiotemporal location\n$(x_o,t_o)$ is $\\psi(x_o,t_o)=1.5-4i$, its conjugate is $\\psi^*(x_o,t_o)=1.5+4i$ and\n$\\psi^*(x_o,t_o)\\times \\psi(x_o,t_o)=18.25$.\n\nThe wavefunction represents a quantum mechanical model for the motion of a free \nparticle moving with a constant velocity along the x-axis without influence of \nexternal forces\n\n$$\\psi(x,t)= \\underbrace{C}_{amplitude}\\cos(\\kappa x - \\omega t) + \ni C\\sin(\\kappa x - \\omega t) =\nCe^{i\\ \\overbrace{(\\kappa x - \\omega t)}^{\\phi,\\ phase\\ angle}},$$\nwhere $C$ is the *amplitude*, $\\kappa$ is the *wavenumber*, $\\omega$\nis the *angular frequency*, and $\\phi=(\\kappa x - \\omega t)$ is the *phase angle.*  \n\nOver an infinitesimal interval of length $\\Delta x$, the probability of finding the particle in that interval is\n\n$$P(x,x+\\Delta x)\\approx \\psi^*(x,t)\\psi(x,t)\\Delta x=\n(C e^{-i\\phi})(C e^{i\\phi})\\Delta x = (C^* C)\\Delta x = \n|C|^2\\Delta x\\in\\mathbb{R}\\ .$$\n\nNote that the constant $C\\in\\mathbb{C}$, $|C|^2\\in\\mathbb{R}$,\nand $P(x,x+\\Delta x)\\geq 0$ is the *probability density*\nthat leads to *quantum mechanics predictions* that can be checked \nusing real physical world experimental observations.\n\n**Example**. Consider a particle with energy $E$ moving along the \nx-axis restricted to the interval $[0,L]$. Let's assume \n$\\psi(x,t) = C e^{-i\\frac{Et}{\\hbar}} \\sin(\\pi x) \\mathbb{I}_{\\{0\\leq x\\leq L\\}}(x)$ is the wavefunction model for this system.\n\nAs we showed earlier, to ensure the probabilistic interpretation of\nthe model, the normalization constant has to be $C=\\sqrt{\\frac{2}{L}}$.",
      "word_count": 685
    },
    {
      "title": "Expectation Values",
      "content": "The classical mechanics solutions to the [equations of motion](https://en.wikipedia.org/wiki/Equations_of_motion) are functions\nof a *measurable quantity*, such as the *particle position* $x(t)$ at time $t$. \n\nHere are the equations of motion for constant acceleration, $a$:\n\n$$v=u+at,\\\\ s=\\frac{u+v}{2}t,\\\\ v^2=u^2+2as, \\\\ s=ut+\\frac{1}{2}at^2, \n\\\\s=vt-\\frac{1}{2}at^2 \\ .$$\nwhere the *variables* are\n\n - $t$ - time (seconds, $s$),\n - $s$ - distance (or displacement in meters, $m$), \n - $u$ - initial velocity ($m/s$), \n - $v$ - velocity at time t  ($m/s$),\n - $a$ - the constant acceleration ($m/s^2$).\n\nNote that all the measurements are in base *SI* units and the quantities $s$, \n$u$, $v$, and $a$ are all *vector quantities*\nand their signs reflect the *direction of motion.*\n\nIn *classical Newtonian mechanics*, the particle has one value of position $x(t)$\nfor any time $t$. Whereas in *quantum mechanics*, the solution to the equations of motion\nare *wavefunctions*, $\\psi(x,t)$ and the particle has a *distribution associated\nwith all positions* at a given time $t$, not a single value, but a distribution\nquantifying the *probability density* of finding the particle in certain areas\nusing the square wavefunction amplitude $|\\psi(x,t)|^2$.\n\nTo relate these QM distributional representations to discrete observable classical\nmechanics measurements we can compute the corresponding *position expected value*,\nwhich represents the *average value of position over a large number of particles (repeated sampling connection to spacekime representation) with the same wavefunction*:\n\n$$\\overbrace{\\langle \\underbrace{x}_{position}\\rangle}^{Expected\\ value\\ of \\\\ \nposition\\ at\\ time\\ t} = \\int_{-\\infty}^{\\infty} x\\ \\overbrace{P(x,t)}^{density}dx=\n\\int_{-\\infty}^{\\infty} x\\ \\psi^*(x,t) \\psi(x,t)\\ dx\\\\ =\n\\int_{-\\infty}^{\\infty} \\underbrace{\\psi^*(x,t)\\ x\\ \\psi(x,t)}_{\\langle \\psi | \n\\underbrace{\\hat{x}}_{Position\\\\ operator} | \\psi \\rangle}\\ dx=\n\\langle \\psi | \\hat{x} | \\psi \\rangle\\ .$$\n\nJust like we have multiple *coordinate representations* of describing functions\n$f:\\mathbb{R}^2\\to \\mathbb{R}$, e.g., Cartesian $(x,y)$, polar $(\\rho, \\varphi)$,\nand conjugate pairs $(z,{\\bar{z}})$, the wavefunction can also be expressed in \ndifferent bases, i.e., in terms of quantities other than position. Examples\nof such alternative bases for representing the wavefunction include *velocity* \n$(v)$, *momentum* $(p)$, *kinetic energy* $(K)$, etc. It's often useful to express\nthe *expectation value of momentum*\n\n$$\\overbrace{\\langle \\underbrace{p}_{momentum}\\rangle}^{Expected\\ value\\ of \\\\ \nmomentum\\ at\\ time\\ t} = \\int_{-\\infty}^{\\infty} p\\ \\overbrace{P(p,t)}^{density}dp=\n\\int_{-\\infty}^{\\infty} p\\ \\psi^*(p,t) \\psi(p,t)\\ dp\\\\ =\n\\int_{-\\infty}^{\\infty} \\underbrace{\\psi^*(p,t)\\ p\\ \\psi(p,t)}_{\\langle \\psi | \n\\hat{p} | \\psi \\rangle}\\ dp=\n\\langle \\psi | \\underbrace{\\hat{p}}_{Momentum\\\\ operator} | \\psi \\rangle\\ ,$$\n\nwhere $dp$ is an infinitesimal interval in momentum. When the wavefunction is\nexpressed in position basis, $\\psi(x,t)$, rather than in momentum space, $\\psi(p,t)$,\nwe can compute the *expectation value of momentum in position-space*\n\n$$\\overbrace{\\langle \\underbrace{p}_{momentum}\\rangle}^{Expected\\ value\\ of \\\\ \nmomentum\\ at\\ time\\ t} = \n\\int_{-\\infty}^{\\infty} {\\psi^*(x,t)\\ \\underbrace{\\hat{p}}_{Momentum\\\\ operator} \n\\ \\psi(x,t)}\\ dx\\\\ =\n\\int_{-\\infty}^{\\infty} {\\psi^*(x,t)\\ \\underbrace{\\left (-i\\hbar\\frac{d}{dx}\\right )\n}_{Momentum\\ operator\\\\ in\\ direction\\ x}\\ \\psi(x,t)}\\ dx\\equiv -i\\hbar\\frac{d}{dx}\\ .$$\n\nExplicitly, to compute the expectation value of the momentum in position space,\nthe integrand $\\langle \\psi | \\hat{p} | \\psi \\rangle$ involves two steps.\nFirst, the momentum operator operates on the wavefunction to the right, \n$\\hat{p} | \\psi \\rangle$. And second, the result is multiplied by the complex \nconjugate of the wavefunction on the left, \n$$\\langle \\psi | \\hat{p} | \\psi \\rangle\\equiv \\underbrace{\\langle \\psi |}_{second\\\\ step} \\overbrace{\\left (\\hat{p} | \n\\psi \\rangle\\right )}^{first\\\\ step}\\ .$$\n\nThere many alternative strategies to derive the *momentum operator in position space*\n(e.g., in the 1D $x$-direction). One approach is by using the [Fourier transform](https://socr.umich.edu/BPAD/BPAD_notes/Biophysics430_Chap12_Imaging.html#2_Fourier_Transform) \nrelation between position and momentum representations. We can express\n\n$$\\psi (x)=\\langle x|\\psi \\rangle =\\int \\langle x|p\\rangle \\langle p|\\psi \\rangle dp=\n\\frac{1}{{\\sqrt {2\\pi \\hbar }}} \\int {e^{ixp/\\hbar }{\\hat {\\psi }}(p) }\\ dp\\ ,$$\n\nwhere $\\hat {\\psi }(p)$ is the Fourier transform of the wavefunction $\\psi(x)$, \ntransforming from coordinate *position-space* ($x$) to *momentum space* ($p$). \nThan,\n\n$${\\hat {p}}=\\int |p\\rangle p\\langle p| \\ dp=-i\\hbar \\int |x\\rangle \n\\left( {\\frac {d}{dx}}\\right ) \\langle x|\\ dx\\ .$$\n\nIn other words, the momentum acting in coordinate space corresponds to spatial frequency,\n\n$$\\langle x|{\\hat {p}}|\\psi \\rangle =-i\\hbar {\\frac {d}{dx}}\\psi (x)\\ .$$\n\nSimilarly, the forward and the inverse [Fourier transforms](https://socr.umich.edu/HTML5/Fourier_Wavelet_app/?Fourier) allows us to express\nthe *position operator in the momentum basis*,\n\n$$\\langle p|{\\hat {x}}|\\psi \\rangle =i\\hbar {\\frac {d}{dp}}\\psi (p)\\ .$$\n\nFor the other spatial dimensions ($y,z$), the momentum operators are defined analogously.\n\n\n**Example**: Consider the one-spatial dimension ($x$) *kinetic energy operator* \n\n$$\\hat{K} =\\frac{1}{2}m(\\hat{v}_x)^2=\\frac{(\\hat{p}_x)^2}{2m}=\n\\frac{\\left (-i\\hbar \\frac{d}{dx}\\right )^2}{2m} =-\\frac{\\hbar^2}{2m}\n\\frac{d}{dx}\\left (\\frac{d}{dx} \\right )\\ .$$\n\nIn essence, computing the *expectation value of the kinetic energy* of a particle in 1D\nrequires a pair of derivatives of the wavefunction prior to its integration\n(to find the overall average). When the wavefunction is *even*, *odd*, or *symmetric*,\nthe calculations of operator expectation values are often simplified.\n\n## Example: Laplace wavefunction\n\nConsider a particle whose behavior is modeled by a\n*Laplace wavefunction* $\\psi(x)=\\frac{1}{\\sqrt{x}}\\ e^{-\\frac{|x|}{x_o}}$.\nCompute the *expectation value of position*.\n\n*Solution*: Plug in the Laplace wavefunction in the definition of expectation value\nfor the position operator. Recalling that an integral of an *odd function* over\na symmetric interval is trivial:\n\n$$\\begin{align*} \\langle x \\rangle &= \\int_{-\\infty}^{\\infty} x|\\psi(x)|^2 dx = \n\\int_{-\\infty}^{\\infty} x\\left |\\dfrac{e^{-\\frac{|x|}{x_0}}}{\\sqrt{x_0}}\\right |^2\\ dx \\\\[4pt] &= \\dfrac{1}{x_0} \\int_{-\\infty}^{\\infty} \\underbrace{x e^{-2\\frac{|x|}{x_0}}}_{odd\\ function}\\ dx = 0  \\end{align*}  \\ .$$\n\nThe result that $\\langle x\\rangle =0$ is to be expected as the Laplace probability density\nfunction is symmetric about $x=0$.\n\n### Connection between Expectation Value, Laplace Transform, and MGF\n\nIn probability and statistics, there is a direct connection between the *expectation value*, the *Laplace transform*, and the *moment generating function* (MGF).\n\nSuppose $X$ is a *random variable*, then its *Laplace transform* (LT), more specifically, the LT of its *probability density function* $f_X(\\cdot)$, is given by the expectation of an exponential: \n\n$$\\mathcal{L}(X)\\equiv \\mathcal{L}(f_X)(z)=\n\\mathbb{E}(e^{-zX})\\ .$$\n\nThe [moment generating function](https://en.wikipedia.org/wiki/Moment-generating_function) of a random variable $X$ is\n\n$$MGF_{X}(t)=\\mathbb{E} \\!\\left[e^{tX}\\right]= \\int_0^{\\infty}f_X(x) e^{tx}dx\\ , \\forall t\\in\\mathbb{R}^+\\ .$$\nThe Laplace transform of a distribution with probability density function $f_X(\\cdot)$ over time $t\\in\\mathbb{R}^+$ is\n\n$${\\mathcal{L}}(f_X)(t)=\\mathbb{E}\\left[e^{-tX}\\right]=\n\\int_0^{\\infty}f_X(x) e^{-tx}dx\\ .$$\n\nThe double-sided Laplace transform of the density $f_X$ is\n\n$$\\mathcal{L}(f_{X})(t)=\\int_{-\\infty }^{\\infty }e^{-tx}f_{X}(x)\\ dx\\ ,$$\n\nand the moment-generating function is\n\n$$MGF_{X}(t)=\\mathbb{E} \\left[e^{tX}\\right]=\n\\int_{-\\infty }^{\\infty }e^{tx}f_{X}(x)\\ dx\\ .$$\n\nHence, the relation between a random variable's moment generating function $MGF_{X}(t)$ and the double-sided Laplace transform of its probability density function \n$f_{X}(x)$ is\n\n$$M_{X}(t)={\\mathcal {L}}(f_{X})(-t),$$\n\nIn other words, when the moment generating function exists, the characteristic function of $X$ is a [Wick rotation](https://en.wikipedia.org/wiki/Wick_rotation) of $MGF_{X}(t)$. The characteristic function of a continuous random variable $X$ is the Fourier transform of its  density $f_{X}(x)$. The Fourier transform of an exponential function $f(x)$ is a Wick rotation of its double-sided Laplace transform. \n\n\n## Exponential Function Uniqueness\n\n**Theorem**: The exponential function $f(x)\\equiv C\\ e^{x}$ is the only function\nthat is its own derivative.\n\n*Proof*: First, confirm that if $f(x)\\equiv C\\ e^{x}$, then \n$f'(x)\\equiv C\\ e^{x}=f(x),\\ \\forall x$. Next, suppose another function \npossesses the same property $g'(x)\\equiv g(x),\\ \\forall x$. \nConsider their *quotient* $h(x)=\\frac{g(x)}{f(x)}=\\frac{g(x)}{e^{x}}=g(x)e^{-x}$,\nwhich is well-defined, since $e^x\\gt 0,\\ \\forall x$. Realize that the quotient \nfunction is constant as $h'(x)=g'(x)e^{-x} - g(x)e^{-x}=0$, since we assumed \nthe property $g'(x)\\equiv g(x)$. Therefore, $h(x)$ is a constant and \n$g(x)=Cf(x)$, and the exponential function is the only possible function that is\nits own derivative.\n\nThis *uniqueness of the exponential function* is important as assuming a \nconstant Hamiltonian (time-invariant energy), the Schrodinger equation \n$\\hbar \\frac{d}{d t}|\\psi(t)\\rangle = H|\\psi(t)\\rangle$ has a solution\n\n$$|\\psi (t)\\rangle =\\underbrace{e^{-i\\frac{{\\hat {H}}t}{\\hbar} }}_{exponential}\\times \n\\underbrace{|\\psi (0)\\rangle\n}_{constant}.$$\n\nThe operator $\\hat{U}( t ) = e^{-i\\frac{{\\hat {H}}t}{\\hbar} }$ is the \n*unitary time-evolution operator*, it preserves the inner product between\nvectors in the Hilbert space. If the initial state is \n$| \\psi( 0 )\\rangle$, then the state at a later time $t$ is given by\n$|\\psi(t)\\rangle = \\hat{U}( t ) |\\psi(0)\\rangle$. \n\n## Example: Time-dependent wavefunction\n\nLet's consider a particle restricted to an interval $[0,L]$ whose\nbehavior is governed by *time-dependent wavefunction* \n\n$$\\psi(x,t) = C\\ e^{-i\\omega t}\\ \\sin \\left (\\frac{\\pi x}{L}\\right )\n\\ \\mathbb{I}_{\\{0\\leq x\\leq L\\}}(x)\\ ,$$\n\nwhere $\\omega$ is the *angular frequency*. The $\\sin()$ periodic trigonometric \nfunction ensures the wavefunction confines the particle to the interval \n$[0,L]$ and $\\psi(0,t) =\\psi(L,t) =0\\ \\forall\\ t\\in\\mathbb{R}^+$.\nCalculate the expectation values of the particle's *position*, *momentum*, \nand *kinetic energy.*\n\n*Solution*: First, to ensure probabilistic interpretation of the wavefunction square\nmagnitude, we normalize the wavefunction to estimate the amplitude constant $C$.\nThen, we will expand the three operators to estimate the corresponding\nexpectation values.\n\n - Estimation of the *normalization constant* ($C$):\n\n$$\\begin{align*} 1 =\\langle \\psi |\\psi \\rangle &= \\int_0^L \\psi^* (x) \\psi(x)\\ dx = \n\\int_0^L \\left(C e^{+i\\omega t} \\sin \\, \\dfrac{\\pi x}{L}\\right) \\left(C e^{-i\\omega t} \n\\sin \\, \\dfrac{\\pi x}{L}\\right) dx \\\\[4pt] &= C^2 \\int_0^L \\sin^2 \\, \n\\dfrac{\\pi x}{L}\\ dx = C^2 \\dfrac{L}{2}\\ \\  \\Longrightarrow\\ \\  C = \\sqrt{\\dfrac{2}{L}}.\n\\end{align*} $$\n\n - Expectation value of *position*\n\n$$\\begin{align*}\\langle x \\rangle &= \\int_0^L \\psi^* (x) x \\psi(x) \\ dx = \n\\int_0^L \\left(C e^{+i\\omega t} \\sin \\, \\dfrac{\\pi x}{L}\\right) x \\left(C e^{-i\\omega t} \n\\sin \\, \\dfrac{\\pi x}{L}\\right) \\ dx \\\\[4pt] &= \nC^2 \\int_0^L x \\, \\sin^2 \\, \\dfrac{\\pi x}{L}\\ dx = C^2 \\dfrac{L^2}{4} \n\\ \\ \\Longrightarrow \\ \\  \\langle x \\rangle = \\dfrac{L}{2}. \\nonumber \\end{align*}  \\nonumber$$\n\n - Expectation value of *momentum* in the $x$-direction\n \n$$\\underbrace{\\hat{p}}_{operator}|\\psi(x)\\rangle \\equiv -i\\hbar\\frac{d}{dx} \\psi(x) = -i\\hbar \\dfrac{d}{dx}\n\\left (C e^{-i\\omega t}\\sin \\frac{\\pi x}{L} \\right ) = \n- i\\frac{C\\ \\hbar}{2L} e^{-i\\omega t} \\cos\\frac{\\pi x}{L}.$$\n\n$$\\begin{align*} \\Longrightarrow \\ \\  \\langle p \\rangle &= \\int_0^L \n\\underbrace{\\left(C e^{+i\\omega t}\\sin \\frac{\\pi x}{L}\\right)}_{\\underbrace{\\langle\\psi(x)|}_{bra}}\n\\underbrace{\\left(-i \\frac{Ch}{2L} e^{-i\\omega t} \\cos\\frac{\\pi x}{L}\\right)}_{\\hat{p}\\underbrace{|\\psi(x)\\rangle}_{ket}}\n\\ dx \\\\[4pt] &= \n-i \\dfrac{C^2 \\hbar}{4L} \\int_0^L \\underbrace{\\sin \\frac{2\\pi x}{L}}_{odd\\ function\\\\ \nabout\\ x=\\frac{L}{2}}\\ dx =0\\ . \\end{align*}$$\n\n - Expectation value of the *kinetic energy* in the $x$-direction \n \n$$\\begin{align} \\underbrace{-\\dfrac{\\hbar^2}{2m}\\dfrac{d^2}{dx^2}}_{\\hat{K}} \n\\psi (x) &= \n- \\dfrac{\\hbar^2}{2m} \\dfrac{d^2}{dx^2} \\left (C e^{-i\\omega t} \\, \\sin \\, \n\\dfrac{\\pi x}{L}\\right ) \\\\[4pt] &= - \\dfrac{\\hbar^2}{2m} C\\ e^{-i\\omega t} \n\\frac{d^2}{dx^2} \\, \\sin \\, \\dfrac{\\pi x}{L} = \n\\frac{C\\ \\hbar ^2}{8mL^2} e^{-i\\omega t} \\, \\sin \\, \\dfrac{\\pi x}{L}. \\end{align}$$\n\n\n$$\\begin{align*} \\Longrightarrow \\langle K \\rangle &= \\int_0^L \\left( C\\ e^{+i\\omega t} \n\\sin \\frac{\\pi x}{L}\\right) \\left(\\dfrac{C\\ \\hbar^2}{8mL^2} e^{-i\\omega t} \n\\sin \\frac{\\pi x}{L}\\right) \\ dx \\\\[4pt] &= \\dfrac{C^2\\ \\hbar^2}{8mL^2} \n\\int_0^L  \\sin^2 \\, \\dfrac{\\pi x}{L}\\ dx = \\dfrac{C^2\\ \\hbar^2}{8mL^2} \n\\dfrac{L}{2} = \\dfrac{\\hbar^2}{8mL^2}. \\end{align*}$$\n\n*Summarizing*:\n\n - The *average position* of a **large number of repeated measurements** of particles in this state is $\\frac{L}{2}$.\n - Even though all the particles are constantly moving (not at rest) since their individual kinetic energy is not zero, the *average momentum* of all these particles in aggregate is trivial because the particles are equally likely to be moving to the right as they are to be moving to the left,\n which cancels their *aggregate momenta.*  \n - The *average kinetic energy* is *inversely proportional* to the particle *mass*, $m$, and the *squared length* of the tube, $\\langle K \\rangle \\propto \\dfrac{1}{m\\ L^2}$.\n - The *probability density* function quantifying the particle's localization, $|\\psi|^2 = \\frac{2}{L} \\, \\sin^2 \\left (\\pi \\frac{x}{L}\\right )$ is *maximized* at location $\\frac{L}{2}$ and *minimized* at the ends, $x=0$ and $x=L$.\n\nFor this specific wavefunction, these expected values are *time-independent*. However, \nin general, time dynamics can be encoded in the wavefunction, which may result in \n*time-dependent expectation estimates.*",
      "word_count": 1772
    },
    {
      "title": "Time Evolution",
      "content": "Some quantum mechanics tasks require prediction of properties of atoms and\nnuclei in equilibrium states, i.e., *time-independent quantum-mechanical systems*.\nHowever, certain QM models describe temporally-dynamic processes, such as \n*radioactive decay*, *scattering*, and *nuclear reactions*, where the \nquantum mechanical systems evolve over time, i.e., \n*time-dependent quantum-mechanical systems*.\n\n## Time-dependent Schrodinger Equation\n\nThe fourth postulate of QM states:\n\n - The evolution of a closed system is unitary (reversible). The time evolution\nof the quantum system is given by the *time-dependent Schrodinger equation* \n\n$$i\\hbar \\frac{\\partial |\\psi\\rangle}{\\partial t} = H(t)| \\psi\\rangle\\ ,$$\nwhere $H=H(t)$ is the time-varying energy operator (Hamiltonian of the system) and \nthe reduced Planck constant ($\\hbar= \\frac{h}{2\\pi}$) facilitates the\nconversion from *energy* to *frequency* units.\n\nThe Schrodinger equation describes the time-evolution of a quantum-mechanical system.\nHowever, the axiom that the *evolution of any closed quantum system is unitary*\nis more general and suggests that the state of a system at a later time $t$ is \ngiven by \n$$|\\psi(t)\\rangle = \\underbrace{U(t)}_{unitary\\ } \\underbrace{| \n\\psi(t=0)\\rangle}_{initial\\\\ condition}\\ ,$$\n\nwhere $U(t)$ is a *unitary operator*, i.e., its *adjoint* \n$U^\\dagger\\equiv \\bar{U}^t$, *transpose* of the complex *conjugate* of the operator, \nis identical to its inverse, i.e., $U^\\dagger\\equiv U^{-1}$ and \n$U\\ U^\\dagger\\equiv \\underbrace{\\mathbb{I}}_{identity\\\\ operator}$.\n\nThe integral equation $| \\psi(t)\\rangle = U(t) | \\psi(0)\\rangle$ relates the \nstate at the initial time $t=0$ to the state at time $t$. \n\n**Example**: A first order linear approximation allows us to represent\na function (e.g., a position) $x(t) = x(0) + vt$, where the speed $v=x'(0)$ is constant. \nAnother way to express this local linear model as a solution to the problem of quantifying the \ntemporal dynamics of position is via a *differential equation*, \n$x'(t)=\\frac{d x(t)}{d t} = v$. \n\nMore generally the [Newton's Second Law of Motion](https://en.wikipedia.org/wiki/Newton%27s_laws_of_motion) links *acceleration* to the *force*.\n\n*The acceleration of an object as produced by a net force is directly proportional to the magnitude of the net force, in the same direction as the net force, and inversely proportional to the mass of the object.*\n\n$$\\underbrace{a}_{acceleration} = \\frac{\\overbrace{F}^{force}}{\\underbrace{m}_{mass}}\\ \\ \\ \n\\Longleftrightarrow m\\frac{d^2x(t)}{dt^2}=F\\ .$$\n\nIn QM, the Schrodinger equation describes the evolution of closed systems. \n\n$$i\\hbar \\frac{\\partial \\psi(x,t)}{\\partial t} = H \\psi(x,t) ,$$\n\nwhere $H$ is the system's Hamiltonian. The solution to the Schrodinger PDE\nis the wavefunction $\\psi(x,t)$ which agrees with the initial condition $\\psi(x,0)$.\n\n## Solutions to the Schrodinger Equation\n\n### Time-independent Hamiltonian\n\nThe TISE is a (narrow) special case of the real Schrodinger equation\ndescribing a quantum system whose Hamiltonian $H$ has no explicit time dependence.\nTo find the solutions in this case it makes sense to try and find *stationary states*,\nwhose time evolution is given by \n$|\\psi(t)\\rangle = e^{-i\\frac{Et}{\\hbar}}|\\psi_0\\rangle$. \nPlugging this model solution in the more general (time-dependent) Schrodinger equation,\nyields the *time-independent Schrodinger equation* \n$\\hat{H}|\\psi(0)\\rangle = E|\\psi(0)\\rangle$, which mathematically is an *eigenvalue problem*.\nSolving the TISE for the energy $E$ and $|\\psi(0)\\rangle$ yields the \n*energies* (eigenvalues, $E$) for the stationary states and the corresponding\neigenfunctions.\n\nThe connection between *TISE* (corresponding to a system with time-independent Hamiltonian) and the *TDSE* (where the system Hamiltonian is time-dependent) is\nrooted in the fact that finding the stationary states (solutions of the TISE) \nnaturally leads to formally solving the full TDSE. Indeed, since $H$ is a [Hermitian operator](https://en.wikipedia.org/wiki/Self-adjoint_operator),\nthe [spectral theorem](https://en.wikipedia.org/wiki/Spectral_theorem) suggests the existence of an orthonormal basis $|n\\rangle$ of\n*stationary eigenstates* with corresponding energies $E_n$ (eigenvalues). \nHence, any state $|\\psi(0)\\rangle$ can be expanded as a superposition of the eigenstate \nbasis \n\n$$|\\psi(0)\\rangle = \\sum_n a_n |n\\rangle \\ \\ \\  \\text{with} \\quad a_n = \\langle n |\\psi(0)\\rangle\\ .$$\nThen, a corresponding solution of the *time-dependent Schrodinger equation* is:\n\n$$|\\psi(t)\\rangle = \\sum_n a_ne^{-i\\frac{E_n t}{\\hbar}}|n\\rangle\\ .$$\n\nSuppose the Hamiltonian $H$ is *time independent* \n\n$$\\underbrace{H}_{total\\\\ energy} = \\underbrace{\\frac{\\hat{p}}{2m}}_{kinetic} +\n\\underbrace{V(x,t)}_{potential} \\overbrace{=}^{time\\\\ independent}\n\\frac{\\hat{p}}{2m} + \\underline{V(x)}\\ .$$\n\nThe solutions of the TISE can be obtained using *separation of variables*.\n\n$$\\psi(x,t) = \\varphi(x)f(t)\\ .$$\n\nTaking the partial derivatives and using the product rule for differentiation\nwe get\n\n$$\\frac{\\partial \\psi(x,t)}{dt} = \\frac{df(t)}{dt}\\ \\varphi(x)\\\\\n\\frac{\\partial \\psi(x,t)}{dx} = \\frac{d\\varphi(x)}{dx}\\ f(t)\\\\\n\\frac{\\partial^2 \\psi(x,t)}{dx^2} = \\frac{d^2 \\varphi(x)}{d^2x}\\ f(t)\\ .$$\n\nThus, the Schrodinger equation can also be expressed as\n\n$$i\\hbar \\frac{\\partial \\psi(x,t)}{\\partial t} = H \\psi(x,t) ,$$\n$$i\\hbar \\frac{\\partial f(t)}{\\partial t}\\varphi(x) = -\\frac{\\hbar^2}{2m} \n\\frac{d^2\\varphi(x)}{dx^2} f(t) +V(x)\\varphi(x)f(t)\\ .$$\n\nDividing both sides by $\\psi(x,t)=\\varphi(x)f(t)$ yields\n\n$$\\underbrace{i\\hbar \\underbrace{\\frac{\\partial f(t)}{\\partial t}\\frac{1}{f(t)}}_{solely\\ a\n\\ function\\ of\\ t} = -\\frac{\\hbar^2}{2m} \\underbrace{\\frac{d^2\\varphi(x)}{dx^2} \\frac{1}{\\varphi(x)} +V(x)}_{solely\\ a \\ function\\ of\\ x}}_{both\\ hand\\ sides\\ are\\ a\\ constant,\\ \\ E}\\ .$$\n\nTherefore,\n\n$$i\\hbar \\frac{\\partial f(t)}{\\partial t}\\frac{1}{f(t)}= \nE\\ \\Longrightarrow \\frac{\\partial f(t)}{\\partial t}=\n\\underbrace{-\\frac{i}{\\hbar}E}_{constant}\\  f(t) \\ \\Longrightarrow \nf(t)=f(0) e^{-i\\frac{Et}{\\hbar}} \\ ,\\\\ \n-\\frac{\\hbar^2}{2m} \\frac{d^2\\varphi(x)}{dx^2} \\frac{1}{\\varphi(x)} +V(x)=E\\\\\n\\Longrightarrow \\psi(x,t) \\equiv \\varphi(x)\n\\underbrace{f(t)}_{f(0) e^{-i\\frac{Et}{\\hbar}}}= \\varphi(x) \\underbrace{f(0)}_{constant} \ne^{-i\\frac{Et}{\\hbar}}.$$\n\nAs the constant $f(0)$ can easily be absorbed in the wavefunction normalization, \nwe can express $\\psi(x,t) = \\varphi(x) e^{-i\\frac{E t}{\\hbar}}$, up to a constant.\n\nEffectively, the states $\\psi(x,t)$ are *not-stationary but are evolving in time.*\n\nHowever, any measurable quantities, such as the *probability density* \n$|\\psi(x,t)|^2$ or the *expectation values of an observable*, \n$\\langle A\\rangle = \\int \\psi^*(x,t)A\\psi(x,t)\\ dx$ remain *time-independent*,\nsince $\\left (e^{-i\\frac{Et}{\\hbar}}\\right )^*e^{-i\\frac{Et}{\\hbar}}\\equiv 1$,\n$\\forall\\ t\\in\\mathbb{R}^+$. Therefore, all *stationary measurable quantities* \ndo not evolve with time\n\n$$\\psi^*(x,t)\\ \\psi(x,t) \\equiv \\underbrace{\\overbrace{e^{-i\\frac{E t}{\\hbar}}}^{scalar}\ne^{+i\\frac{E t}{\\hbar}}}_{1}\n\\underbrace{\\varphi^*(x) \\varphi(x)}_{time\\ independent}\\ .$$\n\nOf course, the *separable wavefunction solution* built from one energy eigenfunction, \n$\\psi (x,t)= \\varphi(x)f(t)$, represent only one particular class of solutions\nto the Schrodinger equation. There are many other potential solutions involving\nmore entangled (*non-separable*) spacetime functions whose shapes depend\non the particular form of the *potential energy* $V(x)$. \n\nTo describe more general TISE solutions, we can use a basis given by the \neigenfunctions of the Hamiltonian, $\\{\\varphi(x)\\}$. The eigenstate of the\nTISE Hamiltonian do not evolve. However we can write any wavefunction as superposition\nof the $\\{\\varphi(x)\\}$ base eigenstates given by the energy eigenfunctions\n\n$$\\psi(x,t) = \\sum_k \\underbrace{c_k(t)\\varphi_k(x)}_{space-time\\\\ separable}\\ .$$\nThe coefficients $c_k(t)$ can be obtained at any instant $t$ by taking the\n*inner product* $c_k(t)=\\langle \\varphi_k (x) |\\psi(x,t)\\rangle$. \nPlugging these in the Schrodinger equation \n$i\\hbar \\frac{\\partial \\psi(x,t)}{\\partial t} = H \\psi(x,t)$, we get\n\n\n$$i\\hbar \\frac{\\partial}{\\partial t} \\sum_k c_k(t)\\varphi_k(x)= \n\\sum_k c_k(t) H\\varphi_k(x)$$\n\n$$\\Longrightarrow i\\hbar  \\sum_k \\frac{\\partial}{\\partial t}c_k(t)\\varphi_k(x)= \n\\sum_k c_k(t) E_k\\varphi_k(x)\\ .$$\n\nFor each *base function* $\\varphi_k(x)$ we then have a corresponding *coefficient equation* \n\n$$i\\hbar  \\frac{\\partial}{\\partial t}c_k(t)= c_k(t) E_k\n\\Longrightarrow c_k(t)= c_k(0)e^{-i\\frac{E_k t}{\\hbar}}\\ .$$\n\nTherefore, a general solution of the Schrodinger equation is \n\n$$\\psi(x,t) = \\sum_k {c_k(0)e^{-i\\frac{E_k t}{\\hbar}}\\varphi_k(x)}\\ .$$\n\n**Remarks**\n\n - The energy eigenvalues (eigen-frequencies) $E_k=\\hbar \\omega_k$ indicate that the wavefunction is a superposition of waves $\\varphi_k(x)$ each with a different frequency $\\omega_k$ propagating in time. The behavior of quantum systems resembles wave propagation. Diffraction patterns formed by electrons scattering from a slit represent one instance of this wave superposition.\n\n - A special property only for the *energy eigenvalues*, not for other observables, is that the *probability of measuring a certain energy* $E_k$ at time $t$ is given by the squared amplitude of the coefficient of $\\varphi_k(x)$, $|c_k(t)|^2=\\left |c_k(0)e^{-i\\frac{E_k t}{\\hbar}}\\right |^2=|c_k(0)|^2 .$ Hence, the *probability for each measurable energy is constant*, i.e., the probability of an energy state does not depend on time. In other words, \n *energy is constant of the motion.* \n\n - *Example*: Suppose we are interested in estimating the probability of finding the system at a \ncertain position, $p(x) = |\\psi(x,t)|^2$, which varies with time. Let $\\psi(x,0) = c_1(0)\\varphi_1(x) + c_2(0)\\varphi_2(x)$, with $|c_1(0)|^2 + |c_2(0)|^2 = |c_1|^2 + |c_2|^2 = 1$, and $\\varphi_1,\\varphi_2$ normalized energy eigenfunctions. At time $t$, we have $\\psi(x,t) = c_1(0)e^{-i\\omega_1 t}\\varphi_1(x) + c_2(0)e^{-i\\omega_2 t}\\varphi_2(x)$ and we can compute $p(x,t)$\n\n$$p(x,t)= \\left | c_1(0)e^{-i\\omega_1 t}\\varphi_1(x) + c_2(0)e^{-i\\omega_2 t}\\varphi_2(x)\\right |^2\\\\\n=\\cdots = |c_1|^2+|c_2|^2 + \\underbrace{2Re\\left [c_1^*c_2\\ \\varphi_1^*\\varphi_2 e^{-i(\\omega_2-\\omega_1)t}\\right ]}_{wave\\ interference}\\ .$$\n\nThe *wave interference* term, $2Re\\left [c_1^*c_2\\ \\varphi_1^*\\varphi_2 e^{-i(\\omega_2-\\omega_1)t}\\right ]$, describes interactions between different \ncomponents of the initial wavefunction.\n\n - These expressions for the *time-dependent wavefunction* are only valid if the *potential energy is itself time-independent*. Otherwise, deriving closed-form solutions of the TISE are more difficult to obtain.\n\n## Unitary Evolution\n\n### TDSE - Time-Dependent Schrodinger Equation\n\nTime-dependent Schrodinger equation describes the evolution of a closed system, \nwhich is *unitary* (reversible) and the evolution is given by the equation\n\n$$i\\hbar \\frac{\\partial |\\psi(x,t)\\rangle}{dt} = H|\\psi(x,t)\\rangle\\ ,$$\nwhere $H$ is the Hamiltonian (energy operator) of the system represents an observable, and $|\\psi(x,t)\\rangle$ is the *state vector* of the quantum system. \nThe position-space wavefunction $\\psi (x,t)$ can be written as the inner product\nof a *time-dependent state vector* $|\\psi (x, t) \\rangle$ with convenient \n*position eigenstates* $| x\\rangle$\n\n$$\\psi (x,t)=\\underbrace{\\langle x|}_{position\\\\ eigenstate}\n\\underbrace{\\psi (t)\\rangle}_{\\ \\ time-dependent\\\\ \\ \\ state\\ vector}\\ .$$\n\nAgain, the time-dependent Schrodinger equation describes the longitudinal evolution\nof a quantum state.\n\n## Propagators\n\nThe *time-independent Schrodinger equation* is used to find the *stationary states* \nof a quantum system, which are unchanged over time. Stationary state solutions\nare associated with specific *energy levels* of the system. \n\nWe can express the evolution of a state $|\\psi(x,t)\\rangle$ in terms of a \n*unitary propagator operator*\n\n$$\\psi(x,t) = U(t)\\psi(x,0)\\ ,$$\nwhere the operator $U$ is unitary, $U^\\dagger U = \\mathbb{I}$. In general,\nthe unitary operator $U=U(x,t)$ could also be a function of space-time (not just time).\nLet's confirm that this state $\\psi(x,t) = U(t)\\psi(x,0)$ is a solution of \nthe to the Schrodinger equation \n$i\\hbar \\frac{\\partial |\\psi(x,t)\\rangle}{dt} = H|\\psi(x,t)\\rangle$ by plugging in\n$\\psi(x,t) = U(t)\\psi(x,0)$\n\n$$i\\hbar \\frac{\\partial}{dt}(U(t))\\underbrace{\\psi(x,0)}_{} = HU(t)\n\\underbrace{\\psi(x,0)}_{}\\ \\ \\Longrightarrow \ni\\hbar \\frac{\\partial U(t)}{dt}= HU(t)\\ .$$\n\nThe second step implication is valid since the equation holds\nfor $\\forall \\psi$ wavefunctions, and therefore, it holds for the unitary\noperator $U$. When the Hamiltonian is *time independent*, the solution of\nthe second TISE equation is\n\n$$i\\hbar \\frac{\\partial U(t)}{dt}= HU(t) \\ \\Longrightarrow\nU(t)=e^{-i\\frac{Ht}{\\hbar}}\\ ,$$\n\nwhere $U(t=0)=\\mathbb{I}$ and $U$ is unitary, since\n$U^\\dagger(t) U(t)=e^{i\\frac{Ht}{\\hbar}}\\ e^{-i\\frac{Ht}{\\hbar}}=\\mathbb{I}$.\n\n## Schrodinger vs. Heisenberg Picture\n\nThe [synergies between Schrodinger and Heisenberg pictures of quantum field theory (QFT) are clearly explicated in this article on operator-valued distributions in QFT](https://doi.org/10.48550/arXiv.1508.05908). \n\nThe Schrodinger and Heisenberg pictures only differ by a Hilbert space basis change \nwith respect to time-dependency. The Heisenberg picture utilizes an algebraic\nmatrix  mechanics formulation in an arbitrary basis where the Hamiltonian is not necessarily diagonal. The Schrodinger picture is useful with time-independent Hamiltonians where\n$\\partial_{t} H=0$ and the state of a system evolves with time, \n$|\\psi(t_0)\\rangle\\to |\\psi(t)\\rangle$ by the *time-evolution operator* \n$|\\psi (t)\\rangle =U(t,t_{0})|\\psi (t_{0})\\rangle$. \n\nThe [Stone–von Neumann theorem](https://en.wikipedia.org/wiki/Stone%E2%80%93von_Neumann_theorem) implies the *uniqueness of the canonical commutation relations between position and momentum operators*. That is, the theorem suggests *unitary equivalence* between the Heisenberg and \nthe Schrodinger pictures, i.e., the two formulations are related by a basis change\nin the Hilbert space.\n\n### Schrodinger Picture\n\nIn the [Schrodinger picture](https://en.wikipedia.org/wiki/Schr%C3%B6dinger_picture)\nformulation of quantum mechanics, *operators are constant*\nand the *states evolve in time.* At time $t$, the Schrodinger equation described a quantum state\nby $|\\psi(t)\\rangle =U(t)|\\psi(0)\\rangle$, where \n\n - the time-evolution operator, $U(t)=T\\ e^{-{\\frac{i}{\\hbar}} \\int_{0}^t dsH_{S}(s)}$, is induced by a (potentially) time-dependent Hamiltonian $H_{S}(t)$, \n - the initial state of the system is $|\\psi (0)\\rangle$, and\n - $T$ and $\\hbar$ are the time-ordering and the reduced Planck constant.\n\nIn the Schrodinger picture, the *expectation value* of any observable, $A_{S}(t)$,\nin the state $|\\psi (t)\\rangle$ is a Hermitian linear operator, $\\langle A\\rangle _{t}$, \nalso potentially time-dependent\n\n$$\\langle A\\rangle _{t}=\\langle \\psi (t)|A_{{S}}(t)|\\psi (t)\\rangle .$$\n\n### Heisenberg Picture\n\nThe [Heisenberg picture](https://en.wikipedia.org/wiki/Heisenberg_picture) of QM represents\n*operators and observables as time-dependent*, whereas the *state vectors are time-independent*.\n\nIn the Heisenberg picture, the observable operators evolve with time \n$A_{H}(t) = U^{\\dagger }(t)A_{S}(t)U(t)$, whereas quantum states remain constant \nwith time. Hence, the expectation value can be computed in either picture\n$\\langle A\\rangle_{t}=\\langle \\psi (0)|A_{H}(t)|\\psi (0)\\rangle$. \n\nThe time-dependent Schrodinger equation (TDSE) \n$\\frac{d}{dt}U(t)=-{\\frac {i}{\\hbar }}H_{S}(t)U(t)$ and using the product rule \nfor differentiation we get the *Heisenberg's equation of motion*\n\n$$\\begin{aligned}{\\frac{d}{dt}}A_{H}(t)&=\\left({\\frac {d}{dt}}U^{\\dagger }(t)\n\\right)A_{S}(t)U(t)+U^{\\dagger }(t)A_{S}(t)\\left(\\frac{d}{dt}U(t)\\right)+U^{\\dagger }(t)\n\\left({\\frac {\\partial A_{S}}{\\partial t}}\\right)U(t)\\\\&=\n{\\frac {i}{\\hbar }}U^{\\dagger }(t)H_{S}(t)A_{S}(t)U(t)-\\frac{i}{\\hbar}U^{\\dagger }(t)\nA_{S}(t)H_{S}(t)U(t)+U^{\\dagger }(t)\\left({\\frac {\\partial A_{S}}\n{\\partial t}}\\right)U(t)\\\\&={\\frac {i}{\\hbar }}U^{\\dagger }(t)H_{S}(t)U(t)U^{\\dagger }(t)\nA_{S}(t)U(t)-\\frac {i}{\\hbar}U^{\\dagger }(t)A_{S}(t)U(t)U^{\\dagger }(t)\nH_{S}(t)U(t)+\\left(\\frac {\\partial A_{S}}{\\partial t}\\right)_{H}\\\\&=\n\\frac {i}{\\hbar}[H_{H}(t),A_{H}(t)]+\\left(\\frac {\\partial A_{S}}{\\partial t}\n\\right)_{H}\\end{aligned}\\ .$$\n\nNote the synergies between the *Heisenberg* and the *Schrodinger Hamiltonians*\n$H_{S}(t)$ and $H_{H}(t)$. \n\n### Heisenberg Equation\n\nExamine the *time-derivative of expectation* ...\n\nThe [Heisenberg equation](https://en.wikipedia.org/wiki/Heisenberg_picture), \ndescribes the time evolution of operators and their relation to the \ntime-derivative of expectation values. In the Heisenberg picture, operators evolve \nwith time while states remain constant. \n\nWhen the Hamiltonian $H_{S}$ is time-independent, the time-evolution operator \n$U(t)=e^{-\\frac {i}{\\hbar }\\ t\\ H_{S}}$ yields the equivalence of the\nSchrodinger and the Heisenberg Hamiltonians, $H_{H}\\equiv H_{S}\\equiv H$, since \nin this case, $U( t )$ commutes with $H$. Thus,\n\n$$\\langle A\\rangle _{t}=\\langle \\psi (0)|e^{{\\frac {i}{\\hbar }}tH}A_{S}(t)\ne^{-{\\frac {i}{\\hbar }}tH}|\\psi (0)\\rangle $$\nand \n\n$$\\begin{aligned}{\\frac {d}{dt}}A_{H}(t) &= \\frac {i}{\\hbar }\n[H,A_{H}(t)] + \n\\underbrace{e^{\\frac {i}{\\hbar }tH}\\left(\n{\\frac {\\partial A_{S}}{\\partial t}}\\right)e^{-{\\frac {i}{\\hbar }}tH}}_\n{trivial,\\ 0}\\end{aligned}\\ ,$$\n\nsince $A_{S}\\equiv A$ is also time-independent. So, we get\n$$\\frac{d}{dt}A_{H}(t) = \\frac{i}{\\hbar } [H,A_{H}(t)]\\ ,$$\n\nwhere $A_{H}(t)\\equiv A(t)=e^{\\frac{i}{\\hbar }\\ t\\ H}\\ A\\ e^{-\\frac {i}{\\hbar}tH}$.",
      "word_count": 2082
    },
    {
      "title": "Wavefunctions, Kime-Functions, and Inference Functions",
      "content": "Recall from the [TCIU distributions section](https://www.socr.umich.edu/TCIU/HTMLs/Chapter3_DistributionTheory.html) that *test functions* $\\phi(\\theta)$ are *infinitely differentiable functions*\nthat either have *compact support* or their *tails are rapidly decreasing* (super-exponentially). We will extend the notion of *actions* of generalized functions $\\psi$ on test functions. This action is defined via *duality pairing*, \n$\\langle\\psi, \\phi\\rangle =\\int_{\\mathbb{R}}{\\psi^*(\\theta)\\phi(\\theta)}\\ d\\theta$.\n\nThe extension to *actions of separable kime-functions* \n$$\\mathfrak{P}(x,y,z,t,\\ \\theta)\\equiv \\underbrace{\\Psi(x,y,z,t)}_{classical\\ wavefunction}\\times \\underbrace{\\ell(\\theta)}_{kime-phase\\\\ distribution}:\\overbrace{\\mathbb{R}^3}^{{\\bf{x}}=(x,y,z)}\\times\n\\overbrace{\\mathbb{C}}^{\\kappa=t e^{i\\theta}} \\longrightarrow \\mathbb{C}$$\n\non *test functions* $\\phi$ is defined by\n\n$$\\underbrace{\\langle\\mathfrak{P}, \\phi\\rangle}_{kime-function\\\\ action} = \n\\overbrace{\\Psi(x,y,z,t)}^{spacetime\\\\ wavefunction}\n\\underbrace{\\int_{\\mathbb{R}}{\\ell^*(\\theta) \\phi(\\theta)}\\ \nd\\theta}_{\\underbrace{\\langle\\ell, \\phi\\rangle}_{kime-phase\\\\ action}\\in\\mathbb{C}}\\ .$$\n\nThe integral of the product of the *kime-phase distribution* $\\ell$ and the test function $\\phi$ represents the action of the kime-phase generalized function on the test function. This integral is an *aggregation function* weight-averaging all values of the test function against the corresponding kime-phase probability density function.\n\n**Note**: Whereas $\\theta\\in \\mathbb{R}$ and $\\ell$ is a univariate\n*kime-phase distribution*, its values are complex, as $\\ell$ is a function of $e^{i\\theta}=\\cos(\\theta)+ i \\sin(\\theta)$.\n\nThis suggests an *explicit relation between wavefunctions and kime-functions*, \nwhere actions of kime-functions on test-functions are just complex multiples of the wavefunctions. Since, wavefunctions are typically normalized to induce probabilistic interpretation of their magnitudes, this suggest the equivalence\n\n$$\\underbrace{\\langle\\mathfrak{P}, \\phi\\rangle}_{kime-function\\ action\\\\ on\\ test-function} = \n\\underbrace{c\\  \\Psi(x,y,z,t)}_{scaled\\ wavefunction}\\ ,\\ c \\in\\mathbb{C}\\ .$$\n\nExtending the classical notion of [generalized functions (distributions)](https://www.socr.umich.edu/TCIU/HTMLs/Chapter3_DistributionTheory.html), \n*kime-functions* can be considered as *generalized wavefunctions*, $\\Psi$, \nwhich describe the state of a QM system *by their action* on test-functions \n$\\varphi$ (outputting complex values) \n\n$$\\left \\langle \\overbrace{\\mathfrak{P}}^{kime-function} \\bigg\\rvert\n\\underbrace{\\varphi}_{test-function} \\right \\rangle \n\\underbrace {\\left (\\overbrace{x,y,z}^{\\bf{x}\\in\\mathbb{R}^3},\n\\overbrace{t,\\theta}^{\\kappa\\in\\mathbb{C}}\n\\right )}_{spacekime}: \\mathbb{R}^3\\times \\mathbb{C} \\longrightarrow \\mathbb{C}\\ .$$\n\nSince *kime-functions* are [linear functionals acting on test-functions](https://www.socr.umich.edu/TCIU/HTMLs/Chapter3_DistributionTheory.html),\nthey are elements of the *dual space* of the space of test functions, $D(\\Omega)$. \n\n - For any test functions $\\{\\varphi_1, \\varphi_2\\} \\in D(\\Omega)$ and \n$\\forall \\alpha , \\beta\\in\\mathbb{C}$, the mapping $T: D(\\Omega)\\to \\mathbb{C}$ should be *linear*\n\n$$T_{\\mathfrak{P}}(a\\varphi_1 + b\\varphi_2 )\\equiv \\langle \\mathfrak{P}, a\\varphi_1 +\nb\\varphi_2 \\rangle = \\alpha\\langle \\mathfrak{P}, \\varphi_1\\rangle + \\beta\\langle\n\\mathfrak{P},\\varphi_2\\rangle\\ .$$\n\n - The mapping $T_{\\mathfrak{P}}$, should also be *continuous*. For any test function $\\varphi \\in D(\\Omega)$ and a corresponding sequence of test functions $\\{ \\varphi_{n} \\} \\in D(\\Omega)$ with \n \n$$\\varphi_n\\underset{n\\to\\infty}{\\stackrel{D}\\longrightarrow}\\varphi \\ \\ \n\\Longrightarrow T_{\\mathfrak{P}}(\\varphi_n)\\underset{n\\to\\infty}{\\longrightarrow} T_{\\mathfrak{P}}(\\varphi)\\ .$$\n\nDenote $T_{\\mathfrak{P}} = \\langle \\mathfrak{P}, \\cdot \\rangle$, which is a linear and continuous mapping from $D$ to the real or complex numbers. \n\nThe following argument *does not really make sense*, as it does not account for kime, \n$\\kappa=te^{i\\theta}$,\n\n$$\\underbrace{\\mathfrak{P}}_{kime-function} (x,y,z, t,\\theta): \n\\underbrace{\\alpha\\phi+ \\beta\\psi}_{superposition\\ of\\\\ test\\ functions} \n\\longrightarrow \n\\alpha \\langle \\mathfrak{P}({\\bf{x}})\\ ,\\ \\phi ({\\bf{x}}) \\rangle +\n\\beta \\langle \\mathfrak{P}({\\bf{x}})\\ ,\\ \\psi ({\\bf{x}}) \\rangle\\\\ =\n\\underbrace{\\alpha \\int_{\\mathbb{R}^3} {\\mathfrak{P}({\\bf{x}})\\ \\phi ({\\bf{x}})\\ d{\\bf{x}}}+\n\\beta \\int_{\\mathbb{R}^3} {\\mathfrak{P}({\\bf{x}})\\ \\psi \n({\\bf{x}})\\ d{\\bf{x}}}}_{\\in\\ \\mathbb{C}}\\ ,\\ \\forall\\ \\alpha,\\beta\\in \\mathbb{C}\\ .$$\n\n**Definition**: *Inference-functions*, or *kime-inference-functions*, \ndenoted by Fraktur-format Latin letters\n$$\\mathfrak{A,B,C,D,E,F,G,\\cdots, P, Q, R, S, T, U, V, W, X, Y,Z}$$\nare a special kind of *kime-functions*, which are separable as products of \n*wavefunctions* over spacetime, denoted by *capital* Greek symbols, \n$\\{\\Psi, \\Phi, \\Xi, \\cdots\\}$, and \n*generalized-functions (kime-phase distributions)*, $\\ell(e^{i\\theta})$. \n\nIndeed, kime *inference-functions* are in the dual-space of the Hilbert space of\ntest functions, i.e., kime *inference-functions* act on test functions as follows:\n\n$$\\underbrace{\\mathfrak{P}}_{inference-function\\\\ (Fraktur-P)} \\left (\\underbrace{x,y,z}_{{\\bf{x}},\\ space}, \n\\underbrace{t,\\cdot}_{kime,\\ \\kappa=te^{i\\theta}}\\right )\\underbrace{\\equiv}_{separability}\n\\overbrace{\\Psi({\\bf{x}},t)}^{wavefunction}\\underbrace{\\ell(\\cdot)}_{phase\\\\ distrib.} \n\\ \\ {\\text{  acting on  }}\\ \\ \n\\underbrace{\\alpha\\phi+ \\beta\\psi}_{superposition\\ of\\\\ test\\ functions}, \\\\ \n\\\\ \n\\Longrightarrow \\mathfrak{P}({\\bf{x}},\\kappa)\\ (\\alpha\\phi+ \\beta\\psi) \\equiv \\Psi({\\bf{x}},t) \\left [\\ell(\\cdot)\\ (\\alpha\\phi+ \\beta\\psi)\\right ]\\ =\\  \n\\underbrace{\\alpha\\Psi({\\bf{x}},t)}_{scalar\\ \\in\\ \\mathbb{C}} \n\\left\\langle \\ell(\\cdot)\\ ,\\ \\phi  \\right\\rangle +\n\\underbrace{\\beta\\Psi({\\bf{x}},t)}_{scalar\\ \\in\\ \\mathbb{C}}  \n\\left\\langle \\ell(\\cdot)\\ ,\\ \\psi  \\right\\rangle\\\\ =\n\\underbrace{\\alpha\\Psi({\\bf{x}},t) \\int_{\\mathbb{R}} {\\ell^*(e^{i\\theta})\\ \\phi (\\theta)\\ d\\theta}+\n\\beta \\Psi({\\bf{x}},t) \\int_{\\mathbb{R}} {\\ell^*(e^{i\\theta})\\ \\psi (\\theta)\\ d\\theta}}_{\\in\n\\ \\mathbb{C}}\\\\\n= \\left (\\underbrace{\\alpha \\int_{\\mathbb{R}} {\\ell^*(e^{i\\theta})\\ \\phi (\\theta)\\ d\\theta}}_{\\in\n\\ \\mathbb{C}} +\n\\underbrace{\\beta \\int_{\\mathbb{R}} {\\ell^*(e^{i\\theta})\\ \\psi (\\theta)\\ d\\theta}}_{\\in\n\\ \\mathbb{C}}\\right ) \\ \\Psi({\\bf{x}},t) \\\\\n= \\left (\\alpha \\left\\langle \\ell(\\cdot) \\ ,\\ \\phi  \\right\\rangle +\n\\beta \\left\\langle \\ell(\\cdot) \\ ,\\ \\psi  \\right\\rangle\n\\right )\\ \\Psi({\\bf{x}},t) \\\\\n= \\left\\langle \\ell(\\cdot) \\ ,\\ \\alpha \\psi +\\beta\\psi \\right\\rangle\n\\ \\Psi({\\bf{x}},t) =\\Psi({\\bf{x}},t) \\left\\langle \\ell(\\cdot) \\ ,\\ \\alpha \\psi +\n\\beta\\psi \\right\\rangle,\\ \\forall\\ \\alpha,\\beta\\in \\mathbb{C}\\ .$$\n\nTo simplify the notation, we can suppress the subscript of the wavefunction $\\Psi$, \nsince technically speaking the *kime inference-function* and the corresponding\n*wavefunction* are linked via the *phase-distribution*, $\\ell(\\cdot)$,\n\n$$\\mathfrak{P}\\underbrace{(\\cdot,\\cdot)}_{spacekime}= \\Psi\\underbrace{(\\cdot,\\cdot)}_{spacetime}\n\\ell\\underbrace{(\\cdot)}_{kime-phase}\\ , \\ \\ \n\\Psi({\\bf{x}},t)\\equiv \\Psi_{\\mathfrak{P}}({\\bf{x}},t)\\ .$$\n\nRecall from the [TCIU Distribution Theory Section](https://www.socr.umich.edu/TCIU/HTMLs/Chapter3_DistributionTheory.html) that \nthe *class of test functions* operated on by distributions can vary. Examples include:\n\n - A class of test functions representing the *space of infinitely differentiable functions with compact support*, $\\mathcal{C}_c^{\\infty}(\\mathbb{R})$. \n - In Fourier analysis, the set of *Schwartz functions* \n\n$$\\mathcal{S}(\\mathbb{R^n})=\\{f\\in C^{\\infty}(\\mathbb{R^n}):\n||f||_{\\alpha,\\beta}<\\infty \\,, \\forall \\alpha, \\beta\\} \\tag{1}$$\n\n&nbsp; represents another useful class of natural test functions consisting of all *infinitely differentiable functions of rapid decay*, i.e., functions $\\phi$ such that $x^n \\phi(x)\\underset{x\\to\\pm\\infty}{\\longrightarrow} 0,\\ \\forall\\ n\\in\\mathbb{N}$. This rapid decay conditions guarantees that the Fourier transforms of Schwartz functions are also Schwartz functions. \n\n## Examples\n\n### Example 1: Kime-Phase Distribution Multiplication by a Function\n\nConsider the *product* of a generalized function $\\ell(e^{i\\theta})$ \n(kime-phase distribution) and a given function $f(\\cdot)$. This product $f\\ell$ is\ndefined in terms of its action on any test function $\\phi\\in\\mathcal{D}(\\Omega)$: \n\n$$\\left \\langle \\underbrace{f\\ \\ell}_{product}(e^{i\\theta}),\\ \\phi\\right \\rangle \\equiv \\langle \\ell(e^{i\\theta}),f\\ \\phi\\rangle,\n\\ \\ \\ \\forall \\phi\\in\\mathcal{D}(\\Omega)\\Longrightarrow \n\\underbrace{f\\ \\phi}_{product}\\in\\mathcal{D}(\\Omega).$$\n\nThis implies that the action of the (product) *distribution* $f\\ \\ell(e^{i\\theta})$ on a test function $\\phi$ is identical to the action of the distribution $\\ell(e^{i\\theta})$ on \n(the modified product) test function $f\\ \\phi$. For instance, suppose\n$f(x)$ is a *smooth function* and the phase distribution is just the Dirac delta\n$\\ell(e^{i\\theta}):=\\delta(\\theta)$. Then, the product \n$f\\ \\ell\\equiv f(\\theta)\\delta(\\theta)$ acts on any test function $\\phi\\in\\mathcal{D}(\\Omega)$ \nby evaluating the product of $f$ and $\\phi$ at the origin ($\\theta=0$)\n\n$$\\langle f(\\theta)\\ \\ell(e^{i\\theta}),\\ \\phi(\\theta) \\rangle =\n\\langle \\delta(\\theta),\\ f(\\theta)\\ \\phi(\\theta)\\rangle = f(0)\\ \\phi(0).$$\n\n### Example 2: Principal Value Distribution\n\nA more nuanced example of a *generalized phase function* is the \n[Cauchy principal value distribution](https://en.wikipedia.org/wiki/Cauchy_principal_value),\n$\\ell(\\theta)\\equiv\\mathcal{P}\\left (\\frac{1}{\\theta}\\right )$, defined as the Cauchy principal \nvalue of the function $\\frac{1}{\\theta}$, which is not Lebesgue/Riemann integrable over\n$\\theta\\in\\mathbb{R}$. The *Cauchy principal value phase-distribution* acts on\na test function $\\phi(\\theta)$ by\n\n$$\\langle \\ell(e^{i\\theta}),\\ \\phi(\\theta) \\rangle =\n\\left \\langle \\mathcal{P}\\left (\\frac{1}{\\theta}\\right ),\\ \\phi(\\theta)\n\\right \\rangle = \\lim_{\\epsilon\\to 0}{\\int_{|\\theta|\\gt\\epsilon}{\\frac{\\phi(\\theta)}{\\theta}\\ \n\\ d\\theta}}\\ .$$\n\nOne application of the Cauchy principal value phase-distribution is to compute or estimate\ndefinite integrals that would otherwise not be well-defined, e.g., in this case\ndue to a singularity at the origin $\\theta=0$. Recall the\n[L'Hopital's rule](https://en.wikipedia.org/wiki/L%27H%C3%B4pital%27s_rule),\nwhich allows us to estimate the value of the integral near the origin, \n$$\\int_{|\\theta|\\lt\\epsilon}{\\frac{\\phi(\\theta)}{\\theta}\\ \n\\ d\\theta},\\ \\ \\ \\lim_{\\epsilon\\to 0}{\\frac{\\phi(\\theta)}{\\theta}}\n\\underbrace{=}_{\\text{L'Hopital}} \\lim_{\\epsilon\\to 0}{\\frac{\\phi'(\\theta)}{\\theta'}}=\n\\lim_{\\epsilon\\to 0}{\\frac{\\phi'(\\theta)}{1}}=\\lim_{\\epsilon\\to 0}\\phi'(\\theta)\\ .$$\n\n### Example 3: Sign Function\n\nThe *sign generalized function (distribution)* \n$$sgn(\\theta)\\equiv \\begin{cases} \n      -1 &,\\ \\theta\\leq 0 \\\\\n      0 &,\\ \\theta=0 \\\\\n      +1 &,\\ \\theta\\ge 0 \n   \\end{cases}$$\n\nacts on test functions $\\phi(\\theta)$ by weight-averaging (or convolving) the \ntest function by the sign function\n\n$$\\langle \\ell(e^{i\\theta}),\\ \\phi(\\theta) \\rangle =\n\\left \\langle sgn (\\theta),\\ \\phi(\\theta) \\right \\rangle =\n\\int_{\\mathbb{R}}{sgn(\\theta)\\ \\phi(\\theta) \\ d\\theta}\\\\\n= \\int_{0}^{\\infty}{\\phi(\\theta) \\ d\\theta}-\\int_{-\\infty}^{0}{\\phi(\\theta) \\ d\\theta} \\ .$$\n\nClearly, for *symmetric* test functions, $\\phi(-\\theta)=\\phi(\\theta)$, this action is trivial, \n$\\langle \\ell,\\ \\phi \\rangle =0$.\n\n\n### Example 4: Laplace Distribution\n\nLet's consider the action of the [Laplace distribution, aka, double exponential distribution](https://en.wikipedia.org/wiki/Laplace_distribution) with \nlocation ($\\mu\\in\\mathbb{R}$) and scale $b\\in\\mathbb{R}^+$ parameters\n\n$$\\ell_{\\mathcal{L}}(\\theta \\mid \\mu, b) = \\frac{1}{2b} e^{\\left( -\\frac{|\\theta - \\mu|}{b} \\right)}$$\n\non test functions $\\phi$:\n\n$$\\langle \\ell_{\\mathcal{L}},\\ \\phi \\rangle =\n\\frac{1}{2b} \\int_{\\mathbb{R}}{e^{-\\frac{|\\theta - \\mu|}{b}}\\ \\phi(\\theta) \\ d\\theta} \\ .$$\n\n**Problem**: Work out the details for some simple test-functions ....\n\n\n## Connection to Quantum Field Theory (QFT) and Operator-Valued Distributions\n\nRecall that *probability distributions* are mathematical abstractions (models) that\nfacilitate *generative (statistical) inference* and *random drawing* (sampling) of measurable observations from various processes. A probability distribution \nthemselves cannot be (holistically) observed, but samples from each distribution \nare observable. \n\nSimilarly, *quantum fields* are mathematical abstractions (models) providing \nmechanisms for *organizing*, *tracking the evolution*, and explicating \n*generators of the algebra of observables*. Quantum fields are \n*not themselves directly observable* - the corresponding \n*actual observables* are their actions on *test functions*, e.g.,\n$\\varphi(f)\\in\\mathbb{C}$, rather than $\\varphi$.\n\nSuppose $\\mathcal{H}$ is a [Hilbert space](https://en.wikipedia.org/wiki/Hilbert_space), a Euclidean vector space over $\\mathbb{R}^3$ representing the states of a quantum particle. The particle \nspatiotemporal dynamics are in $\\mathbb{R}^3\\times\\mathbb{R}^+$ and \n$\\mathcal{H}=L_2(\\mathbb{R}^3)$. For quantum systems with multiple identical particles, this extends to [Fock spaces](https://en.wikipedia.org/wiki/Fock_space). \nOften for simplification, we consider single-particle systems with \n\n$$\\mathcal{H}=L_2(\\mathcal{X}=\\mathbb{R}^3, measure=\\mu=d^{3}{\\bf{x}}))$$ \n\nrepresenting the space of *square-integrable functions*. Of course, this is a\nmeasure-theoretic representation where objects in $\\mathcal{H}$ are actually\n*equivalence classes* of square integrable functions, not functions themselves. \nRecall that many different functions in $L_2$ are *equivalent*, e.g., when they \ndiffer on a set of measure zero. The more general\nFock spaces ($n$ particles) include symmetric or antisymmetric square integrable functions, commonly denoted by $Sym(\\mathcal{H})$, is a quotient space of \nequivalence classes of functions in the tensor algebra \n$\\bigoplus_{n \\in \\mathbb{N}} \\mathcal{H}^{\\otimes n}.$\n\nFor *single particle* systems, states are unit vectors $\\psi\\in \\mathcal{H}$,\n*observables* are *self-adjoint bounded operators* $T$ on $\\mathcal{H}$\nwhose expectation values in the state $\\psi$ are equal to \n$\\langle T\\rangle\\equiv \\langle \\psi|T|\\psi\\rangle\\in \\mathbb{C}.$\nMore specifically, *pure states* are points in the [projective space](https://en.wikipedia.org/wiki/Projective_space) \n$\\mathbb{P}\\mathcal{H}$ representing *hyper-lines* in $\\mathcal{H}$ as equivalence classes of unit vectors modulo a phase factor (random kime-phase). \nConsider a $C^*$ algebra $\\mathcal{A}$ of the bounded operators on $\\mathcal{H}$.\nThen, states are linear functionals $\\langle\\cdot\\rangle:\\mathcal{A}\\to\\mathbb{C}$\nsatisfying two conditions: $\\langle \\mathbb{I} \\rangle=\\mathbb{I}$ and \n$\\langle AA^* \\rangle\\in\\mathbb{R},\\ \\forall A\\in \\mathcal{A}$. \nThis definition ensures that a linear superposition of states is another state\nin the Hilbert space and all pure states are of the form \n$\\langle \\psi|\\cdot| \\psi\\rangle .$\n\nFor systems with *multiple particles*, *states* are elements of $Sym(\\mathcal{H})$\nand *observables* are self-adjoint (Hermitian) bounded operators on the\nHilbert space $Sym(\\mathcal{H})$ of the states. Given a single particle state\n$\\psi$, an example of a two-particle state is the element $\\frac{1}{\\sqrt{2}}\\psi\\otimes \\psi \\in Sym(\\mathcal{H})$.\n\nWhereas in *quantum mechanics* we compute using unit vectors and self-adjoint operators,\nin *quantum field theory* the calculations are done on *operator-valued distributions*,\ni.e., the Hilbert space $Sym(\\mathcal{H})$ of the multi-vector states. The \noperator-valued distribution's action of a quantum field $\\Phi$ on a\ntest function $f({\\bf{x}}),\\ {\\bf{x}}\\in\\mathbb{R}^3$ is a Hermitian\noperator $\\Phi$ on $Sym(\\mathcal{H}).$ Thus, the quantum fields are *operator-valued distributions*, not just states on $Sym(\\mathcal{H}).$\n\nThe *Hilbert space itself a mathematical abstraction*, not a physical object. On\nthe other hand, the *algebra of observables is physical* as all real-measurements\nare either (atomic) pure states, or superpositions of pure states and all\n*AI/ML/statistical inference* and *predictions* are based on such physical \nmeasurements (data-driven inference). The Hilbert spaces are the abstract \nmathematical models of more tangible physical systems. \nAlso, the Hilbert space models are unique up to isomorphisms \nreflecting kime-phase uncertainty, e.g., reflecting quantum fluctuation effects\non measurable observations.\n\nIn QFT, a multi-particle Hilbert space is a Fock space, \n$\\mathcal{H}_{{many}\\choose{particles}} = Sym\\left(\\mathcal{H}_{{single}\\choose{particles}}\\right),$ where the natural physical class of Hermitian operators\npreserve some *locality.* For instance, such operators shrink or expand\nthe support by $\\varepsilon$ or temper the tails of the test functions at\ninfinity (e.g., ensure super-exponential decay). These \n$\\mathcal{H}_{{many}\\choose{particles}}$ operators are defined at any spacetime location \nresembling the definition of classical quantum mechanics operators that can\nbe measured at any spacetime location.\n\nIn a [Gedankenexperiment](https://en.wikipedia.org/wiki/Einstein%27s_thought_experiments), assume we can track/observe a system state\ncharacteristic at any spacetime location. Operators evaluate the \nvalues of the measurable characteristics of the quantum field. Consider\nthe full Hilbert space example with a pair of *creating* and *annihilating* \nquantum field operators. *Functional operators* on $\\mathcal{H}_{{many}\\choose{particles}}$ \ntransform given spacetime locations, $\\mathbb{R}^3$, into classical\nquantum mechanical operators, i.e., bounded Hermitian operators on \n$\\mathcal{H}_{{many}\\choose{particles}}$ complex-value (scalar) outputs. \n\nWe have to utilize *distributions*, rather than *functions*, to ensure that\nuncertainty and commutator relations can be expressed in terms of *Dirac* $\\delta$ *distribution*, i.e., in $\\mathbb{R}^3$, $\\delta(\\cdot)=\\delta^3(\\cdot).$ \nFor instance, if $p,q\\in\\mathbb{R}^3$ are two canonically conjugate quantum fields, \nthe corresponding *commutator*, $[\\cdot,\\cdot]$, of the *creation* $a$ and \n*annihilation* $a^{\\dagger}$ operators is\n\n$$\\underbrace{[a(p), a^{\\dagger}(q)]}_{commutator}=\n\\underbrace{(2\\pi)^3\\delta^3(p - q)\\ \\mathbb{I}}_{distribution}\\ ,$$\nand\n\n$$[a(p), a(q)] = 0\\ \\ , \\ \\  [a^{\\dagger}(p), a^{\\dagger}(q)] = 0\\ ,$$\nwhere for a pair of operators $A,B\\in\\mathcal{H}_{{many}\\choose{particles}}$, $[A,B]:=AB-BA$, and $\\mathbb{I}$ is the *identity operator* on the Hilbert space\n$\\mathcal{H}_{{many}\\choose{particles}}$.\n\nThis implies that the fields $\\{p,q\\}$ must also be *distributions.* Similarly \nfor spacetime fields, representing Fourier transformations\nof the *creation* and *annihilation* operators, whose time-ordered \n[Green's function, i.e., correlation function, or correlator](https://en.wikipedia.org/wiki/Correlation_function_(quantum_field_theory)),\nwill also be a Dirac $\\delta$ distribution. Therefore, the spacetime fields \nare *operator-valued distributions*, rather than functions.\n\n[An introduction to operator-valued distributions and the relevant Hilbert spaces is provided in this QFT book](https://souravchatterjee.su.domains/qft-lectures-combined.pdf).\n\n## Kime Unitary Operators\n\n**Definition 1**: A *unitary linear operator* $U :\\mathcal{H}\\to\\mathcal{H}$ has the property\n$||U\\psi|| = ||\\psi||,\\ \\forall\\ \\psi\\in\\mathcal{H}$.\n\n**Definition 2**: A *strongly continuous unitary group* $\\{U_t\\}_{t\\in\\mathbb{R}}$\nis a collection of unitary operators such that\n\n - $U_{t_1+t_2} = U_{t_1}\\ U_{t_2},\\ \\forall\\ t_1,t_2\\in\\mathbb{R}$, and\n - $\\forall\\ \\psi \\in\\mathcal{H}$, the $\\mathbb{R}\\to\\mathbb{C}$ mapping $t \\mapsto U_t(\\psi)$ is continuous.\n\n**Definition 3**: A *kime continuous unitary group* \n$\\{U_{\\kappa}\\}_{\\kappa\\in\\mathbb{C}}$ is a collection of unitary operators such that\n\n - $U_{\\kappa_1 \\cdot \\kappa_2} = U_{\\kappa_1}\\cdot U_{\\kappa_2},\\ \\forall\\ \\kappa_1,\\kappa_2\\in\\mathbb{C}$, and\n - $\\forall\\ \\psi \\in\\mathcal{H}$, the $\\mathbb{C}\\to\\mathbb{C}$ mapping $\\kappa \\mapsto U_{\\kappa}(\\psi)$ is continuous.\n \n\n### Stone - von Neumann Theorem\n\nThe [Stone - von Neumann theorem](https://en.wikipedia.org/wiki/Stone%27s_theorem_on_one-parameter_unitary_groups) establishes a one-to-one correspondence between \n*self-adjoint operators on a Hilbert space* $\\mathcal {H}$ and \n*one-parameter families of continuous unitary operators* $\\{U_{t}\\}_{t\\in \\mathbb {R}}$:\n\n$$(1)\\ \\ \\forall t_{o}\\in \\mathbb {R} ,\\ \\psi \\in {\\mathcal {H}}:\\ \\lim _{t\\to t_o}U_{t}(\\psi )=U_{t_o}(\\psi),$$\n$$(2)\\ \\ \\forall s,t\\in \\mathbb {R} :\\ U_{t+s}=U_{t}U_{s}\\ .$$\n\nA [historical perspective of the Stone-von Neumann theorem is presented in this article, *A Selective History of the Stone-von Neumann Theorem*](https://www.math.umd.edu/~jmr/StoneVNart.pdf).\n\nThis theorem supports a constructive definition of the *derivative of continuous unitary operators* \n$t\\mapsto U_t$, see the $5$th QM postulate below.\n\nThe one-to-one correspondence between *one parameter strongly continuous unitary groups of operators*\n$U^A :\\mathcal{H}\\to\\mathcal{H}$ and *self-adjoint operators* \n$A^U :\\mathcal{H}\\to\\mathcal{H}$ is given by\n\n$$A^U\\ \\psi = \\lim_{t\\to 0}{\\frac{U^A_t(\\psi) - \\psi}{it}}\\\\\nU^A_t=e^{itA^U}\\ .$$\n\nDenote the *domain* of $A$ by \n\n$$D(A) = \\left \\{\\psi\\in\\mathcal{H}: \\lim_{t\\to 0}{\\frac{U_t(\\psi)-\\psi}{it}}\\ {\\text{exists}}\\right \\}\\ .$$\nConversely, for any self-adjoint operator $A^o$, there exists a strongly\ncontinuous unitary group $\\{U^{A^o}_t\\}_{t\\in\\mathbb{R}}$, such that this relation\nbetween the operator $A^o$ and the unitary group $U^{A^o}$ is satisfied on the domain of $A^o$.\n\n[See this Physics Stack-Exchange discussion about a generalization of the Stone-von Neumann Theorem over kime](https://physics.stackexchange.com/questions/802005/complex-extension-of-the-stone-von-neumann-theorem),\nas well as [this Math-Physics Stack-Exchange example of defining strongly-continuous projective unitary representations of $\\mathbb{C}$ on $L^2(\\mathbb{R},dx)$](https://math.stackexchange.com/questions/4865565/complex-extension-of-the-stone-von-neumann-theorem) by\n\n<!-- https://physics.stackexchange.com/questions/780863/relation-between-stone-von-neumann-theorem-and-bargmanns-theorem?rq=1 -->\n\n$$\\mathbb{C}\\cong \\mathbb{R}^2\\ni (a,b)\\mapsto U(a,b) := e^{i(\\overline{aX - i b \\frac{d}{dx}})},$$\n\n$$\\mathbb{C}\\cong \\mathbb{R}^2\\ni (a,b)\\mapsto V(a,b) := e^{i(\\overline{aX - i 2b \\frac{d}{dx}})}.$$\n\n### Kime generalization\n\n**Problem**: Explore transforming the *additive group* over $t\\in\\mathbb{R}$ to a \n*multiplicative group* $\\kappa=te^{i\\theta}\\in\\mathbb{C}$, where $\\forall\\ \\psi\\in\\mathcal{H}$, the $1:1$ correspondence between \n*one parameter kime continuous unitary groups of operators*, i.e., \n*operator-valued distributions*, $U^A :\\mathcal{H}\\to\\mathcal{H}$ and \n*self-adjoint operators* \n$A^U :\\mathcal{H}\\to\\mathcal{H}$ is given by\n\n$$\\overbrace{A^U \\psi}^{operator-valued\\\\ distribution} = \\lim_{t\\equiv|\\kappa|\\to 0}{\\frac{U^{A^U}_{\\kappa}(\\psi) - \\psi}{it}}\\\\\n\\overbrace{U^{A^U}_{\\kappa}\\underbrace{(\\varphi)}_{test\\\\ function}}^{kime\\ unitary\\ operator}=\n\\underbrace{e^{-itA^U}}_{operator} \\ \\ \\underbrace{\\ell\\left(e^{i\\theta}\\right)}_{distribution} \\varphi\\ ,$$\n\nwhere the action of the *kime-inference function on test functions*,\n$\\langle\\mathfrak{P}, \\phi\\rangle,$ is defined by the kime-phase action on \ntest functions, $\\langle\\ell, \\phi\\rangle = \\int_{\\mathbb{R}}{\\ell^*(\\theta) \\phi(\\theta)}\\ d\\theta \\in\\mathbb{C}$,\n\n$$\\underbrace{\\langle\\mathfrak{P},\n\\phi\\rangle}_{kime-function\\\\ action} =\n\\overbrace{\\Psi(x,y,z,t)}^{spacetime\\\\ wavefunction}\n\\underbrace{\\int_{\\mathbb{R}}{\\ell^*(\\theta) \\phi(\\theta)}\\\nd\\theta}_{\\underbrace{\\langle\\ell, \\phi\\rangle}_{kime-phase\\\\\naction}\\in\\mathbb{C}}\\ .$$\n\nTechnically, $\\ell(\\theta)\\equiv \\ell(e^{i\\theta})$.\n\nThese one parameter kime unitary operators $\\{U_{\\kappa}\\ |\\ \\kappa\\in\\mathbb{C} \\}$ are *continuous*\n$$\\forall \\kappa_{o}\\in \\mathbb {C} ,\\ \\psi \\in {\\mathcal {H}}:\\ \\lim _{\\kappa\\to \\kappa_o}U_{\\kappa}(\\psi )=U_{\\kappa_o}(\\psi),$$\n\nTo simplify all notation, we will be suppressing the extra (unnecessary) superscripts\nsignifying the $U\\equiv U^{A^U} \\longleftrightarrow A^U\\equiv A$ correspondence.\n\n$$\\forall \\kappa_1=t_1e^{i\\theta_1},\\ \\kappa_2=t_2e^{i\\theta_2}\\in \\mathbb {C} ,\\\\ U_{\\kappa_1\\cdot \\kappa_2}=\nU_{t_1e^{i\\theta_1}\\cdot t_2e^{i\\theta_2}} = U_{t_1 t_2 e^{i(\\theta_1+\\theta_2)}} =\n\\underbrace{e^{-i(t_1 t_2)A}}_{operator} \\ \\ \\underbrace{\\ell\\left(e^{i(\\theta_1+\\theta_2)}\\right)}_{distribution}\\\\\n\\overbrace{=}^{\\theta_1\\perp \\theta_2\\\\ \\ell,\\ separable} \\underbrace{e^{-i(t_1)A}\\ \\ell_1\\left(e^{i\\theta_1}\\right)}_{U_{\\kappa_1}} \\ \\ \\underbrace{e^{-i(t_2)A}\\ \\ell_2\\left(e^{i\\theta_2}\\right )}_{U_{\\kappa_2}}=\nU_{\\kappa_1}U_{\\kappa_2}.$$\n\nRecall that $\\forall\\ \\kappa=te^{i\\theta}\\in\\mathbb{C},$ $U_{\\kappa}$ \nis an *operator-valued distribution* acting on *test functions*\n$\\varphi\\in\\mathcal{H}$ and producing complex scalars\n\n$$\\underbrace{U_{\\kappa_1\\cdot \\kappa_2}(\\varphi)}_{\\in\\mathbb{C}}=\nU_{\\kappa_1}(\\varphi) \\cdot U_{\\kappa_2}(\\varphi)\\ .$$\n\nTo explicate the kime-dynamics of states at any kime $\\kappa\\in\\mathbb{C}$,\nconsider an initial state $|\\varphi_{\\kappa_o}\\rangle$. Without loss of generality, we can assume that $\\kappa_o=te^{i\\theta}=0$, i.e., $t=0$. So, the starting\ninitial state is $|\\varphi_{\\kappa_o}\\rangle\\equiv |\\varphi_{o}\\rangle$.\n\nAs the state at kime $\\kappa\\in\\mathbb{C}$ is measurable, the temporal dynamics\nof the system can be expressed in terms of the kime unitary operator group action\n\n$$|\\varphi_{\\kappa}\\rangle=U_{\\kappa}(|\\varphi_{o}\\rangle)=\n\\underbrace{e^{-i t A}}_{operator} \\ \\ \\underbrace{\\ell\\left(e^{i\\theta}\\right)}_{distribution} (|\\varphi_{o}\\rangle)\\ ,$$\n\nwhere $\\ell\\left(e^{i\\theta}\\right)$ is a (prior) model of the kime-phase distribution, which can be *sampled once* for single observations, or \n*sapled multiple times* corresponding to multiple *repeated measurements.*\n\nTaking the partial derivative of $|\\varphi_{\\kappa}\\rangle$ with respect to\nthe *kime-magnitude* (*time*, $t$) yields the *kime-Schrodinger equation*\n\n$$\\frac{\\partial |\\varphi_{\\kappa}\\rangle}{\\partial t}=-iA\n\\underbrace{\\ \\ |\\varphi_{\\kappa}\\rangle\\ \\ }_{\\left (e^{-i t A}\\right )\n\\ell\\left(e^{i\\theta}\\right) (|\\varphi_{o}\\rangle)} \\ .$$\n\nFor instance, consider a *free evolution* (no external forces), \nwhere we are modeling the *energy (Hamiltonian) kime-evolution* of the \nstate of a particle of mass $m$ in $1D$. Assume only *kinetic energy* $K$ \nis at play, without *potential energy*, $V=0$. Then, the energy \n*Hamiltonian operator* $H=A$ is self-adjoint\n\n$$A\\equiv H=-\\frac{1}{2m}\\frac{d^2}{dx^2}\\ .$$\n\nIn this case, the explicit form of the *kime-independent Schrodinger equation*\ndescribing the *physical state of a quantum-mechanical system* is\n\n$$\\frac{\\partial |\\varphi_{\\kappa}\\rangle}{\\underbrace{\\partial t}_{t=|\\kappa|}}=-iA\n\\underbrace{\\ \\ |\\varphi_{\\kappa}\\rangle\\ \\ }_{\\left (e^{-i t A}\\right )\n\\ell\\left(e^{i\\theta}\\right) (|\\varphi_{o}\\rangle)} =\n+i\\frac{1}{2m}\\frac{\\partial^2}{\\partial x^2} |\\varphi_{\\kappa}\\rangle\\ .$$\n\nFor simplicity, here we are working with normalized units, $c=\\hbar = 1$. In the more general $3D$ kinetic energy (free potential) case, the system Hamiltonian is\n\n$$A\\equiv H=-\\frac{h{^2}}{8\\pi{^2}m}\\left(\\underbrace{\\dfrac{\\partial{^2}}\n{\\partial{x^2}}+\\dfrac{\\partial{^2}}{\\partial{y^2}}+\\dfrac{\\partial{^2}}\n{\\partial{z^2}}}_{Laplacian,\\ \\nabla^2}\\right)\\ .$$\n\nThis *kime-independent Schrodinger equation* has an explicit solution\n$$|\\varphi(\\kappa)\\rangle = \\left (e^{-i t E}\\right )\n\\ell\\left(e^{i\\theta}\\right) (|\\varphi_{o}\\rangle)\\ ,$$\n\nwhere $E$ represent observable energies. Since $\\ell\\left(e^{i\\theta}\\right)$ \nis a kime-phase distribution on $[-\\pi,+\\pi)$ and the observable energies\n(eigenvalues of the Hamiltonian) are finite, this suggests that $\\forall\\ \\psi_o\\in L^2(\\mathbb{C})$\n\n$$||\\psi_{\\kappa}||_{L^{\\infty}} \\underset{t\\to\\infty}{\\ \\longrightarrow 0}\\ .$$\n\nTherefore, as $t\\to\\infty$ the *PDF of the position* vanishes and there is \nno limiting probability distribution for the position of the particle in $1D$\nas it can spreads out across the entire real line.\n\nThis was the solution of the *kime-independent Schrodinger equation* in \n*position coordinates*. Let's consider the same *free evolution* (kinetic energy only)\nin *momentum coordinates.* Recall that the Fourier transform provides a \nlinear bijective mapping between *position coordinates*, spacetime representation,\n$\\varphi(x),$ and *momentum coordinates*, k-space frequency representation, ${\\hat{\\varphi}}(p)$. \n\nAgain for simplicity, we'll consider the momentum of a free particle in $1D$\nand set $c=\\hbar=1$. The solution of the Schrodinger equation in momentum coordinates is\n\n$${\\hat{\\varphi}}_{\\kappa}(p)=\\langle p |{\\hat{\\varphi}}_{\\kappa}\\rangle = \n\\left (e^{-i t p^2}\\right ) \\ell\\left(e^{i\\theta}\\right) \n(\\langle p |{\\hat{\\varphi}}_{\\kappa}\\rangle)=\n\\left (e^{-i t p^2}\\right ) \\ell\\left(e^{i\\theta}\\right) \n({\\hat{\\varphi}}_{o}(p))\\ .$$\n\nClearly, \n$||{\\hat{\\varphi}}_{\\kappa}(p)||^2 \\equiv ||{\\hat{\\varphi}}_{o}(p)||^2,$\nsuggesting that the *momentum PDF is static in kime*.\nFor a free-evolution (no potential energy) this finding is not surprising,\nsince the momentum of a free particle should be preserved. However, \nin real observations, quantum fluctuations (intrinsic randomness) will affect\nrepeated measurements of a given observation (e.g., energy). This intrinsically\nstochastic behavior is modeled by the kime-phase distribution\n$\\ell\\left(e^{i\\theta}\\right)\\sim \\Phi_{[-\\pi,+\\pi)]}$.\n\n**Problem**: Extend this $1D$ free-particle example to a *Hamiltonian including both kinetic and potential energy* components \n$$H(\\psi) =\\underbrace{-\\frac{1}{2m}\\frac{d^2}{dx^2}}_{kinetic}\\psi(x) +\n\\overbrace{(V\\psi)(x)}^{\\overbrace{V(x)}^{potential}\\ \\psi(x)}\\ .$$\n\nWork out examples like a *harmonic oscillator* with potential energy\n$V(x)=\\frac{1}{2}m \\omega^2 x^2$, where $\\omega$ is the *oscillation frequency*.\n\n...\n\n### QM Postulates\n\nThe firsts *four quantum mechanics (QM) postulates* include:\n\n - `P1`: The state of a physical system is described by a vector in a separable\ncomplex Hilbert space $\\mathcal{H}$.\n - `P2`: To each (real-valued) observable $O$ corresponds a Hermitian operator\n$\\hat{O}$ on $\\mathcal{H}$. Note that $\\hat{O}$ can be a bounded linear operator such that $\\hat{O} = \\hat{O}^{\\dagger}$, but not all operators $\\hat{O}$ are bounded.\n - `P3`: If $\\hat{O}$ is the operator for an observable $O$, then any experimentally observed value of $O$ must be an eigenvalue of $\\hat{O}$.\n - `P4`: If the observable $O$  corresponds to the operator $\\hat{O}$ and suppose $\\hat{O}$ has an orthonormal sequence of eigenvectors $\\{|\\psi_n\\rangle\\}_n$ paired with eigenvalues $\\{\\lambda_n\\}_n$. Then if the quantum system is in state $\\psi\\in \\mathcal{H}$, the probability that the observed value of $O = \\lambda$ is \n\n$$\\frac{\\sum_{i:\\lambda_i=\\lambda}|\\langle\\psi_i|\\psi\\rangle|^2}{||\\psi||^2}\\ .$$\n\n - `P5`: If the system is in inertial state (only kinetic energy without potential energy) not affected by external influences, then its *state evolves in time* as  $|\\psi(t)\\rangle = U_t|\\psi(0)\\rangle$, for some strongly continuous unitary group $\\{U_t\\}_t$ that only depends on the system (and not on the state).\n\nThe *Stone - von Neumann* theorem allows us to compute the derivative of the time evolution (i.e., explicate the time-dynamics). More specifically, there *exists a unique self-adjoint operator* $\\hat{H}$, the system *Hamiltonian*, such that \n$U_t = e^{-it\\hat{H}}$ satisfies\n\n$$\\frac{d}{dt}U_t=-i\\hat{H}\\ U_t=-i\\hat{H} e^{-it\\hat{H}}=-iU_t\\hat{H}=-ie^{-it\\hat{H}}\\hat{H}\\ .$$\n\n**Kime-Evolution Problem**: Extend these formulations from positive *real time*, $t\\in\\mathbb{R}^+$, to *complex time (kime)*, $\\kappa\\in\\mathbb{C}$.",
      "word_count": 3361
    },
    {
      "title": "Kime Relation to Reality of Quantum States and PBR Theorem",
      "content": "In 2012, [Matthew Pusey, Jonathan Barrett and Terry Rudolph proved the PBR Theorem](https://doi.org/10.1038/nphys2309), which a quantum foundations \n*no-go theorem* for interpreting the *nature of quantum states*. In regard to \nrealistic *hidden variable theories* explaining predictions of quantum mechanics,\nthe PBR theorem rules that pure quantum states must correspond directly to \nstates of reality. This correspondence can't be *epistemic*, i.e., it can't\nrepresent *probabilistic or incomplete states of knowledge about reality*. \nSubsequently, in 2017, a \n[follow up paper *The PBR theorem: Whose side is it on?*](https://doi.org/10.1016/j.shpsb.2016.11.004) discussed implications of the PBR theorem\nin relation to reality of quantum states. Specifically this study discriminates\nbetween *epistemic interpretations* of quantum states and *instrumentalism.*\nThe [PBR theorem also has connections to de Finetti’s probability interpretation as rational degrees of belief, the Einstein-Podolsky-Rosen (EPR) experiment, and Bell’s theorem](https://doi.org/10.1007/978-3-642-21329-8_16).\n\n - (*Objective* or *physical*) $\\psi$-*ontic models* of the wavefunction correspond to the physical states of the system. More specifically, $\\psi$-ontic models the wavefunction correspond directly to the physical state of the system;\n - (*Knowledge* ot *belief*) $\\psi$-*epistemic models* of the wavefunction represent *(partial?) knowledge about the physical state of the system*, not the actual physical reality. In other words, $\\psi$-epistemic models only represent virtual proxy knowledge about the physical state of the\nsystem. \n\nThere are two possible modes of proxy knowledge in *incomplete epistemic models*:\n - The wavefunction $\\psi$ could just yield a *partial description* of the actual physical state of the system, or\n - The wavefunction $\\psi$ is just a *partial representation of our knowledge* about that state. \n\nIn the *case of incomplete* $\\psi$-*ontic models*, it is conceivable that $\\psi$ \ncould be supplemented with further (yet-unknown) parameters – *hidden variables*\n- to *complete* the real-representaiton of the system. In this case, a fixed \nwavefunction $\\psi$ could correspond to various physical\nstates of the system, which can potentially be disambiguated by additional knowledge\nabout the extra hidden variables.\n\nIn the case of *incomplete* $\\psi$-*epistemic models* the completion of the\nknowledge to achieve a perfect reconstruction of physical reality cannot be\naccomplished by hidden variables!\n\nThe *representation incompleteness* takes two forms: \n\n - $\\Psi$ just gives a partial description of the physical state, or \n - a partial representation of our knowledge about that state. \n \nAn incomplete $\\Psi$-*ontic model* could potentially be augmented with further parameters,\ne.g., *hidden variables*, suggesting that the wavefunction could correspond to \nvarious physical states of the system that are distinguishable by knowing the \nvalues of the additional hidden variables. \n\n$\\Psi$-*epistemic models* can also be either *complete* or *incomplete*, however,\ncompleting them cannot be accomplished by adding hidden variables.\n\nAt face value, it appears that PBR theorem supports other no-go theorems, \n[Bell's theorem](https://en.wikipedia.org/wiki/Bell%27s_theorem), \nthat rule out the possibility of explaining the QM predictions \nusing *local hidden variable theories*. Specifically, the PBR theorem \nmay rule out physical reality interpretation via independent hidden variables,\ni.e., quantum states prepared independently can't have independent \nhidden variable descriptions.\n\nA *statistical description of an ensemble* of similar systems makes no definite\nclaims about individual members of the ensemble. This makes it challenging \nto reconcile *probabilistic descriptions of an ensemble* and the precise physical\ndescription of each individual system comprising the ensemble. \nA major point of division is whether quantum states tell us anything about the\nindividual system. Specifically, the question of how to explicate the\n*collapse of the wavefunction* due to measurement (i.e., random sampling from the \nunderlying probability distribution). If wavefunctions directly represent the \nphysical states of individual systems, upon measuring a physical property,\ntheir *instantaneous collapse (to specific \"critical\" values)* still needs to be\nexplained. If quantum probabilities govern the distributions of ensembles of \nsimilar systems, then measurements on individual systems should yield definite\nvalues; In a statistical distribution sense, critical values that correspond.\n\nIn essence, the measurement-induced *wavefunction collapse* is analogous the \n*collapse of a roll of a fair hexagonal die* from ensemble states \n$\\{|1\\rangle, |2\\rangle, |3\\rangle, |4\\rangle, |5\\rangle, |6\\rangle\\}$ of equal\nprobabilities $p(|i\\rangle)=\\frac{1}{6}, \\forall\\ i\\in\\{1, 2, \\cdots, 6\\}$.\nAt each roll of the die, the probabilities characterize an ensemble to either \nof the $6$ states. In the ensemble interpretation, the wavefunction $\\psi$\n*does not represent a physical state of an individual system*. The notions of\nquantum phenomena, e.g., superposition, interference and entanglement, become more\nenigmatic under an ensemble interpretation of quantum mechanics. \n\n**Problem**: Explore the dichotomy of the Heisenberg uncertainty principle \nin the ensemble interpretation, spacekime interpretation, and 5DSTM consortium \ninterpretation of an extra force in 5D that does not have a 4D analogue. \nCan the uncertainty principle reflect a lower-dimensional (4D) statistical \nprojection law unlishing dispersion (variability) of sampled (critical) values \nin an ensemble of systems? Can this MInkowski 4D spacetime uncertainty manifest\nthe loss of $1$ degree-of-freedom (kime-phase distribution),\nwhich transforms 5D definiteness of spacekime events into stochastic values \nrepresenting measurable properties of individual systems?\n\n\n\n\n## PBR Theorem Assumptions\n\nTwo of the critical assumptions of the PBR theorem are:\n\n - The an isolated (not entangled) *quantum system has a real physical state*, not necessarily completely described by quantum theory, but a physical state that is objective and independent of the observer.\n - Quantum systems *prepared independently* have *independent physical states*.\n\n### Classical Mechanics Iterpretation\n\nFor instance, given a point particle moving in 1D, at time $t$. Classical mechanics\nmodels the physical state of the particle as a function of its position $x$ and \nmomentum $p=mv$, scalar mass $m$ and vector velocity $v$. Thus, the \nphysical state of a particle is reflected as a point $(x,p)$ in the 2D phase\nspace. Of course, the other physical properties of the particle (e.g, charge) \nare assumed to be either *fixed* or *functions* of the state, e.g.,\nthe energy $H=H(x,p)$. In a way, other particle physical properties can be considered as\nfunctions constant in time. The exact physical state of the particle at a given point in the phase space is stochastic, subject to some well-defined probability distribution \n$\\xi(x,p)$. \n\n**Problem 1**: Can we consider the *kime-phase distribution* \n$\\ell_{(x,p)}(\\cdot)\\sim \\Phi[-\\pi,\\pi)$ as this enigmatic exact physical state \nprobability distribution $\\xi(x,p)$, which does not directly represent\nreality and evolves over time according to the \n[Liouville's equation](https://en.wikipedia.org/wiki/Liouville%27s_equation)? \nThe state probability distribution function $\\xi(x,p)$ describes the time evolution \nof the state, but instead of reality, it represents a state of knowledge\nabout an experimenter's uncertainty about the physical state of the particle.\n\n**Problem 2**: Explore the [proof of the quantum de Finetti representation theorem](https://doi.org/10.1063/1.1494475) in relation to the *spacekime interpretation*,\nand the SOCR *DNN Exchangeability, Probability Symmetry, Invariance, and Equivariance* paper\nby Yueyang Shen *et al.*.\n\n\n### Quantum Mechanics Interpretation\n\n**Definition**: A *physical property* of a system is some function of the physical state.\nFor each state of the physical system, $\\lambda$, consider a one-parameter family of probability distributions $\\{\\xi_{\\gamma}(\\lambda)\\}_{\\gamma}$. If each pair of distributions in this family are disjoint, \n\n$$\\mathrm{supp}\\left (\\xi_{\\gamma}(\\lambda)\\right)\\cap \\mathrm{supp}\\left (\\xi_{\\delta}(\\lambda)\\right)=\\emptyset,\\ \\forall\\ \\gamma\\not=\\delta\\ ,$$\n\nthen the system’s physical state (label) $\\gamma$ is uniquely fixed by $\\lambda$ \nand $\\gamma$ is a *physical property*.\n\nHowever, $\\gamma$ would *not be a physical property* when $\\exists\\ \\gamma_1\\not= \\gamma_2$, such \nthat the corresponding distributions $\\xi_{\\gamma_1}(\\lambda)$ and $\\xi_{\\gamma_2}(\\lambda)$\nboth assign positive probability to some overlapping region of positive measure ($\\nu$), i.e., \n$$\\nu\\left (\\mathrm{supp} (\\xi_{\\gamma_1}(\\lambda)\\right)\\cap \\mathrm{supp}\\left (\\xi_{\\gamma_2}(\\lambda))\\right)\\gt 0\\ .$$\nIn this situation, a scalar value \n$$\\underbrace{\\lambda}_{system’s\\\\ physical\\ state} \\in  \\underbrace{\\mathrm{supp} (\\xi_{\\gamma_1}(\\lambda))\\cap \\mathrm{supp} ( (\\xi_{\\gamma_2}(\\lambda))}_{\\not= \\emptyset}\\ .$$\nwould be consistent with either label, which is a contradiction.\n\nThe quantum state is a state of knowledge reflecting the uncertainty\nabout the real physical state of the system. Assume there is a mathematical-statistics\nmodel associated with the physical state $\\Xi$ of the system. Recording an experimental\nobservation by sampling the process yields probability likelihoods of different \noutcome measurement follow the distribution $\\xi_{\\alpha}\\sim \\Xi$. When a \ncontrolled quantum experiment is carefully prepared to ensure consistent IID outcomes,\nquantum theory associates a *pure* ($|\\psi_{\\xi_{\\alpha}}\\rangle$) or a *mixed* \n($\\sum_{\\alpha}\\omega_{\\alpha}|\\psi_{\\alpha}\\rangle$) quantum state, yet the \nthe physical state $\\Xi$ is not fixed uniquely by the system preparation process.\nRather $\\xi_{\\alpha}\\sim \\Xi$ is a draw (sample) from the *probability distribution*\nof the physical outcome.\n\nThe main question is **whether quantum state corresponds directly to reality or merely represents partial information about the state**. Consider the following two scenarios in the case of classical mechanics:\n\n - *Case 1*: The experimenter only knows the system energy $E$, and completely uncertain, about other characteristics. This (limited) knowledge corresponds to a distribution $\\xi_E(x,p)$ which is uniformly distributed over all the 2D phase space and the system Hamiltonian $H(x,p)=E$. Different energy values $E'\\not= E''$ correspond to disjoint regions of phase space, since energy is a physical property of the system. Therefore, the *supports* of distributions are *disjoint*, $\\mathrm{supp}\\left (\\xi_{E'}(x,p)\\right)\\cap \\mathrm{supp}\\left (\\xi_{E''}(x,p)\\right)=\\emptyset$.\n - *Case 2*: Assume that a pair of probability distributions have overlapping supports, i.e., $\\mathrm{supp}\\left (\\xi_{E'}(x,p)\\right)\\cap \\mathrm{supp}\\left (\\xi_{E''}(x,p)\\right)\\not=\\emptyset$. Then, the observable quantities $E'$ and $E''$ cannot refer to a single physical property of the system.\n\n### Pure, Superposition & Mixed Quantum States\n\n**Definitions**:\n\n - A *pure quantum state* is a state that can not be written as a probabilistic mixture,\ni.e., a linear combination, of other quantum states. \n - Quantum *density matrix* is a quantum tensor generalization of the classical concept of probability distribution to provide the complete description of a quantum state of a physical system and any observable quantities that can be extracted from from the state. While *state vectors* and *wavefunctions* can only represent *pure states*, density matrices can also represent *mixed states* that represent quantum systems with unknown preparation, i.e., statistical quantum ensembles of possible preparations, or physical systems with entanglements or with system-environment interactions (e.g., *decoherence*).\n - [Density operators](https://en.wikipedia.org/wiki/Density_matrix) are linear projection operators, paired with coresponding *density matrices*. In a 2D Hilbert space scenario, we start with a basis of two states $|0\\rangle $ amd $|1\\rangle $ where the corresponding density operator is represented by the (density) matrix $(\\rho _{ij})=\\left({\\begin{matrix}\\rho_{00}&\\rho _{01}\\\\ \\rho _{10}&\\rho _{11}\\end{matrix}}\\right)=\\left({\\begin{matrix}p_{0} & \\rho _{01}\\\\ \\rho _{01}^* & p_{1} \\end{matrix}}\\right)$. The main diagonal elements are real numbers summing up to one. The off-diagonal elements (coherences) are complex conjugates of each other satisfying the positive semi-definite requirement $(\\rho _{ij}) \\gt 0$.\n\nDensity operators facilitate multi-particle quantum mechanics calculations.\nMore generally, in a quantum system with a $d$-dimensional Hilbert space $\\mathcal{H}$, take\nan arbitrary state $|\\psi\\rangle \\in\\mathcal{H}$, and define $\\hat{\\rho} = |\\psi\\rangle\\, \\langle\\psi|$. This is the desity projection operator for $|\\psi\\rangle$. \nAs finite dimensional linear operators can be represented as matrices, this *density operator*\nis represented by a *density matrix* having the following properties:\n\n - It is *Hermitian*\n - If $\\hat{Q}$ is an observable with *eigenvalues* $\\{q_{\\mu}\\}$ corresponding to the *eigenstates* $|\\mu\\rangle$, then $\\hat{Q}$ measurements on $|\\psi\\rangle$ will yield values $q_{\\mu}$ with probability $p_{\\mu} = \\big|\\langle \\mu | \\psi\\rangle\\big|^2 = \\langle \\mu |\\, \\hat{\\rho}\\, | \\mu \\rangle$.\n - Let $Q$ be an *observable* of a physical system, and suppose an *ensemble is in a mixed state*, where each of the individual *pure states* $|\\psi_{j}\\rangle$ occurs with a corresponding probability $p_{j}$. Then the *mixed-state density operator* is $\\rho=\\rho_{mixed} =\\sum_{j}p_{j}|\\psi _{j}\\rangle \\langle \\psi _{j}|$ and the *mixed-state expectation value* of the measurement is also expressed in terms of the  of *pure states*:\n\n$$\\langle Q\\rangle =\\sum _{j}p_{j}\\langle \\psi _{j}|Q|\\psi _{j}\\rangle =\\sum _{j}p_{j}\\operatorname {tr} \\left(|\\psi _{j}\\rangle \\langle \\psi _{j}|Q\\right)=\\operatorname {tr} \\left(\\sum _{j}p_{j}|\\psi _{j}\\rangle \\langle \\psi _{j}|Q\\right)=\\operatorname {tr} (\\rho\\ Q)\\ .$$\nThe matrix operator $\\operatorname {tr}$ denotes the trace. For *pure states*, \nthe expectation value is $\\langle Q\\rangle =\\langle \\psi |Q|\\psi \\rangle$, \nwhereas for *mixed states* the expectation value is\n$\\langle Q\\rangle =\\operatorname {tr} (\\rho Q).$\n\nRecall that the trace $\\mathrm{tr}$ of a matrix is the sum of the diagonal elements,\nwhich is a scalar invariant of the basis, i.e., $\\mathrm{tr}$ is basis-independent.\n\nDensity operators representing pure states have the following properties:\n - The density operator can be written as an outer product of a state vector $|\\psi \\rangle$ with itself, $\\rho =|\\psi \\rangle \\langle \\psi |$;\n - The operator is an idempotent projection of rank one $\\rho =\\rho^{2}$;\n - The operator purity is unitary $\\operatorname {tr} (\\rho ^{2})=1.$\n\nThere is an important difference between a *probabilistic (statistical) mixture* of\nquantum states and *quantum superpositions* of pure states. \nIn a simple 2D scenario, a physical system prepared with *equal probability* in either one state \n$|\\psi _{1}\\rangle ={1\\choose 0}$ or another state $|\\psi _{2}\\rangle={0\\choose 1}$\ncan be described by the (rank $2$) *density operator of the mixed state*\n\n$$\\rho ={\\overbrace{\\frac {1}{2}}^{equal\\\\ prob}}\n{\\begin{pmatrix} \\overbrace{1}^{|\\psi_{1}\\rangle} & \\overbrace{0}^{|\\psi_{2}\\rangle} \\\\\n0 & 1 \\end{pmatrix}} \\ .$$\n\nwith $|\\psi_{1}\\rangle$ and $|\\psi_{2}\\rangle$ assumed to be orthogonal pure states. \n\nOn the other hand, a *quantum superposition* of these two pure states with equal probability amplitudes yields another *pure state* \n$|\\psi \\rangle =\\frac{1}{\\sqrt {2}}\\left (|\\psi _{1}\\rangle +|\\psi _{2}\\rangle \\right)$ represented by the (rank $1$, not $2$) density matrix\n\n$$ |\\psi \\rangle \\langle \\psi |={\\frac {1}{2}}{\\begin{pmatrix} 1 & 1\\\\ 1 & 1 \\end{pmatrix}}.$$\n\nWhereas probabilistic statistical *mixture* reflects independent factors, *quantum superposition* reflects potential *quantum interference*. For a more direct statistical analogy, the *mixture vs. superposition* duality is analogous to the duality between *linear models with and without interaction* effects\n\n$${\\text{(independence, no interaction model)}}\\\\\nm_1 = \\operatorname {lm} (y \\sim A\\ +\\ B,\\ data = input)\\\\ \\ \\\\\n{\\text{(model with interaction)}}\\\\\nm_2 = \\operatorname {lm} (y \\sim A + B + A:B,\\ data = input)$$\n\nFor a given a pure state, the uncertainties of statistical *mixed-states* \nand a *quantum superpositions* are quantified and interpreted differently. \nQuantum amplitudes reflect interference measured by preparing many copies\nof the same state (drawing multiple IID samples from a fixed statistical distribution)\nand measuring incompatible observables. This interference is in terms of the double-slit experiment where quantum superpositions correspond to particles going through both \nslits at once, which produces interference at the detection screen in the back.\n\nA *mixed state* represents a statistical mixture of two or more pure states, \nwhereas a *superposition state* refers to a joint state composed simultaneously \nof some other states.\n\nConsider a quantum system that has $50\\%$ chance to be observed in state \n$|\\psi_1\\rangle$ and $50\\%$ to be in another state $|\\psi_2\\rangle$. An example \nof a *superposition state* is\n$$|\\psi \\rangle = \\frac{1}{\\sqrt{2}}\\left(|\\psi_1\\rangle +|\\psi_2\\rangle \\right)\\ ,$$\nsince its a *pure state*, there is a $0\\%$ chance that the system is in either of those states $|\\psi_1\\rangle,|\\psi_2\\rangle$, and a $100\\%$ chance that the system is in the superposition state $|\\psi \\rangle$. \n\nThis probabilistic quantification of state likelihoods is made before making any measurements. \nOnce we observe a (*physical*) measurement, i.e, (*statistically*) draw from the state probability distribution corresponding to the observable characteristic property\ndenoted by $|\\psi\\rangle$, this process corresponds to a collapse the system wavefunction, which results in a $50\\%$ chance that the actual measurement (sample) is in *either of the two states* $|\\psi_i\\rangle,\\ i\\in\\{1,2\\}$.\n\n### Light Polarization Example of Mixed and Superposition States\n\nConsider a light bulb source emitting completely random polarized photons with the\nfollowing *mixed state density matrix*\n\n$$\\rho_{mixed}={\\begin{bmatrix}\\frac{1}{2} & 0\\\\ 0 & \\frac{1}{2}\\end{bmatrix}}\\ .$$\nAll photons passing through a *vertical plane polarizer* will be all vertically polarized\nwith a *pure state density matrix*\n\n$$\\rho_{pure}={\\begin{bmatrix} 1& 0 \\\\ 0 & 0 \\end{bmatrix}}\\ .$$\n\nEach individual photon will either have a right or left circular polarization\ndescribed by either orthogonal quantum states $|\\mathrm {r} \\rangle$ or\n$|\\mathrm {l} \\rangle$ }, or by a superposition of the two pure states\n$\\alpha |\\mathrm {r} \\rangle + \\beta |\\mathrm {l} \\rangle$, where \n$|\\alpha |^{2} + |\\beta |^{2}=1$. The observed polarization (detected measurement) \nwill exhibit *linear*, *circular*, or *elliptic* pattern. \n\nFor instance, a single *vertically polarized photon* described by the state \n$|\\mathrm {v} \\rangle =\\frac{1}{\\sqrt {2}}(|\\mathrm {r} \\rangle +|\\mathrm {l} \\rangle )$\nthat passes through a *circular polarizer* will only show a pure state polarized light\n$|\\mathrm {r} \\rangle$ or $|\\mathrm {l} \\rangle$, but not a mixture of both. While\na barrage of photons will have (approximately) half of the photons absorbed by the polarization filter. It's not true *half of the photons are in one state* $|\\mathrm {r} \\rangle$\nand the other half in the state $|\\mathrm {l} \\rangle$. Passing  \n$\\frac{1}{\\sqrt {2}}(|\\mathrm {r} \\rangle + |\\mathrm {l} \\rangle )$ through a \nlinear polarizing filter will not absorb any of the photons, however passing\npure states $|\\mathrm {r} \\rangle$ or $|\\mathrm {l} \\rangle$ will indeed result in\nabsorption of half the photons.\n\nOn the other hand, *non-polarized light* (e.g., from an incandescent light bulbs)\ncannot be described as $\\alpha |\\mathrm {r} \\rangle + \\beta |\\mathrm {l} \\rangle$ \nlinear, circular, or elliptical polarization state. *Polarized light* passes through\na polarizer with a $50\\%$ intensity loss irrespective of the orientation of the \npolarization filter. *Unpolarized light* can be described as a *statistical ensemble* \nwhere each photon has either $|\\mathrm {r} \\rangle$ or $|\\mathrm {l} \\rangle$ polarization \nwith equal probability $\\frac{1}{2}$. Similarly for photons with equal probability of \neither vertical $|\\mathrm {v} \\rangle$ or horizontal $|\\mathrm {H} \\rangle$ polarization.\nThe density operator for unpolarized light is\n\n$$\\rho ={\\frac{1}{2}}|\\mathrm {r} \\rangle \\langle \\mathrm {r} |+{\\frac{1}{2}}|\\mathrm {l} \\rangle\n\\langle \\mathrm {l} |=\\frac{1}{2} |\\mathrm {h} \\rangle \\langle \\mathrm {h} |+\n\\frac {1}{2}|\\mathrm {v} \\rangle \\langle \\mathrm {v} | = \n\\frac {1}{2}{\\begin{pmatrix} 1 & 0 \\\\ 0 & 1 \\end{pmatrix}}.$$\n\nIn radioactive decay, non-polarized light may be generated by using *entangled states*\nthat emit two entangles photons traveling in opposite directions, representing\nthe entangles quantum state \n$\\frac{1}{\\sqrt {2}} (|\\mathrm {r} ,\\mathrm {l} \\rangle + |\\mathrm {l} ,\\mathrm {r} \\rangle )$. \nThe joint state of the two photons represents a *pure state*, whereas\nthe density matrix for each individual photon computed as the partial trace of\nthe joint density matrix represents a *mixed state.*",
      "word_count": 2882
    },
    {
      "title": "Observables (Quantum Measurements) and Linear Transforations as Quantum Operators",
      "content": "Following the notation used in [this article, \"*An introduction to quantum computing for statisticians and data scientists*\"](https://doi.org/10.3934/fods.2024013), \nwe will explicate the pair of *quantum operator* representations of *observables* and \n*linear operators*.\n\nClassical probability theory intuition collides with quantum theoretic interpretations\ndue to quantum interference. At first glance, quantum theory may be counter-intuitive\nin describing precisely (deterministically) and completely the behavior of tiny atomic particles.\n\nLinear algebra over complex (finite/infinite dimensional Hilbert) vector spaces provides \nthe foundation of quantum theory. All closed quantum systems are described as vectors\nover Hilbert spaces, where vectors are pure quantum states, $|\\psi\\rangle$ and \nthe *ket* operator $|\\cdot\\rangle$ is\n\n$$|\\psi\\rangle \\equiv \\begin{pmatrix}\n\\psi_1 \\\\ \\psi_2 \\\\ \\vdots \\\\ \\psi_n \\\\ \\vdots \\end{pmatrix}\\ .$$\n\nThe *coordinate values*, $\\psi_m\\in\\mathbb{C}$, aka *amplitudes*, are used\nto express the quantum state $|\\psi\\rangle$ as a *linear combination* (*superposition*)\nof *quantum base states*, vectors in the Hilbert space. Suppose the standard \nbase states (basis vectors) are $\\{|e_m\\rangle\\}_m$, then\n\n$$|\\psi\\rangle = \\psi_1 |e_1\\rangle + \\psi_2 |e_2\\rangle + \\ldots + \n\\psi_n |e_n\\rangle + \\ldots\\ ,$$\n\nwhich can be finite or infinite depending on the situation.\n\nIn the Hilbert (vector) space, the *inner product* of two vectors $|\\phi\\rangle$ \nand $|\\psi\\rangle$ is defined similarly to the inner product in the \nclassical Euclidean space. However, since the scalar base-field is $\\mathbb{C}$,\nthe inner product uses *complex conjugation* and *transposition* of the left vector,\n$|\\phi\\rangle$, expressed using the *bra* notation, i.e., the conjugate-transpose \nis a row-vector $\\langle\\phi| = (\\phi_1^*\\ \\phi_2^*\\ \\ldots\\ \\phi_n^*\\ \\ldots)$. \nThe asterisk $^*$ indicates complex conjugation. The inner product \nbetween two states $|\\phi\\rangle$ and $|\\psi\\rangle$ is \n\n$$\\langle\\phi|\\psi\\rangle = \\overbrace{\\phi^* \\cdot \\psi=\\sum_m \\phi_m^*\\psi_m}^{discrete\\ case}\n\\ \\ \\ \\langle\\phi|\\psi\\rangle = \\overbrace{\\int_{\\mathbb{R}} \n\\phi^*(x)\\psi (x)\\ dx}^{continuous\\ case}\\ .$$\nQuantum normalization of the states facilitates the probabilistic interpretation\nthe squared *amplitudes* $|\\psi_m|^2$ as *likelihoods*, \ni.e., $\\forall\\ |\\psi\\rangle$, we have $\\langle\\psi|\\psi\\rangle = \\sum_m |\\psi_m|^2 = 1$.\nHence, the squared amplitudes $|\\psi_m|^2$ quantify the probabilities of future \noutcomes of prospective quantum measurement.\n\n*Observables* (*quantum measurements*) characterizes (quantize) unknown quantum states. \nFor an arbitrary quantum state, $|\\psi\\rangle$, and a given reference basis, $|e_m\\rangle$,\nthe outcomes of a quantum measurement\nare always stochastic. For instance, if an instrument measures certain *observable* $|\\psi\\rangle$\nin the standard basis, the actual *measurement value* (*outcome*) $m$ corresponding to the state $|e_m\\rangle$ with probability $|\\psi_m|^2$. The Copenhagen interpretation of quantum \nmechanics suggests that immediately after the measurement, the quantum state\n*collapses to the basis vector* $|e_m\\rangle$ corresponding to the outcome $m$. \n\nIn a classical probabilistic setting, imagine a closed container containing balls \nof different colors. Prior to randomly drawing a ball from the container, \nwe don't know it's color. Yet, taking many repeated samples (drawing a random \nball and recording it's color, before replacing it and mixing the balls in \nthe container) allows us to estimate (quantify) the *color probability distribution*\nover the set of all possible ball colors. Prior to the measuremetn observation,\nthe color of the next ball is a *random variable.* Drawing a ball at random, \naccording to the ball color probability distribution, corresponds to instantiating\na random ball color, i.e., at the time of observing the ball, the experimental\nmeasurement (sampling) collapses the probability distribution into a specific color. \nAnalogously, we can characterize (quantize) quantum states by repeatedly preparing \nthe controlled experiment, making quantum measurements, and extrapolating (modeling)\nthe sampling distribution.\n\nQuantum theory may be viewed as both *counter-intuitive* (stochastic interpretability)\nand *powerful* (reliable computing, estimation, and prediction). Quantum states are \nobserved according to their *squared amplitudes*, which are the corresponding \nprobabilities quantify the likelihoods of each outcome. \nAs the amplitudes are complex values, their corresponding squared amplitudes\nprobability masses (or density values) cancel out under *linear quantum states transformations.* \n\nA quantum state $|\\psi_A\\rangle$ transforms into another state in the same Hilbert space $|\\psi_B\\rangle$ by $|\\psi_B\\rangle = U |\\psi_A\\rangle$, where $U$ is a *linear unitary operator.*\n*Quantum interference* refers to the *cancellation of (complex) amplitudes* under \nlinear transformations. We will see that in general, a *quantum measurement*, \nor a *quantum algorithm*, $A$ is a *collection of linear operators* $A\\equiv\\{M_m\\}$  \ncorresponding to a series of outcomes (or indices of outcomes) $\\{m\\}$ \noccurring with corresponding series of probabilities $\\{p_m\\}$. Hence, quantum\nmeasurements are *series of linear transformations* mapping input states\n$|\\psi_{\\text{input}}\\rangle$ into corresponding output states \n$|\\psi_{\\text{output}}\\rangle$\n\n$$|\\psi_{\\text{output}}\\rangle = A |\\psi_{\\text{input}}\\rangle\\ .$$\n\nMore specifically, a measurement applied to a quantum state $|\\psi\\rangle$ \nresults in a specific outcome $m$ with probability \n$p_m = \\langle \\psi | M_m^\\dagger M_m | \\psi \\rangle.$ Furthermore,\nthe normalized state of the system after the measurement is \n$${\\text{Observation}}=\\frac{\\overbrace{M_m |\\psi\\rangle}^{measurement\\ output}} \n{\\underbrace{\\sqrt{\\langle \\psi | M_m^\\dagger M_m | \\psi \\rangle}}_{normalization\\ const.}}.$$\n\n## Qubit - an Example of a Simple Quantum System\n\nThe basic unit of information in modern computers is a $0/1$ *bit*, whereas\nthe basic information-storage unit of a quantum computer is a *qubit*, $|q\\rangle$,\nwhich is a 2D system $|q\\rangle = a |0\\rangle + b |1\\rangle$, \nwhere $|0\\rangle$ and $|1\\rangle$ form an *orthonormal basis* of the corresponding\n2D Hilbert space. The *basis states* are $|0\\rangle=\\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}$ \nand $|1\\rangle=\\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix}$. \nThe superposition (composite) *qubit state* $|q\\rangle=\\begin{pmatrix} a \\\\ b \\end{pmatrix}$\nis a normalized vector in the 2D Hilbert space describing the state of the \nsingle-qubit quantum system. The complex-scalar value *amplitudes* are the coefficients \n$a, b \\in \\mathbb{C}$, constrained so that $|a|^2 + |b|^2 = 1$. Hence, subject to \na normalization constraint (llosing one degree of freedom, the superposition state\n$|q\\rangle$ is a linear combination of the basis states $|0\\rangle$ and $|1\\rangle$.\n\nA quantum measurement of $|q\\rangle$ in the basis of $\\{|0\\rangle, |1\\rangle\\}$ yields $0$ with probability $|a|^2$ and $1$ with probability $|b|^2$. But prior to making a *physical measurement* (*random sampling*, in statistical terms), the quantum state $|q\\rangle$\nis in a superposition of the two base states. In a way, the state $|q\\rangle$ is \nanalogous to a random variable taking the classical bit values $0$ and $1$ with\ncorresponding probabilities $|a|^2$ and $|b|^2$. Yet, there is a crucial difference: the coefficients $a,b\\in\\mathbb{C}$ do not need to be positive reals! This complexification\nproperty is crucial to the power of quantum computers.\n\nThis 2D superposition property extends to collections of *multiple qubits*, \nreferred to as *quantum registers*, e.g., a register of $3$ qubits can support \nquantum states expressed in terms of the $2^3=8$ base states $\\{|b_1 b_2 b_3\\rangle\\}$\nencoding the base-2 (binary) representations of the numerical outcomes \n$\\{m\\}=\\{0,1,2,3,4,5,6,7\\}$\n\n$$|\\psi\\rangle = \\sum_m \\psi_m|e_m\\rangle \\equiv \\psi_{000} |000\\rangle + \\psi_{001} \n|001\\rangle + \\psi_{010} |010\\rangle + \\psi_{011} |011\\rangle + \\psi_{100} |100\\rangle \n+ \\psi_{101} |101\\rangle + \\psi_{110} |110\\rangle + \\psi_{111} |111\\rangle .$$\n\nFor $b_k = \\{1, 0\\},\\ k\\in\\{1,2,3\\}$, the *base states* $|b_1 b_2 b_3\\rangle$, \nform an orthonormal basis of the Hilbert space, and the *3-qubit register* supports $2^3 = 8$ dimensional quantum states, i.e., superpositions of $8$ basis states. \nThe shorthand notation $|b_1 b_2 b_3\\rangle=|b_1\\rangle \\otimes |b_2\\rangle \\otimes |b_3\\rangle$,\nwhere $\\otimes$ represents the *tensor (outer) product*, i.e., $|b_1 b_2 b_3\\rangle$ \nis an 8-dimensional vector. The tensor form shows that the state \n$|b_1 b_2 b_3\\rangle$ is *separable*, i.e., each qubit in the state can be manipulated *independently* of the other qubits. In general, quantum states are *entangled*, that is\nformed by multiple qubits and *cannot* be expressed as a tensor product.\nGenerally, entangled states $|\\psi\\rangle$ are *not separable*.\n\nThe superposition property and entanglement enable efficient encoding of information \nsupporting enormous computational efficiencies and parallelism. There is nothing special\nwith the *binary* (2D) and *tertiary* (3D) examples above. This composite state superposition\nrepresentaiton generalizes to using $n$-qubit registers can encode $2^n$D vectors\nwith $2^n - 1$ *independent amplitudes*, one less to account for the normalization of quantum states condition, which introduces a interdependence (loss of one degree of freedom). \nNote that the special case of a *separable state* on $n$ qubits can only encode $n$ \nindependent amplitudes. Quantum entanglement provides this massive complexification of\nthe state space, where $n$ qubits can encode $2^n-1$ independent amplitudes.\n\n## Example - Quantum Algorithms\n\nQuantum operations are series of *linear transformations* and *quantum measurements* \non a set of quantum registers. As an example, just like classical algorithms are\noften represented as a series of functions, quantum algorithms (operations) maybe \nimplemented via a series of simple quantum gates, \nanalogous to the traditional logic gates - *AND*, *XOR*, or *NOT.* Quantum gates are \nelementary quantum transformations that act on one, two, three, or more qubits.\n\nQuantum algorithms take an *input quantum state* and transform it into a corresponding\n*output state* that encodes the desired result. The superposition property imply\nthe efficiency of quantum algorithms offering *exponential speedup* over classical\nalgorithms. For instance, a *classical algorithm* that checks $100$-bit strings, i.e., \n$2^{100} \\approx 10^{30}$ possibilities, has to check each of the $2^{100}$ strings. \nOn the other hand, using *quantum parallelism*, a *quantum algorithm* could \npotentially perform the same task in massive parallel fashion labeling the correct \nand incorrect strings using only $100$ operations, one for each of the $100$ qubits \nholding the $2^{100}$ strings in a quantum superposition. \n\nThe (probabilistic) output of a naive quantum computation will be a superposition \nof all the $2^{100}$  labeled results (unsettling). If all results are approximately\nequally probable, then it would take $\\sim 10^{30}$ measurements to extract the \ncorrect answer, which negates any quantum computing benefits. To solve this issue,\nquantum algorithms leverage *quantum interference* - the property that quantum amplitudes\nare complex numbers that can cancel out during the computation (just like in a simple additive operation mode, adding positive and negative real numbers tend to cancel out). Quantum algorithms\nrely on quantum interference to *suppress the amplitudes of the wrong answers*\nwhile *amplifying the amplitudes of the correct answers*. Hence, output states\nof efficient quantum algorithms are superpositions of the desired answers, where\njust a few measurements are sufficient to estimate the final answer within a\npredefined precision (controlled error-rate).\n\n\n## Quantum States, Measurability and Quantum Operators\n\nIn our prior example of a quantum state created on a 3-qubit registers, the expansion of\n$|\\psi\\rangle$ explicates the bit strings of individual qubit basis states as integer numbers,\ne.g., $\\underbrace{|101\\rangle}_{3-qubit\\\\ register}=\\underbrace{|5\\rangle}_{integer}$,\nwhere the $n$-qubit quantum state $|\\psi\\rangle = \\sum_{m=0}^{N-1} \\psi_m |m\\rangle$, \n$N=2^3$, and the integer representation of the bit string is $m=|m\\rangle$. \nHence, the 3-qubit quantum state $|\\psi\\rangle$ is described by a normalized $8$D\nvector over complex numbers, $(\\psi_0, \\psi_1, \\cdots, \\psi_7)^T$. \nThe *orthonormal basis states* \n$$\\underbrace{|m\\rangle}_{integer\\ rep.} \\equiv \n\\underbrace{|b_1 b_2 \\cdots b_n\\rangle}_{binary\\ rep.}\\ ,$$ \nwhere $\\forall\\ m\\in\\{1, 2, \\cdots, n\\},\\ b_m = \\{0, 1\\}$ is the computational basis\nof the Hilbert space.\n\nMuch like in the classical case of Euclidean spaces, the *inner product* between two\nquantum states $|\\psi\\rangle$ and $|\\phi\\rangle$ in an $N$D Hilbert space\ncan be expressed in terms of the product of the paired vector coordinates \n\n$$\\langle\\phi|\\psi\\rangle = \\underbrace{\\sum_{m=0}^{N-1} \\phi_m^*\\psi_m}_{finite\\ dim\\ space},\n\\ \\ \\ \n\\langle\\phi|\\psi\\rangle = \\underbrace{\\int_{\\mathbb{R}} \\phi^* (x)  \\psi(x) \\ dx }_{infinite\\ dim\\ space}.$$\n\nIn quantum notation, the conjugate-transpose of a *ket* is a *bra*, and vice-versa\n\n$$\\left (\\overbrace{|\\phi\\rangle}^{ket} \\right )^*=\n\\overbrace{\\langle\\phi|}^{bra}= \\sum_{m=0}^{N-1} \\phi_m^* \\langle m|\\ ,\n\\ \\ {\\text{and  }} \\ \\left (\\overbrace{\\langle\\phi|}^{bra} \\right )^*=\n\\overbrace{|\\phi\\rangle}^{ket}= \\sum_{m=0}^{N-1} \\phi_m | m\\rangle\\ ,$$\n\nand the pure (base) *bra* $\\langle m|$ is the conjugate transpose of the *ket* $|m\\rangle$.\nFor example, in a 2D Hilbert space, if $|0\\rangle=\\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}$, \nthen $\\langle 0|=\\begin{pmatrix} 1 & 0 \\end{pmatrix}$. As basis states are orthonormal,\nthe inner product is expressed as $\\langle\\cdot|\\cdot\\rangle$, e.g., for a pair of basis states $|i\\rangle$ and $|j\\rangle$ is \n\n$$\\langle i|j\\rangle = \\delta_{ij} \\equiv \\begin{cases} \n1, & \\text{if } i = j \\\\\n0, & \\text{if } i \\neq j \n\\end{cases} \\ ,$$\n\nwhere $\\delta_{ij}$ is the Kronecker delta function. More generally,\nfor $N$D states, the inner product is\n\n$$\\langle \\phi|\\psi\\rangle = \\left( \\sum_{j=0}^{N-1} \\phi_j^* \\langle j| \\right) \\left( \\sum_{i=0}^{N-1} \\psi_i |i\\rangle \\right) = \\sum_{j=0}^{N-1} \\sum_{i=0}^{N-1} \\phi_j^* \\psi_i \\langle j|i\\rangle = \\sum_{i=0}^{N-1} \\phi_i^* \\psi_i. $$\n\n## Quantum Operators\n\n*Quantum operators* are linear and are represented by complex matrices *acting* on vectors \nin the $N$D Hilbert space. For instance, an operator $A=A_{N \\times N}=(a_{ij})_{i,j=0}^{N-1}$\ncan be expressed in *bra-ket* (matrix/tensor) form\n\n$$A = \\sum_{i,j=0}^{N-1} a_{ij} |i\\rangle \\langle j| \\ ,$$\n\nwhich acts on quantum states $|\\psi\\rangle = \\sum_{k=0}^{N-1} \\psi_k |k\\rangle$ by \nstandard matrix multiplication\n\n$$A |\\psi\\rangle = \\left( \\sum_{i,j=0}^{N-1} a_{ij} |i\\rangle \\langle j| \\right) \\left( \\sum_{k=0}^{N-1} \\psi_k |k\\rangle \\right) \\overbrace{=}^{\\langle j|k\\rangle = \\delta_{jk}}\\\\\n\\sum_{i,j=0}^{N-1} a_{ij} \\psi_j |i\\rangle = \\overbrace{\\sum_{i=0}^{N-1} \n\\underbrace{\\left( \\sum_{j=0}^{N-1} a_{ij} \\psi_j \n\\right)}_{scalar\\ coef\\ \\in\\mathbb{C}}\\overbrace{|i\\rangle}^{basis}}^{linear\\ superposition}\\ .$$\n\nNote that vector$\\times$scalar multiplication associative property and the \northonormality of the basis vectors, $\\langle j|k\\rangle = \\delta_{jk}$, \nleads to simplifications of the linear combinations of outer products of \nbasis states $|i\\rangle \\langle j|$. \n\n\n**Definition**: Not all linear operators are quantum operators, but all quantum operators\nare linear. There are *two types of quantum operators*: *unitary transformations* and *observables.* \n\n - *Unitary transformations* map one quantum state into another.\n - *Observables* are related to quantum measurement and probabilistically characterize quantum states.\n - A linear operator $U$ is *unitary* if $U^{-1} = U^\\dagger$, where $\\dagger$ denotes the *conjugate transpose*. Unitary operators preserve the unit norm of quantum states. \n - The *identity operator* $I$ is a unitary operator expressing quantum states in alternative bases. Let $\\{|a_i\\rangle\\}_{i=0}^{N-1}$ be an orthonormal set of basis states of an $N$D Hilbert space and let $\\{|b_j\\rangle\\}_{j=0}^{N-1}$ be an alternative set of orthonormal basis states of the same vector space. A state $|\\psi\\rangle=\\{|a_i\\rangle\\}$ in expressed in terms of first basis states can also be expressed in terms of second basis states by using the identity operator $I = \\sum_{j=0}^{N-1} |b_j\\rangle \\langle b_j|$\n \n$$|\\psi\\rangle = \\sum_{i=0}^{N-1} \\psi_i |a_i\\rangle = \\left( \\sum_{j=0}^{N-1} |b_j\\rangle \\langle b_j| \\right) \\left( \\sum_{i=0}^{N-1} \\psi_i |a_i\\rangle \\right) = \\sum_{j=0}^{N-1} \\left( \\sum_{i=0}^{N-1} \\psi_i \\langle b_j | a_i \\rangle \\right) |b_j\\rangle = \\sum_{j=0}^{N-1} \\psi_j |b_j\\rangle\\ ,$$\nwhere $\\psi_j = \\sum_{i=0}^{N-1} \\psi_i \\langle b_j | a_i \\rangle\\in \\mathbb{C}$ are the (scalar) coordinates of $|\\psi\\rangle$ in the second basis $\\{|b_j\\rangle\\}$.\n\n## Observables and Quantum Measurements\n\nQuantum measurements characterize probabilistically quantum states. Quantum operations\ntransform input quantum states into output measurements of the resulting state that\nreflect the desired result with high probability. Symbolically, *quantum measurements*\nare collections of operators $\\{M_m\\}$ that correspond to outcomes $m$ (as\nbefore, $m$ can represent the actual outcomes or the index of the outcomes), which\noccur with corresponding probabilities $p_m$. A measurement applied to a \nquantum state $|\\psi\\rangle$ yields the outcome $m$ with probability \n$$p_m = \\langle \\psi | M_m^\\dagger M_m | \\psi \\rangle\\ .$$\n\nThe (normalized) state of the system after the measurement is \n$$\\frac{M_m |\\psi\\rangle }{\\sqrt{\\langle \\psi | M_m^\\dagger M_m | \\psi \\rangle}}.$$\n\nBecause the probability of all possible outcomes adds up to $1$, $\\sum_m p_m = 1$\nand for all quantum states, the measurement operators satisfy the *completeness relation*\n$\\sum_m M_m^\\dagger M_m = I$.\n\nFor example, quantum measurement of a qubit $|q\\rangle$  in the binary computational basis \nis a collection of a pair of measurement operators, *projection measurement operators* onto\nthe two base states. Symbolically, $P_0 = |0\\rangle \\langle 0|$ and \n$P_1 = |1\\rangle \\langle 1|$ correspond to outcomes $0$ and $1$, respectively. \nThese quantum operators satisfy the completeness relation \n$$\\sum_m M_m^\\dagger M_m \\equiv P_0^\\dagger P_0 + P_1^\\dagger P_1 = |0\\rangle \\langle 0| 0\\rangle \\langle 0| + |1\\rangle \\langle 1| 1\\rangle \\langle 1| = |0\\rangle \\langle 0| + |1\\rangle \\langle 1| = I.$$\n\nThe chance that $0$ is the measured value is quantified by\n$p_0 = \\langle q | P_0^\\dagger P_0 | q \\rangle = \\langle q | 0\\rangle \\langle 0 | q \\rangle = | \\langle 0 | q \\rangle |^2 = |a|^2.$ \nSimilarly, the chance of observing $1$ is $p_1 = | \\langle 1 | q \\rangle |^2 = |b|^2$. Because $|a|^2 + |b|^2 = 1$, $p_0 + p_1 = 1$.\n\nMore generally, the measurement of an $N$D quantum state $|\\psi\\rangle$ in the \northonormal basis $\\{|a_i\\rangle\\}_{i=1}^N$ is the *set of projection operators* \n$\\{P_m = |a_m\\rangle \\langle a_m|\\}$. The probability $p_m$ that the measurement of\nstate $|\\psi\\rangle$ yields basis state $|a_m\\rangle$ is \n$p_m = | \\langle a_m | \\psi \\rangle |^2$.\n\nThis property is called the **Born rule** and suggests that \n**quantum states are determined up to a complex phase pre-factor** \n$e^{i\\theta}$, where the *phase* $\\theta \\in \\mathbb{R}$, and $i=\\sqrt{-1}$ is\nthe imaginary unit. Hence, the state $|\\psi\\rangle$ is equivalent to all states \nin this form $e^{i\\delta} |\\psi\\rangle,\\ \\forall\\theta\\in\\mathbb{R}$. \nThe *global phase pre-factor* $e^{i\\delta}$ is directly related to the \n*kime-phase* and its physical meaning beyond the reflection of repeated\nmeasurement distribution fluctuations is still being investigated.\n\n**Observables** are linear self-adjoint (Hermitian) operators, $K^\\dagger = K$,\nwhose eigenvalues are all real, but are not necessarily norm-preserving. \n\nLet $|\\kappa_j\\rangle$ be eigenvectors of the observable $K$ with (real) eigenvalues \n$\\kappa_j$, so that $K |\\kappa_j\\rangle = \\kappa_j |\\kappa_j\\rangle$. \nThen, the observable $K = \\sum_j \\kappa_j |\\kappa_j\\rangle \\langle \\kappa_j|$,\nwhere the states $|\\kappa_j\\rangle$ form an orthonormal basis. If \n$P_j = |\\kappa_j\\rangle \\langle \\kappa_j|$ is the *projection operator* onto the \nsubspace spanned by $|\\kappa_j\\rangle$, the observable $K$ is linked to the quantum\nmeasurement by the complete set of projection operators $\\{P_j\\}$ with outcomes $\\{\\kappa_j\\}$. This quantum measurement is called the measurement of the observable $K$.\n\nFor a quantum state $|\\psi\\rangle$, the *expectation value* of the result \nof the measurement of $K$ is\n$$\\mathbb{E}_\\psi[K] \\equiv \\langle K \\rangle = \\sum_j p_j \\kappa_j = \\sum_j | \\langle \\kappa_j | \\psi \\rangle |^2 \\kappa_j,$$\n\nwhere $\\langle \\cdot \\rangle$ denotes the expectation value of an observable and \n$p_j = | \\langle \\kappa_j | \\psi \\rangle |^2$ is the probability that the measurement\nof $K$ in the state $|\\psi\\rangle$ yields the value $\\kappa_j$. \nSince $| \\langle \\kappa_j | \\psi \\rangle |^2 = \\langle \\psi | \\kappa_j \\rangle \\langle \\kappa_j | \\psi \\rangle$, the expectation value is\n\n$$\\langle K \\rangle = \\sum_j \\langle \\psi | \\kappa_j \\rangle \\langle \\kappa_j | \\psi \\rangle \\kappa_j = \\langle \\psi | \\left( \\sum_j \\kappa_j |\\kappa_j\\rangle \\langle \\\n\\kappa_j| \\right) | \\psi \\rangle = \\langle \\psi | K | \\psi \\rangle\\ .$$\n\nThus, the expectation value of an observable $K$ in a quantum state \n$|\\psi\\rangle$ is $\\langle \\psi | K | \\psi \\rangle$. Hence, we can\ncompute the expectation values of observables without explicit knowledge of the\nmeasurement probabilities.\n\n\n...",
      "word_count": 2975
    },
    {
      "title": "Notes",
      "content": "- Minkowski 4D spacetime appears to be a very special Euclidean manifold. The reason for this mathematical-uniqueness is the topological characterization of 4D. For any dimension other than $4$, $n\\in\\mathbb{Z}\\setminus\\{4\\}$, there are *no exotic smooth structures* on $\\mathbb {R}^{n}$. That is, when $n\\not= 4$, any smooth manifold\n$\\mathcal{M}$ *homeomorphic* to $\\mathbb {R}^{n}$ is also *diffeomorphic* to \n$\\mathbb {R}^{n}$. The existence of [exotic $\\mathbb{R}^4$'s](https://en.wikipedia.org/wiki/Exotic_R4) is only possible in $4$D, e.g., Minkowski spacetime. Exotic $\\mathbb{R}^4$'s are differentiable manifolds that are *homeomorphic* to $\\mathbb{R}^4$, i.e., *shape preserving*, but not *diffeomorphic* to $\\mathbb{R}^4$, i.e., *non smooth manifolds*. These strange constructs only exist in $4$D.\n - The uniqueness of the existence of exotic $\\mathbb{R}^4$ manifolds is directly related to the [Clay Mathematics Institute *Millennium Prize Problems*](https://en.wikipedia.org/wiki/Millennium_Prize_Problems) and the [GTR, Yang–Mills Theory, Gauge Theory, Quantum electrodynamics (QED), Symmetry Groups, and the physics Standard Model](https://en.wikipedia.org/wiki/Gauge_theory). In  gauge theory terms, the *Standard Model* unifies the description of $3$ of the fundamental forces - electromagnetism, weak nuclear interactions, and strong nuclear interactions. The [Standard Model](https://en.wikipedia.org/wiki/Standard_Model) can be thought of as a *non-Abelian gauge theory* with the symmetry group $U(1) \\times SU(2) \\times SU(3)$ and a total of $12$ gauge bosons - $1$ photon, $3$ weak bosons, and $8$ gluons.\n - This also relates to the extension of [quantum field theory (QFT) from *operator-valued functions* to *operator-valued distributions*](https://plato.stanford.edu/entries/quantum-field-theory/). An *operator-valued distribution* is a functional $\\Psi$ from the Schwartz space of test-functions to bounded linear operators on the Hilbert space $\\mathcal{H}$ having the following property, $\\forall\\ \\eta, \\xi \\in\\mathcal{H}\\ \\Longrightarrow\\ \\langle\\eta|\\Psi|\\xi\\rangle$ is a *tempered distribution*. A tempered distribution $f:\\mathbb{R}\\to\\mathbb{C}$ is a functional assigning a complex-number to each test function $\\phi$, i.e., $\\langle f,\\cdot\\rangle(\\phi)\\equiv \\langle f,\\phi\\rangle=\\int_{\\mathbb{R}}f^*(\\theta)\\ \\phi(\\theta)\\ d\\theta$.",
      "word_count": 276
    },
    {
      "title": "References",
      "content": "- [Introduction to Applied Nuclear Physics (OCW MIT)](https://ocw.mit.edu/courses/22-02-introduction-to-applied-nuclear-physics-spring-2012/).\n\n\\begin{thebibliography}{99}\n\n\\bibitem{tarter1993model} Tarter, M. E. (1993). Model-based methods in data analysis. In \\emph{Encyclopedia of statistical sciences}. American Cancer Society.\n\n\\bibitem{casals2018state} Casals, M., Giron, F., and Martin, J. (2018). The state of Bayesian learning. \\emph{Annual Review of Statistics and Its Application}, \\emph{5}, 141-166.\n\n\\bibitem{tang2019model} Tang, F., Wang, Z., and Guo, Y. (2019). Model-based clustering of high-dimensional longitudinal data. \\emph{Statistical Modelling}, \\emph{19}(4), 295-318.\n\n\\bibitem{gao2018model} Gao, R., Jin, L., and Wang, Z. (2018). Model-free time series prediction using recurrent neural networks. \\emph{IEEE Transactions on Neural Networks and Learning Systems}, \\emph{29}(5), 1774-1787.\n\n\\bibitem{kaluza1921unitatsproblem} Kaluza, T. (1921). Zum Unitätsproblem der Physik. \\emph{Sitzungsberichte der Preussischen Akademie der Wissenschaften}, 966-972.\n\n\\bibitem{klein1926quantentheorie} Klein, O. (1926). Quantentheorie und fünfdimensionale Relativitätstheorie. \\emph{Zeitschrift für Physik}, \\emph{37}(12), 895-906.\n\n\\bibitem{wesson1992kaluza} Wesson, P. S., Lim, P. L., and Overduin, J. M. (1992). Kaluza-Klein theory with a variable rest mass. \\emph{Physical Review D}, \\emph{46}(12), 5256.\n\n\\bibitem{overduin1997kaluza} Overduin, J. M., and Wesson, P. S. (1997). Kaluza-Klein gravity. \\emph{Physics Reports}, \\emph{283}(5-6), 303-380.\n\n\\bibitem{wesson2007space} Wesson, P. S. (2007). Space, time, matter: Modern Kaluza-Klein theory. World Scientific.\n\n\\bibitem{wesson2002five} Wesson, P. S. (2002). Five-dimensional physics: Classical and quantum consequences of Kaluza-Klein cosmology. World Scientific.\n\n\\bibitem{john1985ultrahyperbolic} John, F. (1985). Ultrahyperbolic partial differential equations. In \\emph{Partial Differential Equations}. Springer.\n\n\\bibitem{courant2008methods} Courant, R., and Hilbert, D. (2008). Methods of mathematical physics. Vol. II: Partial differential equations. Wiley.\n\n\\bibitem{bars2001survey} Bars, I. (2001). Survey of two-time physics. \\emph{Classical and Quantum Gravity}, \\emph{18}(16), 3113-3130.\n\n\\bibitem{dorling1970dimensionality} Dorling, J. (1970). The dimensionality of time. \\emph{Philosophy of Science}, \\emph{37}(2), 234-243.\n\n\\bibitem{craig2009determinism} Craig, D., and Singh, P. (2009). Determinism and causality in two-time physics. \\emph{Physical Review D}, \\emph{80}(2), 025011.\n\n\\bibitem{wang2022determinism} Wang, T., and Li, H. (2022). Determinism and stability of solutions to the ultrahyperbolic wave equation. \\emph{Journal of Mathematical Physics}, \\emph{63}(3), 032501.\n\n\\end{thebibliography}\n\n\n<!--html_preserve-->\n<div>\n    \t<footer><center>\n\t\t\t<a href=\"https://www.socr.umich.edu/\">SOCR Resource</a>\n\t\t\t\tVisitor number <img class=\"statcounter\" src=\"https://c.statcounter.com/5714596/0/038e9ac4/0/\" alt=\"Web Analytics\" align=\"middle\" border=\"0\">\n\t\t\t\t<script type=\"text/javascript\">\n\t\t\t\t\tvar d = new Date();\n\t\t\t\t\tdocument.write(\" | \" + d.getFullYear() + \" | \");\n\t\t\t\t</script\n\t\t\t\t<a href=\"https://socr.umich.edu/img/SOCR_Email.png\"><img alt=\"SOCR Email\"\n\t \t\t\ttitle=\"SOCR Email\" src=\"https://socr.umich.edu/img/SOCR_Email.png\"\n\t \t\t\tstyle=\"border: 0px solid ;\"></a>\n\t \t\t </center>\n\t \t</footer>\n\n\t<!-- Start of StatCounter Code -->\n\t\t<script type=\"text/javascript\">\n\t\t\tvar sc_project=5714596; \n\t\t\tvar sc_invisible=1; \n\t\t\tvar sc_partition=71; \n\t\t\tvar sc_click_stat=1; \n\t\t\tvar sc_security=\"038e9ac4\"; \n\t\t</script>\n\t\t\n\t\t<script type=\"text/javascript\" src=\"https://www.statcounter.com/counter/counter.js\"></script>\n\t<!-- End of StatCounter Code -->\n\t\n\t<!-- GoogleAnalytics -->\n\t\t<script src=\"https://www.google-analytics.com/urchin.js\" type=\"text/javascript\"</script>\n\t\t<script type=\"text/javascript\"_uacct = \"UA-676559-1\"; urchinTracker(); </script>\n\t<!-- End of GoogleAnalytics Code -->\n</div>\n<!--/html_preserve-->",
      "word_count": 384
    }
  ],
  "tables": [
    {
      "section": "Main",
      "content": "    toc_depth: '3'\n---",
      "row_count": 2
    }
  ],
  "r_code": [
    {
      "section": "Main",
      "code": "knitr::opts_chunk$set(echo = TRUE)",
      "line_count": 1
    },
    {
      "section": "Manifold Foliation",
      "code": "library(plotly)\n\n# sweep or define (u,v) spherical coordinate parameter ranges\nphi <- seq(from = 0, to = 2*pi, by = ((2*pi - 0)/(200 - 1)))\npsi <- seq(from = 0, to = pi, by = ((pi - 0)/(200 - 1)))\n\n#p <- plot_ly(x = ~x, y = ~y, z = ~z, type = 'surface', opacity=1,\n#             contour=list(show=TRUE, color=\"#000\", width=15, lwd=10))  %>%\n#  layout(title = paste(\"Layout \", shape), \n#         scene = list(xaxis=x_label,yaxis=y_label, zaxis=z_label))\n#p\n\nshapes <- c(\"Complex Plane\", \"Sphere\", \"Torus\")\nshapeNames <- c(TeX(\"\\\\text{Complex Plane }\\\\mathbb{C}\\\\cong\\\\mathbb{R}^2\"), \n                TeX(\"\\\\text{Sphere }\\\\mathbb{S}^2\"), \n                TeX(\"\\\\text{Torus }\\\\mathbb{T}^2\\\\cong\\\\mathbb{R}^2 / \\\\mathbb{Z}^2\"))\nnCurves <- 5  # number of toral solenoid curves\n                # https://mathcurve.com/courbes3d/solenoidtoric/solenoidtoric.shtml\ncurveGap <- 4 # index gap between solenoids curve rotational shifts\nsamplingRate <- 200  # curve sampling rate\n\n# shape==\"complexPlane\"\n    supportWidth <- 2\n    x2D <- seq(-supportWidth*pi, supportWidth*pi, length.out=samplingRate)\n    y2D <- array(0, c(nCurves, samplingRate))\n    x0 = x2D %o% x2D   # Complex-Plane Grid\n    y0 = x2D %o% x2D\n    z0 <- array(1, c(4*samplingRate, samplingRate))\n    x1D <- c(1:samplingRate)\n    y1D <- seq(1:(4*samplingRate))\n    # p <- plot_ly(x=x1D, y=y1D, z=z0, type=\"surface\", name=\"Complex Plane\", opacity=0.3)\n    # for (curve in 1:nCurves) {  # for each solenoid curve on torus\n    #   y2D[curve, ] <- (curve-nCurves/2)/curveGap + (2+sin(x2D)) + x2D/(supportWidth*pi)\n    #   p <- p %>% add_trace(x=c(1:samplingRate), y=(y2D[curve,]*samplingRate),\n    #                        z=1, name=paste0(\"Curve: \", curve), opacity=1,\n    #                        type=\"scatter3d\", mode=\"lines\")\n    # }\n    # p\n    \n# shape==\"torus\"\n    # h2= 10   # cone height\n    # r2 = seq(from = 0, to = h2, by = ((h2 - 0)/(200 - 1)))  # r = radius\n    # x2 = 3* ((h2 - r2)/h2 ) %o% rep(1, 200)             # x = 3*r\n    # y2 = 3* ((h2 - r2)/h2 ) %o% sin(phi)   # y = r*sin(phi)\n    # z2 = 3* ((h2 - r2)/h2 ) %o% cos(phi)   # z = r*cos(phi)\n\n    ### Kime tube on torus\n#### Parametric curve on torus\n# k1 <- phi -pi\n# k2 <- ((phi-1)^3 + 5*(phi-1)^2 + 2*(phi-5) - 8)/10\n  a <- 6   # Torus radius (from torus gravitational center)\n  r <- 2   # Tube radius (from torus circular core)\n  # When n is a rational p / q , and R > r , the curve is closed and simple, and the node \n  # associated with the corresponding toroidal solenoid is the toroidal node T ( p, q ), \n  # p windings around the torus for q turns around of the axis, which is always a prime node . The nodes T ( p, q ) and T ( q, p ), are equivalent (to go from ( p, q ) to ( q, p ), passing a needle in the core of the torus).\n  p <-  5 # p winding around the torus\n  q <-  1# q turns around of the toral axis\n  n <- p/q\n\n  xOuter <- outer(phi, psi, function(phi, psi) { cos(phi)*(a+r*cos(n*psi)) })\n  yOuter <- outer(phi, psi, function(phi, psi) { sin(phi)*(a+r*cos(n*psi)) })\n  zOuter <- outer(phi, psi, function(phi, psi) { r*sin(n*psi) })\n\n  phi <- seq(from = 0, to = 2*pi, by = ((2*pi - 0)/(50 - 1)))\n  psi <- seq(from = 0, to = 2*pi, by = ((2*pi - 0)/(50 - 1)))\n  psi2 <- seq(from= 0, to = 2*pi, by = ((2*pi - 0)/(50 - 1)))\n\n  xOuter <- outer(phi, psi, function(phi, psi) { cos(phi)*(a+r*cos(psi)) })\n  yOuter <- outer(phi, psi, function(phi, psi) { sin(phi)*(a+r*cos(psi)) })\n  zOuter <- outer(phi, psi, function(phi, psi) { r*sin(psi) })\n\n  xCurveOuter <- array(0, c(nCurves, length(phi)))\n  yCurveOuter <- array(0, c(nCurves, length(phi)))\n  zCurveOuter <- array(0, c(nCurves, length(phi)))\n  \n  # for (curve in 1:nCurves) {  # for each solenoid curve on torus\n  #   for (ind in 1:length(phi)) {  # for each point on the curve\n  #     xCurveOuter[curve, ind] <-\n  #       cos(phi[1 + ((ind -1 + curveGap*(curve-1)) %% length(phi))]) *\n  #         (a+r*cos(n*psi2[1 + ((ind -1 + curveGap*(curve-1)) %% length(phi))]))\n  #     yCurveOuter[curve, ind] <-\n  #       sin(phi[1 + ((ind -1 + curveGap*(curve-1)) %% length(phi))]) *\n  #         (a+r*cos(n*psi2[1 + ((ind -1 + curveGap*(curve-1)) %% length(phi))]))\n  #     zCurveOuter[curve, ind] <-  r*sin(n*psi2[1 + ((ind -1 + curveGap*(curve-1)) %% length(phi))])\n  #   }\n  # }\n\n  for (curve in 1:nCurves) {  # for each solenoid curve on torus\n    gamma <- (curve-1)/(2*pi)\n    rotMatZ <- # 3-by-3 rotation matrix around Z axis\n        matrix(c(cos(gamma), sin(gamma),0,  -sin(gamma),cos(gamma),0,   0,0,1), ncol=3)\n    for (ind in 1:length(phi)) {  # for each point on the curve\n      xCurveOuter[curve, ind] <- cos(phi[ind]) * (a+r*cos(n*psi2[ind])) \n      yCurveOuter[curve, ind] <- sin(phi[ind]) * (a+r*cos(n*psi2[ind])) \n      zCurveOuter[curve, ind] <- r*sin(n*psi2[ind])\n      # apply rotation matrix\n      xCurveOuter[curve, ind] <- \n        (rotMatZ %*% c(xCurveOuter[curve, ind], yCurveOuter[curve, ind], zCurveOuter[curve, ind]))[1]\n      yCurveOuter[curve, ind] <-\n        (rotMatZ %*% c(xCurveOuter[curve, ind], yCurveOuter[curve, ind], zCurveOuter[curve, ind]))[2]\n      zCurveOuter[curve, ind] <-  \n        (rotMatZ %*% c(xCurveOuter[curve, ind], yCurveOuter[curve, ind], zCurveOuter[curve, ind]))[3]\n    }\n  }\n  \n# # plot_ly() %>%\n#     add_trace(x=~xOuter, y=~yOuter, z=~zOuter, type='surface', \n#               opacity=0.5, visible=TRUE, showlegend= FALSE, showscale = FALSE) %>%\n#      add_trace(x=xCurveOuter[1,], y=yCurveOuter[1,], z=zCurveOuter[1,], \n#                type=\"scatter3d\", mode=\"markers+lines\", line=list(width=15)) %>%\n#      add_trace(x=xCurveOuter[2,], y=yCurveOuter[2,], z=zCurveOuter[2,], \n#                type=\"scatter3d\", mode=\"markers+lines\", line=list(width=15)) %>%\n#      add_trace(x=xCurveOuter[3,], y=yCurveOuter[3,], z=zCurveOuter[3,], \n#                type=\"scatter3d\", mode=\"markers+lines\", line=list(width=15)) %>%\n#      add_trace(x=xCurveOuter[4,], y=yCurveOuter[4,], z=zCurveOuter[4,], \n#                type=\"scatter3d\", mode=\"markers+lines\", line=list(width=15)) %>%\n#      add_trace(x=xCurveOuter[5,], y=yCurveOuter[5,], z=zCurveOuter[5,], \n#                type=\"scatter3d\", mode=\"markers+lines\", line=list(width=15))\n   \n\n# shape==\"sphere\" \n    phi <- seq(from = 0, to = 2*pi, by = ((2*pi - 0)/(samplingRate - 1)))\n    psi <- seq(from = 0, to = pi, by = ((pi - 0)/(samplingRate - 1)))\n\n    xCurveOuterSphere <- array(0, c(nCurves, length(phi)))\n    yCurveOuterSphere <- array(0, c(nCurves, length(phi)))\n    zCurveOuterSphere <- array(0, c(nCurves, length(phi)))\n  \n    r3 = 1                           # r = 1\n    x3 = r3 * cos(phi) %o% sin(psi)   # x = r*cos(phi)*sin(psi)\n    y3 = r3 * sin(phi) %o% sin(psi)   # y = r*sin(phi)*sin(psi)\n    z3 = r3 * rep(1, samplingRate) %o% cos(psi) # still need z to be 200*200 parameterized tensor/array\n\n    for (curve in 1:nCurves) {  # for each solenoid curve on torus\n      gamma <- (curve-1)/(2*pi)\n      rotMatZSphere <- # 3-by-3 rotation matrix around Z axis\n          matrix(c(cos(gamma), sin(gamma),0,  -sin(gamma),cos(gamma),0,   0,0,1), ncol=3)\n      for (ind in 1:length(phi)) {  # for each point on the curve\n        xCurveOuterSphere[curve, ind] <- r3*cos(phi[ind]) * sin(psi[ind])\n        yCurveOuterSphere[curve, ind] <- r3*sin(phi[ind]) * sin(psi[ind])\n        zCurveOuterSphere[curve, ind] <- r3*cos(psi[ind])\n        # apply rotation matrix\n        xCurveOuterSphere[curve, ind] <- \n          (rotMatZSphere %*% c(xCurveOuterSphere[curve, ind], yCurveOuterSphere[curve, ind],\n                               zCurveOuterSphere[curve, ind]))[1]\n        yCurveOuterSphere[curve, ind] <-\n          (rotMatZSphere %*% c(xCurveOuterSphere[curve, ind], yCurveOuterSphere[curve, ind],\n                               zCurveOuterSphere[curve, ind]))[2]\n        zCurveOuterSphere[curve, ind] <-  \n          (rotMatZSphere %*% c(xCurveOuterSphere[curve, ind], yCurveOuterSphere[curve, ind],\n                               zCurveOuterSphere[curve, ind]))[3]\n      }\n    }\n  # plot_ly() %>%\n  #    add_trace(x=x3, y=y3, z=z3, type='surface', \n  #             opacity=0.5, visible=TRUE, showlegend= FALSE, showscale = FALSE) %>%\n  #    add_trace(x=xCurveOuterSphere[1,], y=yCurveOuterSphere[1,], z=zCurveOuterSphere[1,], \n  #              type=\"scatter3d\", mode=\"markers+lines\", line=list(width=15)) %>%\n  #    add_trace(x=xCurveOuterSphere[2,], y=yCurveOuterSphere[2,], z=zCurveOuterSphere[2,], \n  #              type=\"scatter3d\", mode=\"markers+lines\", line=list(width=15)) %>%\n  #    add_trace(x=xCurveOuterSphere[3,], y=yCurveOuterSphere[3,], z=zCurveOuterSphere[3,], \n  #              type=\"scatter3d\", mode=\"markers+lines\", line=list(width=15)) %>%\n  #    add_trace(x=xCurveOuterSphere[4,], y=yCurveOuterSphere[4,], z=zCurveOuterSphere[4,], \n  #              type=\"scatter3d\", mode=\"markers+lines\", line=list(width=15)) %>%\n  #    add_trace(x=xCurveOuterSphere[5,], y=yCurveOuterSphere[5,], z=zCurveOuterSphere[5,], \n  #              type=\"scatter3d\", mode=\"markers+lines\", line=list(width=15))\n\n# https://plot.ly/r/custom-buttons/\n\n# updatemenus component\nupdatemenus <- list(\n  list(active = -1, type = 'buttons', # active = -1\n    buttons = list(\n      list(label = shapes[1], method = \"update\",  # Complex Plane\n        args = list(list(visible = c(TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE,\n                                     FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, \n                                     FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE)), \n                    list(title = shapeNames[1]))),\n      list(label = shapes[2], method = \"update\",  # Sphere\n        args = list(list(visible = c(FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE,\n                                     TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE,\n                                     FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE)), \n                    list(title = shapeNames[2]))),\n      list(label = shapes[3], method = \"update\",  # Torus\n        args = list(list(visible = c(FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, \n                                     FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, \n                                     TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE)), \n                    list(title = shapeNames[3])))\n    )\n  )\n)\n\n# Complex Plane\np <- plot_ly(x=x1D, y=y1D, z=z0, type=\"surface\", \n             name=\"Complex Plane\", opacity=0.3)\n    for (curve in 1:nCurves) {  # for each solenoid curve on torus\n      y2D[curve, ] <- (curve-nCurves/2)/curveGap + (2+sin(x2D)) + x2D/(supportWidth*pi)\n      p <- p %>% add_trace(x=c(1:samplingRate), y=(y2D[curve,]*samplingRate),\n                           z=1, name=paste0(\"Curve: \", curve), opacity=1,\n                           type=\"scatter3d\", mode=\"lines\")\n    }\np <- p %>% add_trace(type='scatter3d', mode='text', x=150, y=200, z=1, \n              text=\"C=R^2\", showlegend=F, inherit=F) \n# Sphere \np <- p %>%\n     add_trace(x=x3, y=y3, z=z3, type='surface', name=\"Sphere\",\n              opacity=0.5, visible=FALSE, showlegend= FALSE, showscale = FALSE) %>%\n     add_trace(x=xCurveOuterSphere[1,], y=yCurveOuterSphere[1,], z=zCurveOuterSphere[1,], \n        opacity=1, type=\"scatter3d\", mode=\"markers+lines\", line=list(width=15), visible=FALSE) %>%\n     add_trace(x=xCurveOuterSphere[2,], y=yCurveOuterSphere[2,], z=zCurveOuterSphere[2,], \n        opacity=1, type=\"scatter3d\", mode=\"markers+lines\", line=list(width=15), visible=FALSE) %>%\n     add_trace(x=xCurveOuterSphere[3,], y=yCurveOuterSphere[3,], z=zCurveOuterSphere[3,], \n        opacity=1, type=\"scatter3d\", mode=\"markers+lines\", line=list(width=15), visible=FALSE) %>%\n     add_trace(x=xCurveOuterSphere[4,], y=yCurveOuterSphere[4,], z=zCurveOuterSphere[4,], \n        opacity=1, type=\"scatter3d\", mode=\"markers+lines\", line=list(width=15), visible=FALSE) %>%\n     add_trace(x=xCurveOuterSphere[5,], y=yCurveOuterSphere[5,], z=zCurveOuterSphere[5,], \n               type=\"scatter3d\", mode=\"markers+lines\", line=list(width=15), visible=FALSE) %>%\n     add_trace(type='scatter3d', mode='text', x=0.35, y=-0.9, z=0.9, \n                    text='Sphere S^2', showlegend=F, inherit=F, visible=FALSE) %>%\n  # Torus\n     add_trace(x=~xOuter, y=~yOuter, z=~zOuter, type='surface', name=\"Torus\",\n              opacity=0.5, visible=FALSE, showlegend= FALSE, showscale = FALSE) %>%\n     add_trace(x=xCurveOuter[1,], y=yCurveOuter[1,], z=zCurveOuter[1,], visible=FALSE,\n        opacity=1, type=\"scatter3d\", mode=\"markers+lines\", line=list(width=15)) %>%\n     add_trace(x=xCurveOuter[2,], y=yCurveOuter[2,], z=zCurveOuter[2,], visible=FALSE,\n        opacity=1, type=\"scatter3d\", mode=\"markers+lines\", line=list(width=15)) %>%\n     add_trace(x=xCurveOuter[3,], y=yCurveOuter[3,], z=zCurveOuter[3,], visible=FALSE,\n        opacity=1, type=\"scatter3d\", mode=\"markers+lines\", line=list(width=15)) %>%\n     add_trace(x=xCurveOuter[4,], y=yCurveOuter[4,], z=zCurveOuter[4,], visible=FALSE,\n        opacity=1, type=\"scatter3d\", mode=\"markers+lines\", line=list(width=15)) %>%\n     add_trace(x=xCurveOuter[5,], y=yCurveOuter[5,], z=zCurveOuter[5,], visible=FALSE,\n        opacity=1, type=\"scatter3d\", mode=\"markers+lines\", line=list(width=15)) %>%\n     add_trace(type='scatter3d', mode='text', x=6.5, y=-6.5, z=2.5, \n                    text='Torus T^2', showlegend=F, inherit=F, visible=FALSE) %>%\n  layout(title = \"Foliations of 2D Euclidean and Non-Euclidean Spaces\", showlegend = FALSE,\n         scene = list(xaxis=list(title=\"X\"),yaxis=list(title=\"Y\"),zaxis=list(title=\"Z\")),\n         updatemenus=updatemenus) %>% config(mathjax = 'cdn')\np",
      "line_count": 238
    },
    {
      "section": "Wavefunctions",
      "code": "t <- seq(-6*pi, 6*pi, length.out=400)\nr <- 3\nx <- r * cos(t)\ny <- r * sin(t)\nz <- 2*t\nc <- t%%(2*pi)\n  \ndata1 <- data.frame(x, y, z)\n\np <- plot_ly(data1, x = ~x, y = ~y, z = ~z, type = 'scatter3d', mode = 'lines',\n        showlegend = F, name=\"complex wave\",\n        line=list(width=12, color=~c, colorscale=list(c(0,'red'), c(1,'blue')))) %>%\n  # trace the z-axis\n  add_trace(data1, x = 0, y =0, z = ~z, type=\"scatter3d\", mode=\"lines\", \n              line = list(width = 10, color = ~c, colorscale = list(c(0,'red'), c(1,'blue'))),\n            name=\"Z\", hoverinfo=\"none\") %>%\n  # add projection on plane x=-3\n  add_trace(data1, x = -3, y = ~y, z = ~z, type=\"scatter3d\", mode=\"lines\", \n              line = list(width = 2, dash=\"solid\", color = ~c, \n                          colorscale = list(c(0,'gray'), c(1,'black'))),\n            name=\"Z\", hoverinfo=\"none\") %>%\n  # add projection on plane y=-3\n  add_trace(data1, x = ~x, y = -3, z = ~z, type=\"scatter3d\", mode=\"lines\", \n              line = list(width = 2, dash=\"solid\", color = ~c, \n                          colorscale = list(c(0,'gray'), c(1,'black'))),\n            name=\"Z\", hoverinfo=\"none\") %>%\n  # add a z-line at x=-3,y=0\n  add_trace(data1, x = -3, y = 0, z = ~z, type=\"scatter3d\", mode=\"lines\", \n              line = list(width = 5, dash=\"solid\", color = \"gray\"),\n            name=\"Z\", hoverinfo=\"none\") %>%\n  # add a z-line at x=0,y=-3\n  add_trace(data1, x = 0, y = -3, z = ~z, type=\"scatter3d\", mode=\"lines\", \n              line = list(width = 5, dash=\"solid\", color = \"gray\"),\n            name=\"Z\", hoverinfo=\"none\") %>%\n  # add a x-line at y=0, z=-40\n  add_trace(data1, x = ~x, y = 0, z = -40, type=\"scatter3d\", mode=\"lines\", \n              line = list(width = 15, dash=\"solid\", color = \"gray\"),\n            name=\"Z\", hoverinfo=\"none\")\n  # add a few annotations/arrows\np",
      "line_count": 40
    },
    {
      "section": "Wavefunctions",
      "code": "library(plotly)    \nL <- 5\nlinFunct <- function (x) {\n  return (x/L)\n}\nint_val_0.5L   <- round(integrate(linFunct, lower=0, upper=L/2)$value, 3)\nt <- seq(from=0, to=L, length.out = 1000)\n\n# plots\nf_val <- t/L\n\nplot_ly(x = t[1:500], y = f_val[1:500], type = 'scatter', \n        name=paste0(\"Left Half Density y=f(x)=x; Area=\", int_val_0.5L / L),\n        mode = 'lines', fill = 'tozeroy', opacity=0.3) %>%\n  add_trace(x = t[501:1000], y = f_val[501:1000], type = 'scatter', \n        name=paste0(\"Right Half Density y=f(x)=x; Area=\", (L-int_val_0.5L)/L),\n        mode = 'lines', fill = 'tozeroy', opacity=0.3) %>%\n  layout(title=\"Probability Density of a Ball Traveling in a Linear Tube of Length L (fixed time point)\", \n         xaxis=list(title=\"Space\", tickvals=c(0, L/5, 2*L/5, L/2, 3*L/5, 4*L/5, L), \n                    automargin = T, #seq(0, L, length=L+2), \n                    ticktext = c(\"0\", \"L/5\", \"2L/5\", \"L/2\", \"3L/5\", \"4L/5\", \"L\")), \n         yaxis=list(title=\"Probability\"), legend = list(orientation = 'h', y=-0.5))",
      "line_count": 22
    },
    {
      "section": "Wavefunctions",
      "code": "# library(plotly)    \nL <- 5\nkappa <- pi/L\nC <- \nsinFunct2 <- function (x) { \n  #|    | psi(x,t=0)|^2 = (2/L) * sin ( (pi/L) * x ) * * sin ( (pi/L) * x )\n  return ( (2/L) * (sin(x * (pi/L)))^2 )\n}\nint_val_0.25L   <- round(integrate(sinFunct2, lower=0, upper=L/4)$value, 3)\nt <- seq(from=0, to=L, length.out = 1000)\n\n# plots\nf_val <- sqrt(2/L) * sin(t * (pi/L))\n\nplot_ly(x = t[1:250], y = f_val[1:250], type = 'scatter', \n        name=paste0(\"First Quarter Density y=f(x)=C sin(k x); Area=\", int_val_0.25L),\n        mode = 'lines', fill = 'tozeroy', opacity=0.3) %>%\n  add_trace(x = t[251:1000], y = f_val[251:1000], type = 'scatter', \n        name=paste0(\"Right 3 Quarter Density y=f(x)=C sin(k x); Area=\", 1-int_val_0.25L),\n        mode = 'lines', fill = 'tozeroy', opacity=0.3) %>%\n  layout(title=\"Nonlinear Probability Density of a Particle\\n Traveling in a Tube of Length L (fixed time point)\", \n         xaxis=list(title=\"Space\", \n              tickvals=c(0, L/8, 2*L/8, 3*L/8, 4*L/8, 5*L/8, 6*L/8, 7*L/8,L), \n              automargin = T,      #seq(0, L, length=L+2), \n              ticktext = c(\"0\",\"L/8\", \"L/4\", \"3L/8\", \"L/2\", \"5L/8\", \"3L/4\",\n                           \"7L/8\", \"L\")), \n         yaxis=list(title=\"Probability\"), legend=list(orientation='h', y=-0.5))",
      "line_count": 27
    },
    {
      "section": "Copenhagen Quantum Mechanics Interpretation of Wavefunctions",
      "code": "# library(plotly)\nsize=300\nt <- seq(from=0, to=2*pi, length.out=size)\npressure <- cos(5*t)\ndisplacement <- sin(5*t)\ny <- seq(from=-1, to=1, length.out=size)\nz <- pressure %o% rep(1, size)\nplot_ly(x=~t, y=~y, z=~t(z), type=\"heatmap\", colors=\"Greys\", showscale= F) %>%\n  add_trace(x=~t, y=~pressure, type=\"scatter\", mode=\"lines\", name=\"Pressure\",\n            line = list(color = 'blue', width = 5)) %>%\n  add_trace(x=~t, y=~displacement, type=\"scatter\", mode=\"lines\",\n            name=\"Displacement\", line = list(color = 'red', width = 5)) %>%\n  layout(title = \"Displacement and Pressure of a Propagating Sound Wave\", \n         xaxis=list(title=\"time\"), \n         yaxis=list(title=\"Value\", scaleanchor=\"x\", scaleratio=2.2),\n        legend = list(title=list(text='<b>Functions</b>'), orientation='h'))",
      "line_count": 16
    },
    {
      "section": "Expectation Values",
      "code": "library(plotly)\nx <- seq(from=-4, to=4, length.out=2000)\nindexN <- seq(1:10)\ny <- list()\n\np <- plot_ly(type = \"scatter\", mode=\"lines\")\nfor (i in indexN) {\n  y[[i]] <- dnorm(x, mean=0, sd=1/indexN[i])\n  p <- p %>% add_trace(x=x, y=y[[i]], \n                       hovertemplate = paste0(\"Distribution=N(mu=0,sd=1/\", indexN[i], \")\\n\", \"(%{x}, %{y})\"),\n                       name=paste0(\"N(mu=0,sd=1/\", indexN[i], \")\"))\n}\np <- p %>% \n  layout(title=\"Gaussian Test Functions Approximating Dirac Delta\",\n     xaxis=list(title=\"Critical Values\"), yaxis=list(title=\"Densities\"))\np",
      "line_count": 16
    }
  ]
}