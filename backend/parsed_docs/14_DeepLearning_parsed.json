{
  "metadata": {
    "created_at": "2024-11-30T13:46:16.729697",
    "total_sections": 14,
    "total_code_chunks": 138,
    "total_tables": 9,
    "r_libraries": [
      "EBImage",
      "GGally",
      "SnowballC",
      "XML",
      "caret",
      "cowplot",
      "crossval",
      "deepviz",
      "ggplot2",
      "httr",
      "igraph",
      "imager",
      "jpeg",
      "keras",
      "keras3",
      "knitr",
      "magick",
      "magrittr",
      "mlbench",
      "pROC",
      "pins",
      "plotly",
      "purrr",
      "reshape",
      "reticulate",
      "rsample",
      "rvest",
      "stringi",
      "tensorflow",
      "tfaddons",
      "tfdatasets",
      "tfds",
      "tfhub",
      "tfruns",
      "tibble",
      "tidyverse",
      "tm",
      "torch",
      "torchvision",
      "unet",
      "utf8",
      "xml2",
      "zeallot",
      "zip"
    ]
  },
  "sections": [
    {
      "title": "Main",
      "content": "---\ntitle: \"DSPA2: Data Science and Predictive Analytics (UMich HS650)\"\nsubtitle: \"<h2><u>Deep Learning, Neural Networks</u></h2>\"\nauthor: \"<h3>SOCR/MIDAS (Ivo Dinov)</h3>\"\ndate: \"`r format(Sys.time(), '%B %Y')`\"\ntags: [DSPA, SOCR, MIDAS, Big Data, Predictive Analytics] \noutput:\n  html_document:\n    theme: spacelab\n    highlight: tango",
      "word_count": 38
    },
    {
      "title": "before_body: SOCR_header.html",
      "content": "toc: true\n    number_sections: true\n    toc_depth: 4\n    toc_float:\n      collapsed: false\n      smooth_scroll: true\n    code_folding: show",
      "word_count": 13
    },
    {
      "title": "Deep Learning Neural Networks",
      "content": "[Deep learning](https://en.wikipedia.org/wiki/Deep_learning#Deep_neural_%0Anetwork_architectures) is a special branch of machine learning using a collage of algorithms to model high-level motifs in data. Deep learning resembles the biological communications between brain neurons in the central nervous system (CNS), where synthetic graphs represent the CNS network as nodes/states and connections/edges between them. For instance, in a simple synthetic network consisting of a pair of connected nodes, an output sent by one node is received by the other as an input signal. When more nodes are present in the network, they may be arranged in multiple levels (like a multiscale object) where the $i^{th}$ layer output serves as the input of the next $(i+1)^{st}$ layer. The signal is manipulated at each layer and sent as a layer output downstream and interpreted as an input to the next, $(i+1)^{st}$ layer, and so forth. Deep learning relies on multiple layers of nodes and many edges linking the nodes forming input/output (I/O) layered grids representing a multiscale processing network. At each layer, linear and non-linear transformations are converting inputs into outputs.\n\nIn this chapter, we explore the R-based deep neural network learning and demonstrate state-of-the-art deep learning models utilizing CPU and GPU for fast training (learning) and testing (validation). Other powerful deep learning frameworks include *TensorFlow*, *Theano*, *Caffe*, *Torch*, *CNTK* and *Keras*.\n\n*Neural Networks vs. Deep Learning*: Deep Learning is a machine learning strategy that learns a deep multi-level hierarchical representation of the affinities and motifs in the dataset. Machine learning Neural Nets tend to use shallower network models. Although there are no formal restrictions on the depth of the layers in a Neural Net, few layers are commonly utilized. Recent methodological, algorithmic, computational, infrastructure and service advances overcome previous limitations. In addition, the rise of *Big Data* accelerated the evolution of *classical Neural Nets* to *Deep Neural Nets*, which can now handle lots of layers and many hidden nodes per layer. The former is a precursor to the latter, however, there are also *non-neural* deep learning techniques. For example, *syntactic pattern recognition methods* and *grammar induction discover hierarchies*.",
      "word_count": 341
    },
    {
      "title": "Deep Learning Training",
      "content": "Review [Chapter 6 (Black Box Machine-Learning Methods: Neural Networks, Support Vector Machines, and Random Forests)](https://socr.umich.edu/DSPA2/DSPA2_notes/06_ML_NN_SVM_RF_Class.html) prior to proceeding.\n\n## Perceptrons\n\nA **perceptron** is an artificial analogue of a neuronal brain cell that calculates a *weighted sum of the input values* and *outputs a thresholded version of that result*. For a bivariate perceptron, $P$, let’s denote the weights of the two inputs, $(X,Y)$ by $A$ and $B$, respectively. Then, the weighted sum could be represented as: $$W = A X + B Y.$$\n\nAt each layer $l$, the weight matrix, $W^{(l)}$, has the following properties:\n\n - The number of rows of $W^{(l)}$ equals the number of nodes/units in the previous $(l-1)^{st}$ layer, and \n - The number of columns of $W^{(l)}$ equals the number of units in the next $(l+1)^{st}$ layer. \n\nNeuronal cells fire depending on the presynaptic inputs to the cell which causes constant fluctuations of the neuronal membrane - depolarizing or hyperpolarizing, i.e., the cell membrane potential rises or falls. Similarly, perceptrons rely on thresholding of the weight-averaged input signal, which for biological cells corresponds to voltage increases passing a critical threshold. Perceptrons output non-zero values only when the weighted sum exceeds a certain threshold $C$. In terms of its input vector, $(X,Y)$, we can describe the output of each perceptron ($P$) by:\n\n$$Output(P) = \n\\left\\{\n\\begin{array} {}\n    1, & if\\ A X + B Y > C \\\\          \n    0, & if\\ A X + B Y \\leq C\n\\end{array}\n\\right. .$$\n\nFeed-forward networks are constructed as layers of perceptrons where the first layer ingests the inputs and the last layer generates the network outputs. The intermediate (internal) layers are not directly connected to the external world, and are called hidden layers. In *fully connected networks*, each perceptron in one layer is connected to every perceptron on the next layer enabling information \"fed forward\" from one layer to the next. There are no connections between perceptrons in the same layer. \n\nMultilayer perceptrons (fully-connected feed-forward neural networks) consist of several fully-connected layers representing an `input matrix` $X_{n, m}$ and a generated `output matrix` $Y_{n, k}$. The input $X_{n,m}$ is a matrix encoding the $n$ cases and $m$ features per case. The weight matrix $W_{m,k}^{(l)}$ for layer $l$ has rows ($i$) corresponding to the weights leading from all the units $i$ in the previous layer to all of the units $j$ in the current layer.\n\nThe hidden size parameter $k$, the weight matrix $W_{m , k}$, and the bias vector $b_{k}$ are used to compute the outputs at each layer:\n\n$$Y_{n, k}^{(l)} =f_k^{(l)}\\left ( X_{n, m}^{(l)} W_{m , k}^{(l)} +b_{k}^{(l)} \\right ).$$\n\nThe role of the bias parameter is similar to the intercept term in linear regression and helps improve the accuracy of prediction by shifting the decision boundary along the $Y$ axis. The outputs are fully-connected layers that feed into an `activation layer` to perform element-wise operations. Examples of **activation functions** that transform real numbers to probability-like values include:\n\n - the [sigmoid function]( https://en.wikipedia.org/wiki/Sigmoid_function), a special case of the [logistic function](https://en.wikipedia.org/wiki/Logistic_function), which converts real numbers to probabilities, \n - the rectifier (`relu`, [Rectified Linear Unit](https://en.wikipedia.org/wiki/Rectifier_(neural_networks))) function, which outputs the $\\max(0, input)$,\n - the [tanh (hyperbolic tangent function)](https://en.wikipedia.org/wiki/Hyperbolic_function#Hyperbolic_tangent).\n\n\n\nThe final fully-connected layer may be hidden of a size equal to the number of classes in the dataset and may be followed by a `softmax` layer mapping the input into a probability score. For example, if a size ${n\\times m}$ input is denoted by $X_{n\\times m}$, then the probability scores may be obtained by the `softmax` transformation function, which maps real valued vectors to vectors of probabilities:\n\n$$\\left ( \\frac{e^{x_{i,1}}}{\\displaystyle\\sum_{j=1}^m e^{x_{i,j}}},\\ldots, \\frac{e^{x_{i,m}}}{\\displaystyle\\sum_{j=1}^m e^{x_{i,j}}}\\right ).$$\n\nBelow is a schematic of a fully-connected feed-forward neural network of nodes \n$$ \\{ a_{j=node\\ index, l=layer\\ index} \\}_{j=1, l=1}^{n_j, 4}.$$\n\n\n\n\nThe plot above illustrates the key elements in the calculations of the action potential, or activation function, and the corresponding training parameters:\n\n$${a}_{\\textrm{node}=k,\\textrm{layer}=l}=f\\left(\\sum \\limits_i{w}_{k,i}^{(l)}\\times {a}_i^{(l-1)}+{b}_k^{(l)}\\right),$$\nwhere:\n\n - $f$ is the *activation function*, e.g., [logistic function](https://socr.umich.edu/DSPA2/DSPA2_notes/11_FeatureSelection.html) $f(x) = \\frac{1}{1+e^{-x}}$. It converts the aggregate weights at each node to probability values,\n - $w_{k,i}^l$ is the weight carried from the $i^{th}$ element of the $(l-1)^{th}$ layer to the $k^{th}$ element of the current $l^{th}$ layer,\n - $b_{k}^l$ is the (residual) bias present in the $k^{th}$ element in the $l^{th}$ layer. This is the information not explained by the training model.\n\nUsing training data, these network parameters (weights) may be estimated using different techniques, e.g., using [least squares](https://socr.umich.edu/DSPA2/DSPA2_notes/03_LinearAlgebraMatrixComputingRegression.html), [gradient descent  methods](https://socr.umich.edu/DSPA2/DSPA2_notes/13_FunctionOptimization.html), [LASSO/Chapter 11](https://socr.umich.edu/DSPA2/DSPA2_notes/11_FeatureSelection.html), and many different [numerical optimization schemes](https://socr.umich.edu/DSPA2/DSPA2_notes/13_FunctionOptimization.html).",
      "word_count": 746
    },
    {
      "title": "Biological Relevance",
      "content": "There are parallels between biology (neuronal cells) and the mathematical models (perceptrons) for neural network representation. The human brain contains about $10^{11}$ neuronal cells connected by approximately $10^{15}$ synapses forming the basis of our functional phenotypes. The schematic below illustrates some of the parallels between brain biology and the mathematical representation using synthetic neural nets. Every neuronal cell receives multi-channel (afferent) input from its dendrites, generates output signals and disseminates the results via its (efferent) axonal and synaptic connections to dendrites of other neurons. \n\nThe perceptron is a mathematical model of a neuronal cell that allows us to explicitly determine algorithmic and computational protocols for transforming input signals into output actions. For instance, a signal arriving through an axon $x_0$ is modulated by some prior weight, e.g., synaptic strength, $w_0\\times x_0$. Internally, within the neuronal cell, this input is aggregated (summed, or weight-averaged) with inputs from all other axons. Brain plasticity suggests that `synaptic strengths` (weight coefficients $w$) are enhanced by training and prior experience. This learning process controls the direction and influence of neurons on other neurons. Either excitatory ($w>0$) or inhibitory ($w\\leq 0$) influences are possible. Dendrites and axons carry signals to and from neurons, where the aggregate responses are computed and transmitted downstream. Neuronal cells only fire if action potentials exceed a certain threshold. In this situation, a signal is transmitted downstream through its axons. The neuron remains silent, if the summed signal is below the critical threshold. \n\nTiming of events is important in biological networks. In the computational perceptron model, a first order approximation may ignore the timing of neuronal firing (spike events) and only focus on the frequency of the firing. The firing rate of a neuron with an activation function $f$ represents the frequency of the spikes along the axon. We saw some examples of activation functions earlier.\n\nThe diagram below illustrates the parallels between the brain network-synaptic organization and an artificial synthetic neural network.\n\n[![](https://wiki.socr.umich.edu/images/a/a6/DSPA_22_DeepLearning_Fig1.png)](https://wiki.socr.umich.edu/images/a/a6/DSPA_22_DeepLearning_Fig1.png)",
      "word_count": 322
    },
    {
      "title": "Simple Neural Net Examples",
      "content": "Before we look at examples of deep learning algorithms applied to model observed natural phenomena, we will develop a couple of simple networks for computing fundamental Boolean operations.\n\n## Exclusive OR (XOR) Operator\nThe [exclusive OR (XOR) operator](https://en.wikipedia.org/wiki/Exclusive_or) works as a bivariate binary-outcome function, mapping pairs of false (0) and true (1) values to dichotomous false (0) and true (1) outcomes.\n\nWe can design a simple two-layer neural network that calculates `XOR`. The **values within each neuron represent its explicit threshold**, which can be normalized so that all neurons utilize the same threshold, typically $1$. The **value labels associated with network connections (edges) represent the weights of the inputs**. When the threshold is not reached, output is $0$, and when the threshold is reached, the output is $1$.\n\n\nLet's work out manually the 4 possibilities:\n\nWe can validate that this network indeed represents an XOR operator by plugging in all four possible input combinations and confirming the expected results at the end.\n\n\n\n## NAND Operator\nAnother binary operator is `NAND` ([negative AND, Sheffer stroke](https://en.wikipedia.org/wiki/NAND_gate)) that produces a false (0) output if and only if both of its operands are true (1), and generates true (1), otherwise. Below is the `NAND` input-output table.\n\nSimilar to the `XOR` operator, we can also design a one-layer neural network that calculates `NAND`. The **values within each neurons represent its explicit threshold**, which can be normalized so that all neurons utilize the same threshold, typically $1$. The **value labels associated with network connections (edges) represent the weights of the inputs**. When the threshold is not reached, the output is trivial ($0$) and when the threshold is reached, the output is correspondingly $1$. Here is a shorthand analytic expression for the `NAND` calculation:\n\n$$NAND(X,Y) = 1.3 - (1\\times X + 1\\times Y).$$\nCheck that $NAND(X,Y)=0$ if and only if $X=1$ and $Y=1$, otherwise it equals $1$.\n\n\n## Complex networks designed using simple building blocks \n\nObserve that stringing some of these primitive networks together, or/and increasing the number of hidden layers, allows us to model problems with exponentially increasing complexity. For instance, constructing a 4-input `NAND` function would simply require repeating several of our 2-input `NAND` operators. This will increase the space of possible outcomes from $2^2$ to $2^4$. Of course, introducing more depth in the **hidden layers** further expands the complexity of the problems that can be modeled using neural nets.\n\nYou can interactively manipulate the [Google's TensorFlow Deep Neural Network Webapp](https://playground.tensorflow.org) to gain additional intuition and experience with the various components of deep learning networks. \n\nThe [ConvnetJS demo provides another hands-on example using 2D classification with 2-layer neural network]( https://cs.stanford.edu/people/karpathy/convnetjs/demo/classify2d.html).",
      "word_count": 435
    },
    {
      "title": "Neural Network Modeling using `Keras`",
      "content": "There are many different neural-net and deep-learning frameworks. The table below summarizes some of the main deep learning `R` packages.\n\n## Iterations - Samples, Batches and Epochs\n\nMost DL/ML `R` packages provide interfaces (APIs) to libraries that are built using foundational languages like C/C++ and Java. Most of the Python libraries also act as APIs to lower-level executables compiled for specific platforms (Mac, Linux, PC).\n\nThe `keras` package uses the `magrittr` package `pipe` operator (`%>%`) to join multiple functions or operators, which streamlines the readability of the script protocol. Also, the library `zeallot` supplies the reverse piping function \"%<-%\", used in multiple assignment operators, see `brain_dataset()` function later.\n\nThe `kerasR` package contains functions analogous to the ones in `keras` and utilizes the $\\$$ operator to create models. There are parallels between the core `Python` methods and their `keras` counterparts: `compile()` and `keras_compile()`, `fit()` and `keras_fit()`, `predict()` and `keras_predict()`.\n\nBelow we will demonstrate the utilization of the `Keras` package for deep neural network analytics. This will require installation of `keras` and `TensorFlow` via `R` `devtools::install_github(\"rstudio/keras\")`. For additional details, see the `keras` [installation reference](https://tensorflow.rstudio.com/reference/keras/install_keras/), [user guide and FAQs](https://tensorflow.rstudio.com/guide/keras/faq/).\n\n\nWe start by installing `keras`, which would install the `keras` library, \n`Tensorflow` and other dependencies. After the installation the `R` session will restart. \nThe following two blocks of code are *run manually only once*, to install the\nnecessary system libraries, mind the flag `eval=FALSE`, then restart the entire\nRStudio session.\n\n\nThe below cell will install tensorflow dataset wrapper for `R`.\n\n\n\n\n\nBefore we start training load all the necessary libraries into the R session.\n\n\nThe [`Keras` package](https://keras.rstudio.com/) includes built-in datasets with `load()` functions, e.g., `mnist.load_data()` and `imdb.load_data()`.\n\n\n## Use-Case: Predicting Titanic Passengers Survival\n\nInstead of using the default data provided in the `keras` package, we will utilize one of the datasets on the [DSPA Case-Studies Website](https://umich.instructure.com/courses/38100/files/folder/Case_Studies), which can be loaded much like [we did earlier in Chapter 2](https://socr.umich.edu/DSPA2/DSPA2_notes/02_Visualization.html). Below, we download the [Titanic Passengers Dataset](https://umich.instructure.com/courses/38100/files/folder/data/16_TitanicPassengerSurvivalDataset) and perform some preprocessing steps.\n\n\n## EDA/Visualization\n\nWe can start by some [simple EDA plots](https://socr.umich.edu/DSPA2/DSPA2_notes/02_Visualization.html), reporting some numerical summaries, examining pairwise correlations, and showing the distributions of some features in this dataset.\n\n\n## Data Preprocessing\n\nBefore we go into modeling the data, we need to preprocess it, e.g., normalize the numerical values and split it into training and testing sets.\n\n\nUse `keras::normalize()` to normalize the numerical data. See [the details about installing `keras`, `TensorFlow`, and their dependencies in R/Python/Posit/RStudio environment](https://tensorflow.rstudio.com/reference/tensorflow/install_tensorflow).\n\n\nNext, we'll partition the raw data into *training* (80%) and *testing* (20%) sets that will be utilized to build the forecasting model (to predict Titanic passenger survival) and assess the model performance, respectively. \n\n\n## Keras Modeling\n\nFor *multi-class classification problems* via NN modeling, the `keras::to_categorical()` function allows us to transform the outcome attribute from a vector of class labels to a matrix of Boolean features, one for each class label. In this case, we have a bivariate (binary classification), passenger survival indicator.\n\nKeras modeling starts with first initializing a sequential model using the `keras::keras_model_sequential()` function. \n\nWe will try to predict the passenger survival using a fully-connected multi-layer perceptron NN. We will need to choose an activation function, e.g., `relu`, `sigmoid`. A rectifier activation function (relu) may be used in a hidden layer and a `softmax` activation function may be used in the final output layer so that the outputs represent (posterior) probabilities between 0 and 1, corresponding to the odds of survival. In the first layer, we can specify 8 hidden nodes (`units`), an `input_shape` of 4, to reflect the 4 features in the training data *age*, *fare*, *price*, *ticketcount*, and the output layer with 2 output values, one for each of the survival categories. We can also inspect the structure of the NN model using:\n\n - `summary()`: print a summary representation of your model,\n - `get_config()`: return a list that contains the configuration of the model,\n - `get_layer()`: return the layer configuration,\n - `$layers`: NN model attribute retrieves a flattened list of the model's layers,\n - `$inputs`: NN model attribute listing the input tensors,\n - `$outputs`: NN model attribute retrieves the output tensors.\n\n\nOnce the model architecture is specified, we need to estimate (fit) the NN model using the `training` data. The adaptive momentum (`ADAM`) optimizer along with `categorical_crossentropy` objective function may be used to **compile** the NN model. Specifying `accuracy` as a metrics argument allows us to inspect the quality of the NN model fit during the training phase (training data validation). The *optimizer* and the *objective* (loss) functions are the pair of required arguments for model compilation. \n\nIn addition to *ADAM*, alternative optimization algorithms include Stochastic Gradient Descent (*SGD*) and Root Mean Square proportion (*RMSprop*). ADAM is essentially RMSprop with momentum whereas NADAM is ADAM RMSprop with Nesterov momentum. Following the selection of the optimization algorithm, we need to tune the model parameters, e.g., learning rate or momentum. Choosing an appropriate objective function depends on the classification or regression forecasting task, e.g., regression prediction (continuous outcomes) usually utilizes Mean Squared Error (*MSE*), whereas multi-class classification problems use *categorical_crossentropy* loss function and binary classification problems commonly use *binary_crossentropy* loss function.\n\n\n## NN Model Fitting\n\nThe next step fits the NN model (`model.1`) to the training data using 200 epochs, or iterations over all the samples in `train_dat2.X` (predictors) and `train_dat2.Y` (outcomes), in batches of 10 samples. This process trains the model on a specified number of epochs (iterations or exposures) on the training data. One epoch is a single pass through the whole training set followed by comparing the model prediction results against the verification labels. The batch size defines the number of samples being propagated through the network at once (as a batch). \n\n\n## Convolutional Neural Networks (CNNs)\n\nConvolutional Neural Networks represent a specific type of Deep Learning algorithm that incorporates the topological, geometric, spatial and temporal structure of the input data (generally images) and assigns importance by learning the weights and biases of the (image) intensities associated with the objects or affinities present in the data. These important features are then utilized to differentiate between datasets (images) or components within the data (structure and objects in images). CNNs require less pre-processing compared to other DL classification algorithms, which may depend on manually-specified filters. CNNs tend to learn these filters by iteratively extrapolating multi-resolution characteristics in the data objects by convolution methods. See the [DSPA Appendix for the mathematical operation convolution and its applications in image processing](https://socr.umich.edu/DSPA2/DSPA2_notes/DSPA_Appendix_6_ImageFilteringSpectralProcessing.html).\n\nRecall that one may attempt to learn the features of an image (or a higher dimensional tensor) by flattening the image array (matrix/tensor) into a 1D vector. This vectorization works well if there are no spatiotemporal dependencies in the data. Most of the time, there are such image intensity correlations that can’t be ignored. The CNN architecture facilitates a mechanism to better model the intrinsic image affinities, reduce the number of DNN parameters, and produce more reliable predictions. Many images are represented as tensors whose modes (dimensions) encode spatial, temporal, color-channel, and other information about the observed image intensity. For instance, an RGB image of size $1,000 \\times 1,000=10^6$ pixels, may require 3MB of memory/storage. A CNN learns to encode the image into a higher-dimensional multispectral hierarchical tensor encoding the intrinsic image characteristics that can lead to easy classification of similar images or generation of synthetic images. For instance, ignoring the color-channels and using a stride=10, convolving the original image of dimension with a kernel of size $10\\times 10$ would yield another (smoother) lower-resolution image of size $100\\times 100$, encoding the convolved features. \n\nThe convolution process aims to extract the high-level features such as edges, borders, and contrasts from the input image. CNNs involve both convolutional and dense layers. Much like the [Fourier transform](https://www.socr.umich.edu/TCIU/HTMLs/Chapter3_Kime_Phase_Problem.html), the first convolutional layer captures low-level features such as edges, color, gradient orientation, etc. Subsequent layers progressively add higher-level details and the entire CNN holistically encodes the understanding of the input image structure.\n\nConvolution, de-convolution (the reverse process) and padding reduce or increase the image dimensionality. \nMost CNNs mix *convolutional layers* with *pooling layers*. The latter are responsible for reducing the spatial size of the convolved features, which decreases the computational data processing demand. Pooling may be implemented as *Max Pooling* or *Average Pooling*. Max-pooling takes an image patch defined by the kernel and returns the maximum intensity value. It performs noise-suppression as it decimates noisy pixel intensities, denoises the image, and reduces the image dimensions. Average-pooling returns the average of all intensity values covered by the image-kernel and reduces the image dimension.\n\nJointly, the convolutional and pooling processes form the CNN $i$-th layer and the number of layers may reflect the ANN complexity. Fully connected layers are typically added to the ANN architecture to enhance the classification, prediction, or regression performance of DL models. Fully-connected layers provide a mechanism to learn non-linear associations and non-affine characteristics of high-level features captured as outputs of the convolutional layers. \n\n## Model EDA\n\nWe can visualize the model fitting process using `keras::plot()` jointly depicting the loss of the objective function and the accuracy of the model, across epochs. Alternatively, we can split the pair of plots - one for the *model loss* and the other for the *model accuracy*. The $\\$$ operator is used to access the tensor data and plot it step-by-step. A sign of overfitting may be an accuracy (on training data) that keeps improving while the accuracy (on the validation data) worsens. This may be an indication that the NN model started to *learn* noise in the data instead of learning real patterns or affinities in the data. While the accuracy trends of both datasets are rising towards the final epochs, this may indicate that the model is still in the process of learning on the training dataset (and we can increase the number of epochs).\n\n\n## Passenger Survival Forecasting using New Data\n\nOnce the model is fit, we can use it to predict the survival of passengers using the testing data, `test_dat2.X`. As we have seen before, `predict()` provides this functionality. Finally, we can evaluate the performance of the NN model by comparing the predicted class labels and `test_dat2.Y` using `table()` or `confusionMatrix()`.\n\n\nWe can also utilize the `evaluate()` function to assess the model quality using testing data.\n\n\n## Fine-tuning the NN Model\n\nThe main NN model parameters we can adjust to improve the model quality include:\n\n - the *number of layers*,\n - the *number of nodes* within layers (*hidden units*),\n - the *number of epochs*,\n - the *batch size*.\n  \nModels can be improved by adding additional layers, increasing the number of hidden units, and by tuning the optimization parameters in `compile()`. Let's first try to add another layer to the N model.\n\n\nNext we can examine the effects of adding more *hidden units* to the NN model.\n\n\nFinally, we can attempt to fine-tune the optimization parameters provided to the `compile()` function. For instance, we can experiment with alternative optimization algorithms, like the Stochastic Gradient Descent (SGD), `optimizer_sgd()`, and adjust the *learning rate*, `learning_rate`. In addition, we can specify alternative learning rate to train the NN, typically by 10-fold increase or decrease, which trades algorithmic accuracy, speed of convergence, and avoidance of local minima.\n\n\n## Model Export and Import\n\nIntermediate and final NN models may be saved, (re)loaded, and exported using of `save_model_hdf5()` and `load_model_hdf5()` based on the [HDF5 file format (h5)](https://support.hdfgroup.org/HDF5/whatishdf5.html). We can operate on *complete models* on just on the *model weights*. the models can also be exported in [JSON](https://www.json.org) or [YAML](https://yaml.org) formats using `model_to_json()` and `model_to_yaml()`, and their load counterparts `model_from_json()` and `model_from yaml()`.\n  \n\nLet's demonstrate loading several pre-trained models, [(resnet50)](https://keras.io/api/applications/resnet/), [VGG16](https://keras.io/api/applications/vgg/), [VGG19](https://keras.io/api/applications/vgg/), and using them for simple out-of-the-box image classification and automated labeling of an [image of New Zealand's Lake Mapourika](https://upload.wikimedia.org/wikipedia/commons/2/23/Lake_mapourika_NZ.jpeg). This image recognition example will be expanded later. For now, we will simply illustrate the quick and efficient utilization of an existing pretrained neural network to qualitatively describe an image in a narative form.",
      "word_count": 1974
    },
    {
      "title": "Classification examples",
      "content": "## Sonar data example\n\nLet's load the `mlbench` packages which includes a [Sonar data](https://www.rdocumentation.org/packages/mlbench/versions/2.1-1/topics/Sonar) `mlbench::Sonar` containing information about sonar signals bouncing off a metal cylinder or a roughly cylindrical rock. Each of 208 observations includes a set of 60 numbers (features) in the range 0.0 to 1.0, and a label M (metal) or R (rock). Each feature represents the energy within a particular frequency band, integrated over a certain period of time. The M and R labels associated with each observation classify the record as rock or mine (metal) cylinder. The numbers in the labels are in increasing order of aspect angle, but they do not encode the angle directly. \n\n\nLet's start by using a **multi-layer perceptron** as a classifier using a general multi-layer neural network that can be utilized to do classification or regression modeling. It relies on the following parameters:\n\n* Training data and labels,\n* Number of hidden nodes in each hidden layer,\n* Number of nodes in the output layer,\n* Type of activation,\n* Type of output loss.\n\nHere is one example using the *training* and *testing* data we defined above:\n\n\n*Note* that you may need to specify `crossval::confusionMatrix()`, in case you also have the `caret` package loaded, as `caret` also has a function called `confusionMatrix()`.\n\n\nWe can plot the ROC curve and calculate the AUC (Area under the curve). Specifically, we will show computing the *area under the curve (AUC)* and drawing the *receiver operating characteristic (ROC)* curve. Assuming 'positive' ranks higher than 'negative', the [AUC](https://en.wikipedia.org/wiki/Receiver_operating_characteristic#Area_under_the_curve) quantifies the probability that a classifier will rank a randomly chosen positive instance higher than a randomly chosen negative instance. For binary classification, interpreting the AUC values, $0\\leq AUC\\leq 1$, corresponds with (poor) *uninformative classifiers* when $AUC=0.5$ and perfect classifiers when $AUC\\to 1^-$.",
      "word_count": 295
    },
    {
      "title": "Case-Studies",
      "content": "Let's demonstrate deep neural network regression-modeling and classification-prediction using several biomedical case-studies.\n\n## Schizophrenia Neuroimaging Study\n\n[The SOCR Schizo Dataset is available here](http://wiki.stat.ucla.edu/socr/index.php/SOCR_Data_Oct2009_ID_NI).\n\n\nTo get a visual representation of the deep learning network we can display the computation graph (this code is suppressed).\n\n\n\n## ALS regression example\n\nThe second example demonstrates a deep learning regression using the [ALS data](\"https://umich.instructure.com/files/1789624/download?download_frd=1) to predict `ALSFRS_slope`. Note that in this case the clinical feature we are predicting, $Y=ALSFRS_{slope}$ (ALS functional rating scale progression over time), is a continuous outcome. Hence, we have a *regression problem*, which requires a different `keras` network formulation from the *categorical or binary classification problem* above.\n\nIn general, normalizing all data features ensures the model is scale- and range-invariant. Feature normalization may not be always necessary, but it helps with improving the network training and ensures the resulting network prediction is more robust. The function `tfdatasets::feature_spec()` provides tensorflow data normalization for tabular data.\n\n\n\nThe `feature_spec` output *spec* is used together with the `keras::layer_dense_features()` method to directly perform pre-processing in the TensorFlow graph. We can take a look at the output of a dense-features layer created by the `feature_spec`, which is a matrix (2D tensor) with scaled values.\n\n\nNext, we design the network architecture model using the `feature_spec` API by passing the `dense_features` from the new *spec* object.\n\n\nIt's time to compile the deep network model and wrap it into a function `build_model()` that can be reused for different experiments. Remember that `keras::fit()` modifies the model in-place.\n\n\nModel training follows with 200 epochs where we record the training and validation accuracy in a *keras_training_history* object. For tracking the learning progress, we use a custom callback to replace the default training output at each epoch by a single dot (period) printed in the console .\n\n\nLet's visualize the model’s training data performance using the metrics stored in the history object. This graph provides clues to determine training duration and confirm model performance convergence.\n\nThis graph shows little improvement in the model after about 200 epochs. Let’s update the fit method to automatically stop training when the validation score doesn’t improve. We’ll use a callback that tests a training condition for every epoch. If a set number of epochs elapses without showing improvement, it automatically stops the training.\n\n\n\nHave a look at the [Google TensorFlow API](http://playground.tensorflow.org/#activation=tanh&batchSize=10&dataset=circle&regDataset=reg-plane&learningRate=0.03&regularizationRate=0&noise=0&networkShape=4,2&seed=0.81083&showTestData=false&discretize=false&percTrainData=50&x=true&y=true&xTimesY=false&xSquared=false&ySquared=false&cosX=false&sinX=false&cosY=false&sinY=false&collectStats=false&problem=classification&initZero=false&hideText=false). It shows the importance of *learning rate* and the *number of rounds*. You should test different sets of parameters. \n\n - Too small *learning rate* may lead to long computations.\n - Too large *learning rate* may cause the algorithm to fail to converge, as large step size (learning rate) may by-pass the optimal solution and then oscillate or even diverge.\n\nFinally, we can forecast and predict the ALSFRS_slope using data in the testing set:\n\n\n\n## IBS Study\nLet's try another example using the [IBS NI Study data](http://wiki.stat.ucla.edu/socr/index.php/SOCR_Data_April2011_NI_IBS_Pain). Again, we will use deep neural network learning to predict a categorical/binary classification label (diagnosis, DX).\n\n\nThese results suggest that the DNN classification of IBS diagnosis is not good (at least under the specific network topology and training conditions).\n\n\n## Country QoL Ranking Data\n\nAnother case-study we have seen before is the [country quality of life (QoL) dataset](http://wiki.stat.ucla.edu/socr/index.php/SOCR_Data_2008_World_CountriesRankings). Let's try to fit a network model and use it to predict the overall QoL. This is another binary classification problem categorizing countries as either *developed* or *developing.*\n\n\nNote that even a simple DNN network rapidly converges to an accurate model. \n\n## Handwritten Digits Classification\n\nIn [Chapter 6 (ML, NN, SVM Classification)](https://socr.umich.edu/DSPA2/DSPA2_notes/06_ML_NN_SVM_RF_Class.html) we discussed Optical Character Recognition (OCR). Specifically, we analyzed handwritten notes (unstructured text) and converted it to printed text.\n\nThe [Modified National Institute of Standards and Technology (MNIST) database](https://yann.lecun.com/exdb/mnist/) includes a large handwritten digits imaging dataset with human annotated labels. Every digit is represented by a $28\\times 28$ thumbnail image. You can download the training and testing data from [Kaggle](https://www.kaggle.com/c/digit-recognizer/data).\n\nThe `train.csv` and `test.csv` data files contain gray-scale images of hand-drawn digits, $0, 1, 2, \\ldots, 9$. Each 2D image is $28\\times 28$ in size and each of the $784$ pixels has a single pixel-intensity representing the lightness or darkness of that pixel (stored as a 1 byte integer $[0,255]$). Higher intensities correspond to darker pixels.  \n\nThe training data, `train.csv`, has 785 columns, where the first column, **label**, codes the actual digit drawn by the user. The remaining  $784$ columns contain the $28\\times 28=784$ pixel-intensities of the associated 2D image. Columns in the training set have $pixel_K$ names, where $0\\leq K\\leq 783$. To reconstruct a 2D image out of each row in the training data we use this relation between pixel-index ($K$) and $X,Y$ image coordinates: \n\n$$K = Y \\times 28 + X,$$\nwhere $0\\leq X, Y\\leq 27$. Thus, $pixel_K$ is located on row $Y$ and column $X$ of the corresponding 2D Image of size $28\\times 28$. For instance, $pixel_{60=(2\\times 28 + 4)} \\longleftrightarrow (X=4,Y=2)$ represents the pixel on the 3-rd row and 5-th column in the image. Diagrammatically, omitting the \"pixel\" prefix, the pixels may be ordered to reconstruct the 2D image as follows:\n\n\nNote that the point-to-pixelID transformation ($K = Y \\times 28 + X$) may easily be inverted as a pixelID-to-point mapping: $X= K\\ mod\\ 28$ (remainder of the integer division ($K/28$) and $Y=K %/%28$ (integer part of the division $K/28$)). For example:\n\n\nThe `test data` (test.csv) has the same organization as the training data, except that it does not contain the first **label** column. It includes 28,000 images and we can predict image labels that can be stored as $ImageId,Label$ pairs, which can be visually compared to the 2D images for validation/inspection.\n\n\nLet's look at some of these example images:\n\n\nIn these CSV data files, each $28\\times 28$ image is represented as a single row. Gray-scale images are $1$ byte, in the range $[0, 255]$, which we linearly transformed into $[0,1]$. Note that we only scale the $X$ input, not the output (labels). Also, we don't have manual gold-standard validation labels for the testing data, i.e., `test.y` is not available for the handwritten digits data.\n\n\nNext, we can transpose the input matrix to $n\\ (pixels) \\times  m\\ (examples)$, as the column major format required by the classifiers. The image labels are evenly distributed:\n\n\nThe majority class (`1`) in the training set includes 11.2% of the observations.\n\n### Configuring the Neural Network\n\nThe neural network model is trained by feeding the training data, i.e., *training images (train.x)* and *training labels (train.y)*. The network learns to associate specific images with concrete labels. Then, the network generates label predictions for (new) *testing images* that can be compared to the true labels of test-images (if these are available) or visually inspected to confirm correct auto-classification.\n\nThe `magrittr` package pipe operator, `%>%`, is commonly used for short-hand notation to allow left-and-right feed-and-assignment that can be interpreted as “do <something> then feed into and do <subsequent operation>”.\n\nNodes and layers represent the basic building-blocks of all artificial neural networks. Both are generalizations of brain neuron and network data processing that effectively transform, compress, or filter the input data. *Inputs* go in a node or a layer, and *outputs* come out. Network layers learn to extract effective representations of the inputs that are coded as meaningful outputs that can be connected by chaining together multiple layers that progressive distill the information into compressed generic knowledge (patterns) that can be used to predict, forecast, classify, or model the mechanistic relations in the process. That is, we use data as a proxy of observable processes for which we don;t have explicit closed-form probability distribution models (typically complex multivariate processes).\n\nThe network below chains a pair of layers densely connected (i.e., fully connected neural layers). The `keras_model_sequential()` method specifies the network architecture before we start with training (i.e., estimating the weights). The *loss function* specifies how the network measures its performance on the\ntraining data to adjust the network weights (using train.x and train.y) to optimize the loss. The *optimizer* specifies the mechanism for updating the network weight coefficients using the training data relative to the specified loss function. Different metrics can be used to track the performance during the iterative training and testing process. For instance, accuracy represents the fraction of the images that were correctly classified. The second layer is a *10-way softmax layer* that returns a vector of 10 probability scalars (all positive and summing to 1) each representing the probability that the current hand-written image represents any of the 10 digits ($0, 1, 2, \\cdots,9$). The `compile()` function modifies the network in place to specify the optimization strategy, the loss function and the assessment metric that will be used in the learning process.\n\nIn this network example, we chain two dense layers to each layer and apply simple tensor operations (tensor-dot-product/matrix multiplication and tensor addition) to the input data to estimate the weight parameter tensors, i.e., attributes of the layers encoding the persistent knowledge of the network. The `categorical_crossentropy` is the specific loss function that is optimized in the training phase to provide a feedback signal for learning the weight tensors. The loss optimization relies on mini-batch stochastic gradient descent, which is defined by the `rmsprop` optimizer argument.\n\n\n\nConcatenating dense layers allows us to build a neural network whose depth is determined by the number of layers that are specified by a version of `layer_dense(units = 512, activation = \"relu\")`, which represents a function of the input (2D tensor) and output a different 2D tensor that may be fed as input tensor to the next layer. Let $ReLu(x)=\\max(x, 0)$. $W$ and $b$ represent two of the attributes of the layer (trainable weight parameters of the layer), i.e., the 2D kernel tensor and the bias vector. Then the layer-output $O$ is:\n\n$$O= ReLu( W\\times Input + b).$$\n\nDeep learning network models are represented as directed, acyclic graphs of layers. Often, these networks constitute a linear stack of layers mapping a single input to a single output. Different types of network layers are appropriate for different kinds of data tensors:\n\n - Simple vector data, stored in *2D tensors* of shape $(samples,features)$, are often modeled using densely connected layers, i.e., fully connected dense layers (`keras::layer_dense function()`). \n - Sequence data, stored in *3D tensors* of shape $(samples, timesteps, features)$, are typically modeled by recurrent layers such as `keras::layer_lstm()`. \n - Image data, stored in *4D tensors*, is usually processed by 2D convolution layers (`keras::layer_conv_2d()`).\n \n\n### Training\n\nWe are ready to start the network training process. At the initialization step of the learning process, the weight matrices are filled with random values (random initialization). At the start, when $W$ and $b$ are random, the output `relu(W*Input) + b` is likely going to be meaningless. However, the subsequent iterative\nprocess optimizing the objective (loss) function will gradually adapt to these weights (training process) by repeating the following steps until certain stopping criterion is met:\n\n - Draw a (random) batch of training samples $x$ and their corresponding targets $y$.\n - Forward pass: Run the network on $x$ to obtain predictions $y_{pred}$. \n - Estimate the loss of the network on the batch data assessing the mismatch between $y$ and $y_{pred}$.\n - Update all weights ($W$ and $b$) of the network to reduce the overall loss on this batch.\n\nIterating this process eventually yields a network that has a low loss on its training data indicating good fidelity (match between predictions $y_{pred}$ and expected targets $y$). This reflects the network learning process progressed and accurately maps inputs to correct targets. See the [BPAD Mathematical Foundations Chapter](https://socr.umich.edu/BPAD/BPAD_notes/Biophysics430_Chap01_MathFoundations.html) for more information on calculus of differentiation and integration, gradient minimization, and loss optimization. \n\n**Stochastic gradient descent (SGD)** is a powerful function optimization strategy for differentiable multivariate functions. Recall that function's extrema are attained at points where the derivative (gradient, $\\nabla (f)$) is trivial ($0$) or at the domain boundary. Hence, to minimize the loss, we need to find all points (parameter vectors/tensors) that correspond to trivial derivatives/gradients of the objective function $f$. Then, pick the parameter vectors/tensors/points leading to the smallest values of the loss. In neural network learning, this means analytically finding the combination of weight values corresponding to the smallest possible loss values. \n\nThis optimization is achieved at $W_o$ when $\\nabla (f)(W_o) = 0$. Often, this gradient equation is a polynomial equation of $N$ parameters (variables) corresponding to the number of coefficients ($W$ and $b$) in the network. For large networks (with millions of parameters), this optimization is difficult. An approximate solution may be derived using alternative numerical solutions. This involves incrementally modifying the parameters and assuming the loss function is differentiable. We can then compute its gradient, which points the direction of the fastest growth or decay of the objective function.\n\n - Draw a (random) batch of training samples $x$ and their corresponding targets $y$.\n - Forward pass: Run the network on $x$ to obtain predictions $y_{pred}$. \n - Estimate the loss of the network on the batch data assessing the mismatch between $y$ and $y_{pred}$.\n - Compute the gradient of the loss $\\nabla (f)$ with regard to the network’s parameters (a backward pass).\n - Slightly update/adjust the parameters in the opposite direction of the gradient, e.g., $W = W-(step \\times gradient)$, which reduces the loss function value on the batch data.\n \nIn practice, neural network learning depends on chaining many tensor operations. For instance, a network $f$ composed of three tensor operations $a$, $b$, and $c$, with weight matrices $W_1$, $W_2$, and $W_3$ can be expressed as $f(W_1, W_2, W_3) = a(W_1, b(W_2, c(W_3)))$. The chain-rule for differentiation yields that  $f(g(x)) = f'(g(x)) \\times g'(x)$ leads to a corresponding neural network optimization algorithm (*backpropagation*), which starts with the final loss value and works backward from the top layers to the bottom layers, sequentially applying the chain rule to compute the contribution of each parameter to the aggregate loss value.\n\n\n\nLet's now train (fit or estimate) the neural network model using `keras`. In general, the first mode (axis) in the data tensors is typically the sample axis (sample dimension). Often, it's difficult to process all data at the same time, breaking the data into small **batches**, e.g., batch_size=128, allows for more effective, efficient, and tractable processing (learning). The MNIST tensor consists of images, saved as 3D color arrays indexed by height, width, and depth, where gray-scale images (like the MNIST digits) have only one color channel. In general, image tensors are always 3D. Hence, a batch of 128 gray-scale images of size $256\\times 256$ is stored in a tensor of *shape* $(128, 256, 256, 1)$, whereas a batch of 128 color (RGB) images is stored as a $(128, 256, 256, 3)$ tensor.\n\n\nInvoking the method `fit()` launches the iterative network learning on the training data using mini-batches\nof 128 samples. Each iteration over all the training data is called an **epoch**. Here we use epoch=10 to indicate looping 10 times over. At each iteration, the network computes the gradients of the weights with regard to the loss on the batch and updates the tensor weights. After completing 10 epochs, the network learning performed 3,290 gradient updates (329 per epoch), which progressively reduced the loss of the network from $10^{-2}$ to $10^{-4}$. This low loss indicates the network learned to classify handwritten digits with high accuracy (0.99).\n\nDuring the training process, two graphs are dynamically shown that illustrate the parity between the network loss function (expected to decrease) and the accuracy of the network, using the training data.\nNote that the accuracy approaches 0.99, but remember, this is training-data sample-accuracy, which is biased. \nTo get a more realistic performance estimate, we can test the model on an independent set of 10,000 testing data images.\n\n\nThe testing data accuracy is 0.9886, on par with the training data performance, which indicates no evidence of overfitting.\n\n\n### Forecasting\n\nNext, we will generate forecasting using the model on testing data and evaluate the prediction performance. The `preds` matrix has $28,000$ rows and $10$ columns, containing the desired classification probabilities from the `output layer` of the neural net. To extract the maximum label for each row, we can use the `max.col`:\n\n\nThe predictions are stored in a 1D $28,000(rows)$ vector, including the predicted classification labels generated by the network output layer.\n\n\n\n### Examining the Network Structure\n\nThere are a variety of network topologies, e.g., two-branch networks, multi-head networks, inception blocks, etc., that encode the *a priori* hypothesis space of predefined possibilities. Specifying the network topology constrains the space of possibilities to a specific series of tensor operations that map input data onto outputs. Then, the learning only searches for a good set of network parameter values (the weight tensors involved in these tensor operations). Specifying the network architecture in advance is as much an art as it is science.\n\nThere are two main strategies to define an a priori network topology model. Linear stacks of network layers are specified using the `keras::keras_model_sequential()` method, whereas functional API's provide interfaces for specifying directed acyclic graph (DAG) layer networks with more flexible architectures. Functional network APIs facilitate managing the data tensors processed by the model as well as applying layers to tensors just as though the layers are abstract functions. In the compilation step below, we configure the learning process by specifying the model optimizer and loss functions, along with the metrics for tracking the iterative learning process.\n\n\n\n### Model Validation\n\nWe can use *accuracy* to track the performance of the NN training during the learning process on new (prospective) data.\n\n\nNote that the `keras::predict()` method only works with *Sequential* network models. However, when using the functional API network model we need to use the `keras::predict()` method to obtain a vector of probabilities and then get the *argmax* of this vector to find the most likely class label for the image.",
      "word_count": 2938
    },
    {
      "title": "Classifying Real-World Images using *Tensorflow* and *Keras*",
      "content": "A real-world example of deep learning is the classification of 2D images (pictures) or 3D volumes (e.g., neuroimages).\n\nWe will demonstrate the use of **pre-trained** network models ([resnet50](https://keras.io/api/applications/resnet/), [vgg16](https://keras.io/api/applications/vgg/), and [vgg19](https://keras.io/api/applications/vgg/)) to predict the class-labels of real world images. There are [dozens of pre-trained models that are made available to the entire community](https://keras.io/api/applications/). These advanced Deep Network models yield state-of-the-art predictions that accurately label different types of 2D images. We will use the `keras` and `tensorflow` packages to load the pre-trained network models and classify the images, along with the `imager` package to load and preprocess raw images in `R`.\n\n\n## Load the Pre-trained Model\n\nYou can [download, unzip. and examine this pre-trained model](https://www.socr.umich.edu/people/dinov/2017/Spring/DSPA_HS650/data/Inception.zip). There are many different types of pre-trained deep neural network models, e.g., \n\n - [Resnet50: Deep Residual Learning for Image Recognition](https://arxiv.org/abs/1512.03385),\n - [VGG16: Very Deep Convolutional Networks for Large-Scale Image Recognition](https://arxiv.org/abs/1409.1556), by Oxford's Visual Geometry Group, and\n - [VGG19: Very Deep Convolutional Networks for Large-Scale Image Recognition](https://arxiv.org/abs/1409.1556).\n\nThe VGG's are deep convolutional networks, trained to classify images, with VGG19 model layers comprised of:\n\n -  Conv3x3 (64)\n -  Conv3x3 (64)\n -  *MaxPool*\n -  Conv3x3 (128)\n -  Conv3x3 (128)\n -  *MaxPool*\n -  Conv3x3 (256)\n -  Conv3x3 (256)\n -  Conv3x3 (256)\n -  Conv3x3 (256)\n -  *MaxPool*\n -  Conv3x3 (512)\n -  Conv3x3 (512)\n -  Conv3x3 (512)\n -  Conv3x3 (512)\n -  *MaxPool*\n -  Conv3x3 (512)\n -  Conv3x3 (512)\n -  Conv3x3 (512)\n -  Conv3x3 (512)\n -  *MaxPool*\n -  Fully Connected (4096)\n -  Fully Connected (4096)\n -  Fully Connected (1000)\n -  *SoftMax*\n\nMore information about the [VGG architecture is available online](https://iq.opengenus.org/vgg19-architecture/).\n\n\n## Load and Preprocess a New Image\n\nTo classify a new image, start with selecting and importing the image into R. Below, we show the classifications of several different types of images.\n\n\nBefore feeding the image to the deep learning network for classification, we *may* need to do some preprocessing to make it fit the network input requirements. This image preprocessing (e.g., cropping, intensity mean-centralization and scaling, etc.) can be done manually in `R`. For example below is an instance of an image-preprocessing function. In practice, we can also use the function `keras::imagenet_preprocess_input()`.\n\n\nHere is an example of calling the preprocessing function to obtain a conforming (normalized) image ready for auto-classification.\n\n\n## Image Classification\n\nUse the `predict()` function to get the probability estimates over all (learned) classes and classify the image type.\n\n\nThe `prob` prediction generates a $1000 \\times 1$ array representing the (vector) of probabilities reflecting the likelihood that the input image resembles (is classified as) each of the top 1,000 known image categories. We can report the indices of the top-10 closest image classes to the input image.\n\nClearly, this US weather pattern image is not well classified by either of the three different deep networks. The optimal predictions include *television*, *digital_clock*, *theater_curtain*, etc., however, the prediction confidence is very low, $Prob< 0.052$. None of the other top-10 class-labels capture the type of this weather-pattern image.\n\n## Additional Image Classification Examples\n\nThe machine learning image classification results won't always be this poor. Let's try classifying several alternative images.\n\n###  Lake Mapourika, New Zealand\n\nLet's try the automated image classification of this lakeside panorama.\n\n\nThis photo does represent a lakeside, which is reflected by the top three class labels:\n\n* Model 1 (resnet50): lakeside,  boathouse, dock, breakwater.\n* Model 1 (VGG19): lakeside, breakwater, boathouse, dock.\n* Model 1 (VGG16): lakeside, breakwater, dock, canoe.\n\n###  Beach \n\nAnother coastal boundary between water and land is represented in this [beach image](https://upload.wikimedia.org/wikipedia/commons/9/90/Holloways_beach_1920x1080.jpg).\n\n\nThis photo was classified appropriately and with high-confidence as:\n\n* sandbar.                                      \n* lakeside.                                 \n* seashore.\n \n###  Volcano\n\nHere is another natural image representing the [Mount St. Helens Vocano](https://upload.wikimedia.org/wikipedia/commons/thumb/d/dc/MSH82_st_helens_plume_from_harrys_ridge_05-19-82.jpg/1200px-MSH82_st_helens_plume_from_harrys_ridge_05-19-82.jpg).\n\n\nThe predicted top class labels for this image are perfect:\n\n - volcano, alps.\n - mountain_tent.\n - geyser.\n\n### Brain Surface\n\nThe next image represents a 2D snapshot of 3D shape reconstruction of a brain cortical surface. This image is particularly difficult to automatically classify because (1) few people have ever seen a real brain, (2) the mathematical and computational models used to obtain the 2D manifold representing the brain surface do vary, and (3) the patterns of sulcal folds and gyral crests are quite inconsistent between people.\n\n\nThe top class labels for the brain image are:\n\n - brain, coral.\n - mask, knot.\n - cauliflower.\n - acorn.\n\nImagine if we can train a brain image classifier that labels individuals (volunteers or patients) solely based on their brain scans into different classes reflecting their development, clinical phenotypes, disease states, or aging profiles. This will require a substantial amount of expert-labeled brain scans, model training and extensive validation. However any progress in this direction will lead to effective computational clinical decision support systems that can assist physicians with diagnosis, tracking, and prognostication of brain growth and aging in health and disease. \n\n## Face mask: synthetic face image\n\nWe can also try the deep learning methods to see if they can uncover (recover) the core deterministic model or structure used to generate designed, synthetic, or simulated images.\n\nThis example is a synthetic computer-generated image representing a cartoon face or a mask.\n\n\nThe top class labels for the face mask are:\n\n - comic_book, mask.\n - analog_clock.\n - shield, abaya.\n\nYou can easily test the same image classifier on your own images and identify classes of pictures that are either well or poorly classified by the deep learning based machine learning model.",
      "word_count": 890
    },
    {
      "title": "Data Generation:  simulating synthetic data",
      "content": "## Fractal shapes\n\nOne way to design fractal shapes is using [iterated function systems (IFS)](https://en.wikipedia.org/wiki/Iterated_function_system). each IFS is represented by finite set of [contraction mappings](https://en.wikipedia.org/wiki/Contraction_mapping) acting on complete metric spaces:\n\n$$\\{f_i : X \\rightarrow X ∣ i=1,2,... , N\\} , N \\in \\mathbb {N}.$$\nIn the case of 2D sets and images, linear and contracting IFS's can be represented as linear operators:\n$$f(x,y) = A \\begin{bmatrix} x \\\\ \n  y \\end{bmatrix}\n  +\n\\begin{bmatrix} e \\\\ \n  f \n\\end{bmatrix}\n=\n\\begin{bmatrix} \n  a & b \\\\ \n  c & d \n  \\end{bmatrix} \n  \\begin{bmatrix} \n  x \\\\ y \n  \\end{bmatrix} + \n  \\begin{bmatrix} e \\\\ \n  f \\end{bmatrix}.$$\n\nComputationally, these linear IFS contraction maps can be expressed as $N\\times 7$ matrices, where $N$ is the number of maps and $7$ is the number of parameters needed to describe an affine transformation in $R^2$.\n\nLet's take as an example [Barnsley's fern](https://en.wikipedia.org/wiki/Barnsley_fern), which is designed to model [real lady ferns (*athyrium filix-femina*)](https://en.wikipedia.org/wiki/Athyrium_filix-femina). It can be defined by a set of $N=4$ IFS contraction maps:\n\nHere is how the *Barnsley Fern* can be generated in R.\n\n\n## Fake images\n\nYou can also try to use `TensorFlow` and `Keras` to generate some \"fake\" *synthetic images* that can be then classified. This can be accomplished by using a [Generative Adversarial network (GAN)](https://en.wikipedia.org/wiki/Generative_adversarial_network) to synthetically sample from a collection of images like the MNIST image sets, e.g., `keras::dataset_fashion_mnist`, `keras::cifar10`, and `keras::dataset_mnist`. See [tutorial 1](https://blogs.rstudio.com/tensorflow/posts/2018-08-26-eager-dcgan/), [tutorial 2](https://jjallaire.github.io/deep-learning-with-r-notebooks/notebooks/8.5-introduction-to-gans.nb.html#), and [this R code](https://github.com/rstudio/keras/blob/master/vignettes/examples/eager_dcgan.R) for examples.\n\n\nClearly this is a very simple image and the DNN classification is not expected to be very informative. The results reported above will vary with the draw of the randomly generated synthetic image.",
      "word_count": 268
    },
    {
      "title": "Generative Adversarial Networks (GANs)",
      "content": "The articles [Generating Sequences With Recurrent Neural Networks, by Alex Graves](https://arxiv.org/abs/1308.0850) and [Generative Adversarial Nets, by Goodfellow and colleagues](https://papers.nips.cc/paper/2014/file/5ca3e9b122f61f8f06494c97b1afccf3-Paper.pdf), introduced a novel strategy to use recurrent neural networks to generate realistic signals, including audio generation (music, speech, dialogue), image generation, text-synthesis, and molecule design, etc.  GANs represent an alternative strategy to [variational auto-encoders (VAE)](https://ieeexplore.ieee.org/document/8285168) to generate synthetic data.\n\nGAN frameworks estimate generative models using an adversarial process that simultaneously trains a pair of network models - a *generative model* $G$ that captures the data distribution, and a separate *discriminative model* $D$ that estimates the probability that a previously generated (synthetic) sample was real, i.e., came from the training data, rather than a synthetic $G$ output. \n\nFor a binary classification, the $G$ training maximizes the probability of $D$ making a mistake (adversity), which corresponds to a *mini-max* optimization of a two-player game. The state space of all potential $G$ and $D$ permits a unique solution where $G$ recovers the training data distribution and $D=\\frac{1}{2}$ is a constant, which corresponds to 50-50 change (largest entropy). Often, the $G$ and $D$ networks are defined as multilayer perceptrons (MLP) that can be jointly fit using [backpropagation](https://en.wikipedia.org/wiki/Backpropagation).\n\nGAN learning requires iterative estimation of the generator’s distribution $p_g$ using the training data $x$, subject to some prior on noisy input latent variables $Z\\sim p_Z(z)$. Denote a generator mapping to the data space as $G(z; \\theta_g)$ where $G$ is a differentiable function representing a multilayer perceptron network with parameters $\\theta_g$, and let the second multilayer perceptron network $D(x; \\theta_g)$ represents the output scalar probability that the input $x$ came from the training data rather than from generator’s distribution $p_g$.\n\nThe iterative NN modeling fitting (learning) involves:\n\n - $D$ maximization of the probability of assigning the correct labels (true=real or false=synthetic) to both types of inputs $x$, either from training examples of synthetic samples from $G$, and\n - Simultaneous training $G$ to minimize $\\log(1 −D(G(z)))$. \n \nThis dual optimization process for $D$ and $G$ corresponds to a two-player *mini-max* game with an objective value function $V (G,D)$:\n\n$$\\min_G \\max_D V (D,G) = \\mathbb{E}_{x∼p_{data}(x)} [\\log D(x)] + \\mathbb{E}_{x∼p_{Z}(z)} [\\log(1 −D(G(z)))]. $$\n\nThis training approach enables recovering the data generating distribution using numerical iterative approaches. Note that for finite datasets, a perfect optimization of $D$ in the inner loop of training is computationally impractical and in general may result in overfitting. Therefore, the algorithm alternates the estimation process by performing $k$ steps of optimizing $D$ followed by $1$ step of optimizing $G$. When $G$ updates change slowly, repeating this process yields $D$ estimation near its optimal solution. In practice, direct gradient optimization of the objective value function $V (G,D)$ may be insufficient to learn/estimate $G$. Therefore, early in the learning process when $G$ may be poorly estimated, $D$ can reject samples with higher confidence because these early generations are expected to be obviously simple and fake, i.e., different from the training data and unrealistic, as for the early initial iterations, $\\log(1 −D(G(z)))$ may saturate. Therefore, in the early training process, rather than training $G$ to minimize $\\log(1 −D(G(z)))$, the $G$ training may focus on maximizing $\\log D(G(z))$. Eventually, we transition to minimizing the correct cost $\\log(1 −D(G(z)))$ and the final result of this dynamic optimization still has the same fixed point for $G$ and $D$, but provides stronger gradients early in the learning process.\n\n## CIFAR10 Archive\n\nWe show GAN training using [CIFAR10 images, dataset of 50K $32\\times 32$ RGB images, representing 10 classes (5K images per class)](https://en.wikipedia.org/wiki/CIFAR-10). Let's focus on `birds` (label=2). All (low-resolution) images are of dimension $\\left (\\underbrace{32, 32}_{pixels}, \\underbrace{3}_{RGB\\ colors} \\right )$. Note the 3-channel RGB intensities. Below is a $10\\times 10$ collage of the first 100 bird images in the CIFAR10 archive.\n\n\n\n## Generator ($G$)\n\nRecall that the GAN represents a forger (adversarial) network $G$ and an expert network $D$ duking it out for superiority. Let's first examine $G$ and experiment with a generator network which takes a random vector input (a stochastic point in the latent space) and outputs a decoded synthetic image that is sent to the expert (discriminator) for auto-labeling.\n\nWe will demonstrate a [keras](https://keras.io/examples/generative/dcgan_overriding_train_step/) implementation of GAN modeling using **deep convolutional GAN (DCGAN)**. Both the generator $G$ and discriminator $D$ will be [deep convnets](https://en.wikipedia.org/wiki/Convolutional_neural_network). \n\nThe method `layer_conv_2d_transpose()` is used for image upsampling in the generator. GAN model includes:\n\n - A generator network $G$ mapping vectors of shape (*latent_dim*) to (fake) RGB images of dimension $\\left (\\underbrace{32, 32}_{pixels}, \\underbrace{3}_{RGB\\ colors} \\right )$.\n - A discriminator network $D$ mapping images of the same dimension to a binary score estimating the probability that the image is real.\n - A GAN network concatenating the generator and the discriminator together: `gan(x) <- discriminator(generator(x))` to map latent space vectors $x$ to the discriminator decoding real/fake and an assessment of the realism of generator output images.\n - $D$ is trained using examples of *real* and *synthetic* $G$-output images along with their corresponding “real”/”synth” labels.\n - $G$ training using the gradients of the generator’s weights reflecting the loss of the GAN objective function. At each iteration, these $G$ weights are updated to optimize the cost function in a direction to improve $D$ performance to correctly ID  “real” and \"synth\" images supplied by the generator.\n - To avoid getting the generator stuck with generating purely noisy images, we use dropout on both the discriminator and the generator.\n\n\n\n\n## Discriminator\n\nThe expert (Discriminator) network takes as input a real or synthetic image and outputs a label (or probability prediction) about the chance that the image came from the real training set or was synthetically created by the generator network ($G$).\n\n$G$ is trained to confuse the discriminator network $D$ and evolve toward generating increasingly more realistic output images. As the number of training epochs increases, the artificially created images become similar to the real training data images.\n\nThus, $D$ continuously adapts its neural network to increase the probability of catching fake images. However, this process also gradually improves the $G$ capability to generate highly realistic output images. As the dual optimization process stabilizes and the training terminates, the generator is producing realistic images from random points in the state space, and the discriminator improves with detection of fakes.\n\nBelow is an implementation of a discriminator model taking a real or synthetic candidate image as input and outputting a classification label \"generated (synth) image\" or \"real image from the training set\".\n\n\n## The adversarial network \n\n\n\n## Training the DCGAN\n\nJust like most other deep learning processes, the deep convolutional GAN (GCGAN) *design*, *training*, and *tuning* involve significant scientific rigorous and artistry.  The theoretical foundations are intertwined with heuristic approaches translating some intuition and human-intelligence into computational modeling. Some of the exemplary heuristics involved in DCGAN modeling  and the implementation of the GAN *generator* and *discriminator* include:\n\n - Using the $\\tanh()$ function in the last activation of the generator, as opposed to the more standard `sigmoid` function commonly employed in other types of DL models.\n - Random sampling points from the latent space rely on *Gaussian (normal)* distribution, rather than a high-entropy *uniform* distribution. This randomness and stochasticity during training yields more reliability and robustness in the final models. \n - DCGAN training aims to achieve a dynamic equilibrium (tug-of-war between $G$ and $D$ nets). To ensure the GAN models avoid local minima (sub-optimal solutions), ), randomness is embedded in the training process. Stochasticity is introduced by using dropout in the discriminator (omitting or dropping out the feedback of each discriminator in the framework with some probability at the end of each batch) and by adding random noise to the labels for the discriminator.\n - Sparse gradients can negatively impact the GAN training process. Sparsity is often a desirable property in DL as it makes many theoretically intractable computational problems solvable in practice. Gradient sparsity in DCGANs is the result of (1) *max-pooling* operations for calculating the largest value in each patch of each feature map, i.e., down sampling or pooled feature maps to highlight the most salient feature in the patch (instead of averaging the signal as is the case of average pooling); or (2) *ReLU activations* (rectified linear activation function, ReLU, is a piecewise linear function that will output the input directly if it is positive, otherwise, it will output zero). `Max-pooling` can be swapped with strided convolutions for downsampling. Whereas `ReLU` activation can be replaced by `layer_activation_leaky_relu`, which is similar to ReLU, but it relaxes sparsity constraints by allowing small negative activation values.\n - The $G$ generated output images may exhibit checkerboard artifacts caused by unequal coverage of the pixel space in the generator. This problem may be addressed by employing a kernel of size divisible by the image stride size whenever we use a strided `layer_conv_2d_transpose` or `layer_conv_2d` in both the generator and the discriminator. The stride, or pitch, is the number of bytes from one row of pixels in memory to the next row of pixels in memory; the presence of padding bytes widens the stride relative to the width of the image.\n\nRecall that stochastic gradient descent optimization facilitates iterative learning using a training dataset to update the learnt model at each iteration:\n    \n - The [*batch size* is a hyperparameter](https://machinelearningmastery.com/difference-between-a-batch-and-an-epoch/) of gradient descent that controls the number of training samples to work through before the model’s internal parameters are updated.\n - The *number of epochs* is a hyperparameter of gradient descent that controls the number of complete passes through the training dataset.\n\nLet's demonstrate the synthetic image generation using the [CIFAR10](https://www.cs.toronto.edu/~kriz/cifar.html) imaging data archive of 10K images labeled in 10 different categories (e.g., airplanes, horses).\n\nThe example below just does 2 epochs. Increasing the *iterations* parameter ($k\\times 100$) would generate more, and increasingly accurate synthetic images (in this case we are focusing on birds, label 2).\n\n## Elements of the DCGAN Training\n\nThe DCGAN training involves looping (iterating over each epoch) the following steps:\n\n - Randomly traverse the latent space (introduce random noise by random sampling).\n - Use $G$ to generate images based on the random noise in the previous step.\n - Mix the synth-generated images with real real-images (from training data).\n - Train $D$ to discriminate (label) these mixed images, outputting “real” or “fake” class labels.\n - Again, randomly traverse the latent space drawing new random points (in the latent space).\n - Train the DCGAN model using these random vectors, with a fixed target label=\"real\" for all images. This process updates only the network weights of the generator! The discriminator is static inside the GAN. Hence, these updates force the discriminator to predict “real images” for synthetically-generated images. This is the adversarial phase, as it trains the generator to fool the (frozen) discriminator.\n - In the experiment below, we use a low number of `iterations <- 200`. To generate more realistic results, this number needs to be much higher (e.g., $10,000$).\n \nGPU computing Note: these DCGAN models are very computationally intensive. The performance is enhanced by installing [CUDA Toolkit](https://developer.nvidia.com/cuda-toolkit) and [NVIDIA cuDNN](https://developer.nvidia.com/cudnn), which allow you to run the calculations on the GPU, instead of the default, CPU.\n\n\n\nThe **generator** transforms *random latent vectors* into *images*. The **discriminator** attempts to correctly identify the real and synthetically-generated images. The generator is trained to fool the discriminator. \n\n**Iterative Protocol**:\n\n - *Inputs*: Random vector from the latent space (`random_latent_vectors <- matrix(rnorm(batch_size * latent_dim), nrow = batch_size, ncol = latent_dim)`) and Real Images (`real_images[1,,,] * 255`);\n - Generator (decoder) - receives *Inputs* and *training feedback* from Discriminator including real and synth images and their discriminated labels (real or synthetic);\n - Generator outputs new synth (decoded) image that is sent along with another real image as input to the Discriminator below for another real vs. synth labeling\n - Discriminator receives a pair of (real and synth) images as inputs, and outputs labels (real or synth) to them and forwards the results to generator\n - This iterative process continues until a certain stopping criterion is reached.\n \nThe GAN (generator network) is iteratively trained and tuned to fool the discriminator network (i.e., pass synth images as real). This training cycle continues and the neural network evolves toward generating increasingly realistic images. Simulated artificial images begin to look indistinguishable from their real counterparts. The discriminator network becomes less effective in telling the two types of images apart. In this iterative process, the discriminator is constantly adapting to the gradually improving capabilities of the generator. This constant reinforcement yields realistic versions of synthetic computer-generated images. At the end of the training process, which is highly non-linear and discontinuous, the generator churns out input latent space points into realistic-looking images.",
      "word_count": 2081
    },
    {
      "title": "Transfer Learning",
      "content": "Humans learn complex tasks by capitalizing on their prior experiences, no matter how remote these previous encounters may appear to be. By the age of 5, most kids can learn how to ride a bicycle in a couple of training sessions. This riding ability is acquired after they have already mastered the arts of *running*, also known as  *controlled falling*, navigating complex 3D environments, and anticipating dynamic 4D spatio-temporal events. In effect, before kids start pedaling, their many prior holistic training experiences ensure that they “know” the basics of bike balancing. Children's formative years include a very large number of trial-and-errors, parental guidance sessions, and societal cues. These events already provide the basic building blocks necessary to learn bicycle riding. And this is well in advance of the actual \"bicycle training\" experience, which we typically associate with bicycle riding. \n\nThis learning process is very different for machines. It's extremely difficult to train a machine (a robot) to ride a bike, because these prior experiences kids go through are missing and can not be easily built and transferred to complete the new task of learning how to balance a bike. In a way, humans learn new tasks easily as (1) they already have a large collection of skills they have already mastered, and (2) they can *transfer*, mix, match, integrate, and harness their prior experiences to the process of learning a *new task*. **Transfer machine learning** attempts to replicate this human transfer learning process into the domain of artificial intelligence. The goals are to expedite the ML training process by capitalizing on prior knowledge, expand the realm of ML/AI applications, and enable their “last mile” training to ensure they generate \"reasonable decisions and actions\" without starting with blank slate *de novo* learning.\n\n## Deep Network Transfer Learning in Text Classification\n\nOne of the main challenges of AI/ML interpretation of free text is the extreme heterogeneity of the information and the unstructured format of the text content. This problem can be resolved by structurizing the input text and establishing homologies between multiple text samples (e.g., clinical notes). In a nutshell, transfer learning facilitates this process and enables (1) synthetic text generation (new data) that simulates realistic textual content (non-human data); and (2) transformation of unstructured text to structured data elements. For instance, if an $input=clinical\\ notes$, a DNN model generates $output=vector$ representing a quantitative signature vector of the input text; think of it as a vector of principal components associated with the specific free text. \n\nThe result of this AI process is that independently of the text length or type, DNN always generates a numeric vector of a fixed size (say 128 values). This canonical representation establishes *homologies* between any given set of strings (character arrays).\n\nLet's demonstrate *transfer machine learning* using the [medical specialty text-mining example of clinical notes example that we saw in Chapter 5](https://socr.umich.edu/DSPA2/DSPA2_notes/05_SupervisedClassification.html). This data includes a binary outcome indicating whether  the medical specialty unit (there are 40 such units) is a **surgical** unit or not. We’ll split the 4,999 cases, each containing 6 data elements, including the medical-specialty unit and clinical notes, into training and testing sets. \n\nThe key will be to use `keras` to build and train a ML model for predicting surgical vs. non-surgical units from the content in the corresponding medical notes by using a previously trained text-mining DNN that quantizes text of any size. One also needs to install the \n[`tfhub` package (TensorFlow Hub)](https://github.com/rstudio/tfhub), which provides\nreusable machine learning libraries.\n\n\n### Binary Transfer Learning Label-Classification of Clinical Text\n\nLet’s now **design a full DNN binary-classification model** composed of 4 layers stacked sequentially. The first *transfer learning* layer represents the pre-trained TensorFlow Hub layer (prior model), which is loaded as the a priori left-most base layer in the full DNN and maps clinical notes (description sentences) into its embedding vector (canonical signature vector). There are a number of *pre-trained text embedding models* we can choose in this transfer-learning example. For instance, we can use [google/tf2-preview/gnews-swivel-20dim/1](https://tfhub.dev/google/tf2-preview/gnews-swivel-20dim/1), which splits the sentences into tokens, embeds each token, and then combines the embedding yielding an output of dimensions: (num_examples, embedding_dimension). The output of this initial *transfer learning prior model layer* is a fixed-length output vector, which is fed into the next fully-connected (Dense) *layer-2* with 16 hidden units. Layer-2 output feeds into the next (dense) *layer-3* with 6 nodes. Finally, Layer-3 output goes into the last *layer-4*, which also is a densely connected layer with a single output (class label). Using the `sigmoid` activation function, this output represents a probability value between 0 and 1 indicating the model predicted chance, or confidence level, that the medical note text was written in a hospital *surgical unit*.\n \nOther examples of pre-trained text mining models that can be used for transfer learning include:\n\n - [google/tf2-preview/gnews-swivel-20dim/1](https://tfhub.dev/google/tf2-preview/gnews-swivel-20dim/1),\n - [google/tf2-preview/nnlm-en-dim128/1](https://tfhub.dev/google/tf2-preview/nnlm-en-dim128/1), and\n - [google/tf2-preview/gnews-swivel-20dim-with-oov/1](https://tfhub.dev/google/tf2-preview/gnews-swivel-20dim-with-oov/1), similar to [google/tf2-preview/gnews-swivel-20dim/1](https://tfhub.dev/google/tf2-preview/gnews-swivel-20dim/1), but with 2.5% vocabulary converted to OOV buckets, which helps when the training and testing vocabularies are not fully overlapping.\n - [google/tf2-preview/nnlm-en-dim50/1](https://tfhub.dev/google/tf2-preview/nnlm-en-dim50/1) is a much larger pre-trained model with vocabulary of size 1M and 50 dimensions.\n  - [google/tf2-preview/nnlm-en-dim128/1](https://tfhub.dev/google/tf2-preview/nnlm-en-dim128/1) is another large model, vocabulary of size 1M, and 128 dimensions.\n\nWe will demonstrate NN-augmentation (transfer learning) modifying the base-model using the [pre-trained NN English Google News 200B corpus](https://tfhub.dev/google/tf2-preview/nnlm-en-dim128/1) by adding 4 extra layers at the end, which will be tuned for our specific clinical text (medical notes). Of course, similarly, any of the other pre-trained models can be used as alternatives.\n\nDownload the [clinical dataset](https://socr.umich.edu/DSPA2/DSPA2_notes/05_SupervisedClassification.html) and split it into training:training (80:20).\n\nNote that in this clinical-notes example, the input data consists of medical text transcriptions stored as string sentences. In the first demonstration, we will try to predict a binary integer label, 0 or 1, representing a non-surgical or surgical clinical unit where the clinical note was transcribed. To structurize the free-text as a computable data object (a matrix), we will automatically convert sentences into embedding vectors. This can be accomplished using [text2vec](https://github.com/dselivanov/text2vec) or [keras::layer_text_vectorization()](https://www.rdocumentation.org/packages/keras/versions/2.4.0/topics/layer_text_vectorization) transformations, or by including a pre-trained text embedding as the first layer. This takes care of the text preprocessing, facilitates transfer learning, and makes the text-to-matrix independent of the text and the size of the clinical note.\n\n\n####  Define a fresh new `model1` *de novo*\n\n\n#### Naive - out-of-the-box prior-model assessment (without retraining)\n\nIn a naive approach, we can even evaluate the performance of the *prior model* ([English Google News 200B](https://tfhub.dev/google/tf2-preview/nnlm-en-dim128/1)), i.e., assess transfer learning without any additional add-on training using the new problem-specific data. Remember that we have a univariate (binary) outcome and if we use `dataset_batch(32)`, the output will include a vector of 32 probability estimates.\n\nWe will see next that Keras knows how to extract elements from TensorFlow Datasets automatically making it a much more memory efficient alternative than loading the entire dataset to RAM before passing to Keras.\n\nTo build the DNN model, we need to specify the network topology as a stack of network layers that include (1) schema representing the unstructured text data (clinical note descriptions), and (2) Number and complexity of each subsequent layer in the model. For simplicity, in this example we will convert the 40 different medical units into binary \"surgical\" unit labels; 0 or 1 factors.\n\nThe unstructured text can be converted into embedding vectors of a fixed size, which simplifies the text processing. Using the transfer learning *prior* model, which includes a pre-trained text embedding and appears as the first DNN layer. This allows us to outsource the text preprocessing and transformation into quantitative information tensor. This is the key step illustrating the benefits of add-on based transfer-learning in fine-tuning previously trained models.\n\nThe result of using this transfer-learning prior is that the model is *invariant* with respect to the length of the input clinical text - the output shape of the embeddings is $(num\\_examples\\times embedding\\_dimension)$.\n\n\n\nClearly these surgical unit predictions can't be expected to be very reliable, as the model is not fine-tuned yet to respond specifically to *clinical text*.\n\nThe next step is to **compile the transfer-learning model** by specifying a *loss function* and an *optimizer* to facilitate the transfer-learning during the iterative network model fitting (fine-tuning). In this binary classification problem, we will use the `binary_crossentropy()` loss function. The model results in generating a probability value, which is presented as the output of the final DNN layer (the right-most single-unit layer with a sigmoid activation).\n\nAnother possible loss function for binary outcome is `mean_squared_error()`. However, binary_crossentropy is often better for dealing with probabilities as it measures the “distances” between probability distributions representing the predicted outcome and the ground-truth in supervised problems. Yet, `mean_squared_error()` is also applicable in a regression model setting. We will also employ [Adaptive Moment Estimation (ADAM)](https://en.wikipedia.org/wiki/Stochastic_gradient_descent#Adam) as it's an effective optimizer.\n\n#### Simple Transfer Learning \n\nLet's use the `nnlm-en-dim128` (prior model) to define an expanded DNN model by adding additional four layers at the end to customize the deep neural network to our specific clinical data.\n\n\n#### Full-scale Transfer learning \n\nNext we will use the structure/topology of the pre-trained model, but estimate all $124M$ network parameters, not only the final $11K$ parameters at the end, as we did earlier.\n\n\nThe final pair of steps include:\n\n - **Training**. *Transfer learning* involving fine-tuning the model starting with a prior pre-trained model, which is re-trained on the specific medical text (training) data,  and \n - **Validation**. The learning process involves repeated model estimation using mini-batches of 512 samples (see `dataset_batch()`) with 10 (for speed) or more (e.g., 100+, for accuracy and precision) epochs. This process involves 10 (or 100+) iterations over all samples in the dataset. During the fine-tuning training process, the transfer learner will report the initial and each subsequent model *loss-value* (optimization measure) and *accuracy* (fidelity measure) on sets of 10,000 samples from the validation set (see `dataset_shuffle()`).\n\n\nThis simple transfer learning approach achieves an accuracy of about 73-76%. More model customization and longer training are expected to significantly improve the performance of the fine-tuned transfer-learning DNN model. Additional information about [`R`-based tensorflow DNN modeling is available here](https://tensorflow.rstudio.com/guide/tensorflow/eager_execution/) and [here](https://tensorflow.rstudio.com/learn/resources/).\n\n\n### Multinomial Transfer Learning classification of Clinical Text\n\nLoad all the appropriate R/Python packages and set up the RStudio environment.\n\n\nThe same clinical data can be used for multinomial classification, where the *outcome* is the clinical specialty unit (there are 40 hospital units in this case-study), the *input* is the given clinical text. Start by defining the special labels (clinical units). The prediction of the 40-class labels will depend on the input $x$ consisting of the string `clinicalNotes`, representing the concatenated *transcriptions* and *descriptions*.\n\nIn this transfer learning example of multiclass text classification, we will utilize the [gnews-swivel-20dim model with text embedding trained on English Google News 130GB corpus](https://tfhub.dev/google/tf2-preview/gnews-swivel-20dim/1).\n\n\n\n\n<!-- OLD CODE ....................................................\n\n\nAgain, split the data into training and testing sets and cast the outcome $y$ (medical_specialty) as a label ($1:40$).\n\n\n\n\n\n\nConfigure the *training* and *testing* data as **matrices** that will be used in the model-fitting (training) and model-assessment (validation) steps below.\n\n\n\n\nDefine the 40 medical specialty units as categorical labels, outcomes that can be used in the multinomial training/classification.\n\n\nReserve 20% of the data for subsequent validation.\n\n\nDefine the extended model.\n\n\nMind that this model has over 136K parameters in total.\n\n\n\nDisplay the training and validation model performance.\n\n\nFinally, we can test the multinomial classification on the clinical text data for these 4 hospital units using the independent testing data.\n\n-->\n\n\n### Binary Classification of Film Reviews\n\nAll readers are encouraged to try text-based transfer learning using [alternative datasets](https://umich.instructure.com/courses/38100/files/folder/Case_Studies), e.g., the [50,000 movie reviews dataset](https://github.com/tensorflow/datasets/blob/master/docs/datasets.md#imdb_reviews). The code skeleton below illustrates the basic pipeline workflow for the movie review's binary classifications.\n\n\n## Image classification\n\nSimilar to the unstructured text-mining (film review case) we illustrated above, we can use DNN transfer learning for *image classification.* \n\n### Performance Metrics\n\n#### Binary Cross-Entropy Measure\n\nThe *cross-entropy* measure of dissimilarity between two discrete probability distributions $p$ (true state) and $q$ (predicted state) with identical support $X$ is defined as\n\n$$H(p,q) = -\\sum _{x_i\\in X}{p(x_{i})\\log q(x_{i})}.$$\nFor binary outcomes, logistic regression transforms the log-loss over all training observations, i.e., it optimizes the average cross-entropy in the sample. \n\nFor a sample indexed by $n = 1, \\cdots, N$, the expected (average) loss function is:\n\n$$J(w) ={\\frac{1}{N}} \\sum _{n=1}^{N}H(p_{n},q_{n})\\ =\\ -{\\frac {1}{N}}\\sum _{n=1}^{N}\\ {\\bigg [}y_{n}\\log {\\hat {y}}_{n}+(1-y_{n})\\log(1-{\\hat {y}}_{n}){\\bigg ]},$$\n\nwhere ${\\hat {y}}_{n}\\equiv g(w \\cdot x_{n})=\\frac{1}{1+e^{-w \\cdot x_{n}}}$ and $g(z)$ is the logistic function. The logistic loss is the *cross-entropy loss* or *log-loss*, and binary refers to the situation of  binary outcome labels $\\{-1,+1\\}$.\n\nHence, the *binary cross-entropy* (*BCE*) is simply\n\n$$H(p,q) = -\\sum _{x_i\\in X}{p(x_{i})\\log q(x_{i})}\n= -y\\log {\\hat {y}}-(1-y)\\log(1-{\\hat {y}}),$$\nwhere $p \\in \\{ y , 1 − y \\}$ and $q \\in \\{ \\hat {y}, 1 − \\hat {y} \\}$ represent the probability of the *true* and *predicted* binary outcomes, respectively.\n\nHigh or low BCE values indicate \"bad\" or \"good\" model performance, respectively, with a perfect model having a $BSE\\approx 0$.\n\n#### Dice Coefficient\n\nThe [Sørensen–Dice coefficient](https://en.wikipedia.org/wiki/S%C3%B8rensen%E2%80%93Dice_coefficient) (*Dice Coefficient*) is another measure to assess the similarity between two sets, samples, or distributions. In our case we are applying the dice coefficient to track the overlap between the true brain-tumor masks, and the DCNN-derived mask-estimate (prediction) of the tumor based on the raw brain image.\n\n\n### `Torch` Deep Convolutional Neural Network (CNN)\n\nThe [U-Net: Convolutional Networks for Biomedical Image Segmentation](https://lmb.informatik.uni-freiburg.de/people/ronneber/u-net/), shown on the image below, is an example of a DCNN.\n![U-Net Architecture](https://lmb.informatik.uni-freiburg.de/people/ronneber/u-net/u-net-architecture.png)\nThe U-shaped CNN (U-Net) represents successive convolutional layers with max-pooling. During the auto-encoding (left-down-hill branch) the U-Net reduces image resolution (downsampling), whereas during the subsequent decoding phase (right-uphill branch) upsamples the images to arrive at an output of the same size as the original input. The information analysis (encoding) and synthesis (decoding) facilitate the labeling of each output image pixel by feeding information in each decoding layer from the corresponding encoding layer with matching resolution in the downsizing encoding layer.\n\nEach upsampling (decoding) step concatenates the output from the previous layer with that from its counterpart in the compression (encoding) step. The final decoding output is a mask of the same size as the original image, derived by a $1\\times 1$-convolution, which does not require a dense layer at the end as the output convolutional layer represents a single filter. Below we show how to load, train, and use a U-Net for transfer learning in 2D image segmentation. Note that this model has over $3M$ trainable parameters. You can see an [R example of a Unet model for input-output tensors of shape=c(128,128)](https://github.com/rstudio/keras/blob/master/vignettes/examples/unet.R), see lines 73-183.\n\n\n\n#### Data Import\n\nLet's first download and load in the [Brain Tumor Imaging dataset](https://umich.instructure.com/courses/38100/files/folder/Case_Studies/36_TCGA_MRI_Segmentation_Data_Phenotypes). These data come from a 2019 study on [Association of genomic subtypes of lower-grade gliomas with shape features automatically extracted by a deep learning algorithm](https://doi.org/10.1016/j.compbiomed.2019.05.002). The 2D brain MR images are paired with 2D tumor masks, which are trivial for controls and non-trivial for patients, using [The Cancer Imaging Archive (TCIA)](https://wiki.cancerimagingarchive.net/display/Public/TCGA-LGG). The data represent 110 patients with lower-grade glioma and include fluid-attenuated inversion recovery (FLAIR) MRI scans. There are 3-channels of the MRI data; *pre-contrast, FLAIR*, and *post-contrast*. The corresponding tumor masks were obtained by manual-delineations on the FLAIR images by board-certified radiologists. \n\n\n\n\nCreate the necessary directories to store the training and validation imaging data (brain MRIs and tumor masks).\n\n\nDefine data-frames containing the file-names for all training and validation data.\n\n\n(Optionally) *convert all 2D TIFF images to PNG RGB format*! This may be necessary \nto ensure the input images are 3-channels, and are correctly interpreted as tensorflow objects.\n\n\n\nDerive a binary class label - cancer (for non-trivial tumor masks) or control (for empty tumor masks).\n\n\n#### Torch-based Transfer Learning\n\nNext we will ingest the *3-channel (RGB) imaging data* and the corresponding *tumor masks* (binary images) for each participant. The method `torch::dataset()` allows specifying `initialize()` and `.getitem()` methods for complex computable data objects. The first method `initialize()` creates the archive of *imaging* and *mask* file names that can be utilized by the second method `.getitem()` for iterating over all cases. The method `.getitem()` returns ordered input-output pairs and performs weighted sampling, with prevalence to large lesion images, which is useful for accounting for DNN training with imbalanced classes.\n\nThe training sets can be enhanced by *data augmentation* -- a process expanding the set of training images and masks via operations such as *flipping, resizing, and rotating* based on certain specifications.\n\nBelow we use [PyTorch](https://blog.rstudio.com/2020/09/29/torch/) to define a **brain_dataset** method providing a larger *augmented* *training* dataset, new size `length(train_ds) ~ 2K`, and a larger *validation* set, new size `length(valid_ds)~1K`. In practice, we can use any alternative transfer-learning strategy including `pytorch`, `tensorflow`, `theano`, etc.\n\nNote that `unet` training takes significant computational time; training 20-epochs took a total of 600 compute hours, which translates into a couple of days of computing on a 20-core server. We have provided [several precomputed/pre-trained *.pt models on Canvas](https://umich.instructure.com/courses/38100/files/folder/Case_Studies/36_TCGA_MRI_Segmentation_Data_Phenotypes).\n\n\nBelow, we define a function `brain_dataset()` required for iterative retrieval of pytorch datasets. All such datasets need to have a method called `initialize()` instantiating the inventory of *imaging* and *mask* file names that will be used by the second method, `.getitem()`, to ingest the imaging data from these files, return input-image plus mask-target pairs, and perform data-augmentation. The parameter `random_sampling=TRUE`, `.getitem()` controls the weighted sample loading of image-mask pairs with larger in size tumors. This option is used with the training set to counter any class-label imbalances.\n\nThe training sets, but not the validation sets, use of *data augmentation* to ensure DCNN-invariance to specific spatiotemporal and intensity transformations. During imaging-data augmentation, the training images/masks may be *flipped, resized*, and *rotated* with specifiable probabilities for each type of augmentation transformation.\n\n\n\nNext, using the `brain_dataset()` method, we actually generate the (training and validation) imaging datasets as computable objects using the raw filenames in the training and validation data-frames defined above.\n\n\nLet's visualize one testing and one validation image-mask pairs using `plot_ly()`.\n\n\nDemonstrate training-data image-augmentation by using one image to generate 7 rows of 4 augmented images.\n\n\nInstantiate training/validation data loaders using `torch::dataloader()`, which combines a data-set and a sampler-iterator into a single/multi-process iterator over the entire dataset.\n\n\nNext, we specify the `Unet` model indicating the number of “down” or encoding (analysis) depth for shrinking the input images and incrementing the number of filters, as well as specify how do we go “up” again during the decoding (synthesis) phase.\n\n\nBefore we start the `unet` model training, we need to specify CPU/GPU device and optimization scheme.\n\n\nOn a multi-core machine, training the `UNET` model will require ~2-hrs per epoch. This step can be skipped if you load in a previously pre-trained model (`model`) that is saved (`torch_save(model, \"/path/model.pt\")`) and available for import (`torch_load(\"/path/model.ptt\")`), [see several *.pt model here](https://umich.instructure.com/courses/38100/files/folder/Case_Studies/36_TCGA_MRI_Segmentation_Data_Phenotypes).\n\n\nStart the `Unet` training process (this is suspended here to enable real-time knitting of the HTML doc).\n\n\nEvaluate the trained DCNN model using `model_6.pt` and a batch of $n=10$ validation datasets (2D brain imaging scans).\n\n\nFinally, we can assess the `unet model` performance on the independent validation images, report the DCNN-derived tumor masks (as images) and some quantitative measures (e.g., Binary Cross-Entropy, Dice coefficient). The figure displays the results - brain image, true mask, and DCNN-estimated mask.\n\n\n#### Torch-based DNN-based Image Reconstruction and Synthetic Image Generation\n\n##### Data Reparametrization\n\nThis image-normalization (*standardization*) is necessary to avoid extreme differences in image intensities (e.g., sMRI, fMRI, PET, SPECT, dMDI/DTI, MRS, and other imaging modalities tend to have vastly different scales).\n\n\n##### Define the Architecture of the UNet *Encoder* Branch\n\n\n##### Define the Architecture of the UNet *Decoder* Branch\n\n\n##### Define the Loss Function & Optimizer\n\n\n##### Train DNN UNet (Encoder & Decoder Branches)\n\nFor *GPU optimization* of this long calculation [see this GPUComputingWithR module](https://jaredlander.com/content/2021/09/GPUComputingWithR.html#66).\n\n\n##### Obtain the DNN-derived Image Reconstructions and Random Synthetic Images\n\nThe synthetic images are derived by randomly sampling the latent space of the DNN (bottom of network) and using solely the *decoding branch* of the UNet.\n\n\n##### Result Visualization\n\nFinally, plot examples of the DNN-derived image reconstruction and synthetic image generation.\n\n\n### Tensorflow Image Pre-processing Pipeline\n\nThe image prepossessing steps above use `torch` syntax. [This blog](https://blog.rstudio.com/2020/09/29/torch/) provides context on similarities and differences between `torch/pytorch/libtorch` and `tensorflow/keras`.\n\nNext, we will use `tensorflow` (*TF*) to again ingest independently the images employing `tf$image` functions, e.g., `decode_png()`. This [introduction to RStudio-Tensorflow](https://tensorflow.rstudio.com/guide/tfdatasets/introduction/) is helpful to understand the `tf` syntax.\n\nAssuming the data is already loaded, see the previous section (**Torch Data Import**), we will first preload all the necessary `tensorflow` libraries.\n\n\nRemember that we already have the ZIP data (*training=data* and *validation=mri_valid*) downloaded and expanded in a local partition `/data/`. We will split the data into training:testing $80:20$ and read the imaging/masking data from the PNG files into tensorflow data objects `training_dataset` and `testing_dataset` (this is the separate *validation set*).\n\n\nIn practice, the *uint8* data type of the RGB values in PNG/TIFF files are human-interpretable, the U-net expects floating point tensor elements. Thus, we will convert the 3-channel input images to real numbers and scale them to values in the interval $[0,1)$.\n\nFor improving computational efficiency, sometimes it may be necessary to reduce the computational burden by down-sizing the images, e.g., to $128\\times 128$ or even $32\\times 32$. In principle, we want to protect the native aspect ratio in the images, keep the pixels isotropic, and avoid distortion. In this case we won't reduce the image size, but it may be useful sometimes.\n\nThe Tensorflow protocol also includes augmentation of the imaging data. Earlier, we used `torch` augmentation, now we use `tensorflow`. Of course, we will apply the same augmentation-transformations (scale, rotate, flip) to the tumor-mask as well as the brain images, see these three methods `resize()`, `flip()`, `rotate()` in the `create_dataset()` function above. In addition, we can augment the data by intensity-transformations that preserve the spatial image structure but alter the contrast, brightness, and image saturation, see this `random_bsh()` method. \n\n\nThe core functions we built above can be integrated into a new function, `create_dataset()`, which represents the complete end-to-end image preprocessing pipeline, The *input* to this pipeline is a dataframe of filenames containing the brain-images and tumor-masks, and the corresponding output contains the `training_dataset` and the `validation_dataset` as tensorflow dataset-objects that will be used in the model-fitting phase.\n\n\nThe UNet DCNN model summary includes:\n\n - Column 1: Layer type and specifications\n - Column 2: “output shape” contains the expected network U-shape parameters. Note that during the encoding phase, the image *Width* and *Height* sizes decrease initially (until the middle of the \"U\", reaching a minimum resolution of $8\\times 8$). Then, they start increasing again during the decoding phase, until reaching the sizes of the original image resolution. Similarly, the number of filters increases during encoding and then decreases during the decoding phase terminating with an output layer having a single filter. Finally, the model architecture includes *concatenation* layers in the decoding phase that aggregate information from “below” with information that comes “laterally” from the parallel nodes in the encoding phase.\n - Column 3: shows the number of parameters used in each layer of the DCNN.\n - Column 4: for each layer (row), column 4 shows the parent (previous) layer in the network. \n\nIn this *image-segmentation problem*, the loss function needs to account for the result of labeling ALL pixel intensities in the brain images. Hence, every pixel location contributes equally to the total loss measure. As Binary classification yields a $1$ (tumor) or $0$ (normal brain tissue), the `binary_crossentropy()` method is one appropriate choice of a loss function. During the iterative transfer learning process, we can track the classification accuracy, dice coefficient or other evaluation metrics that capture the proportion of correctly classified pixels.\n\nNext we will define, compile and test the base (pre-training default) model, prior to model fitting. This is a naive prediction without model tuning or transfer learning.\n\n\nThe part below shows the UNet/DCNN model fitting for a single epoch. This block of code is not run (`eval=F`) as it takes hours to complete, but below we show the results from offline DCNN trainings with different settings.\n\n\nWhen training the DCNN model, keep in mind that this step is very computationally intensive (each epoch can take hours to complete). Running a small number of epochs may be feasible in an interactive RStudio session, but dozens of epochs are necessary to train the network to perform well (e.g., yield high Dice coefficient values).\n\n\nOnce we have pre-trained (`history <- model %>% fit()`) and saved (`save_model_hdf5()`) the model (`model`), we can load it back as `mod1` in the interactive session and use it for prediction. Several [pre-trained models (e.g., 50 and 100 epochs) are available on the Canvas site](https://umich.instructure.com/courses/38100/files/folder/Case_Studies/36_TCGA_MRI_Segmentation_Data_Phenotypes). Below, we are using one of the pre-trained Unet models (`model_TF_Brain_epoch_100.h5`, 250MB) to illustrate the prediction performance, i.e., automated brain-tumor segmentation using 2D neuroimaging data.\n\nNotice the steady model improvement (accuracy, binary tumor-labeling, and dice-coefficient) with respect to the epoch index.\n\n\nFinally, we can explicate some of the *Transfer Learning* process by modifying the pretrained model `mod2` and obtaining a new model, `modTransferLearning`, which demonstrates synthetic image generation. This new modified `modTransferLearning` DCNN will output 3-channel brain-images, not tumor masks (predicted by `mod2`). Note that 31M parameters part of the original pretrained `mod2` are fixed and we are only estimating the remaining $16K$ parameters in this transfer-learning tuning process.\n\n\nOnce we have trained (`history <- model %>% fit(()`) and saved (`save_model_hdf5()`) the model (`model`), we can load it back as `mod1`  the interactive session and use it for prediction.\n\n\n### Notes about the Tensorflow pipeline protocol\n\n#### Preprocessing\n\nThe preprocessing pipeline allows inspecting intermediate results using `reticulate::as_iterator()` on the dataset.\n\n\nFor the subsequent transfer-learning, we need to add additional layers to the base-model (`mod1`). The output of every `Conv2D` and `MaxPooling2D` layer is a 3D tensor of shape `(height, width, channels)`. In our-case, the final mask-output is a single-channel image. The *width* and *height* dimensions typically shrink with network layer depth. The number of output channels for each `Conv2D` layer is controlled by the `filters` parameter (e.g., 32 or 64). As the width and height shrink, we can add more output channels in each `Conv2D` layer in the NN.\n\nNote that the new transfer-learning model (`TL_model`) has only $17K$ parameters to estimate, as the $31M$ parameters of the base model (`mod`) are now frozen, i.e., they will not be tuned or estimated during the `TL_model` re-fitting, which will be much faster than the estimation of the original model.\n\n - Total params: 31,048,611\n - Trainable params: 16,931\n - Non-trainable params: 31,031,680\n\nAfter we design the DCNN model (Unet), we need to again compile it and estimate the fit to obtain the remaining *trainable parameters.*\n\n#### Network Layers\n\n - **Convolutional Layers**: In the late 1990s, LeCun introduced one of the most popular strategies for generating signature (feature) vectors corresponding to single- or multi-channel 2D images. Previously, alternative methods, such as wavelet or spectral decomposition, could be used to map images as features. Then more classical AI/ML techniques, such as support vector machine, knn, logistic regression, among others, may be employed to model, analyze, predict and classify images.\n\nTransforming 2D or higher-dimensional images as feature-vectors disregard some of the spatial interaction between pixels, voxels, and tensors. *Convolution layers* tend to capture and protect some of the spatial information from neighboring spatial locations. This is accomplished by down-sampling the image into features by convolving the images with *kernels* (*filters*) and then using the resampled convolution images to predict specific outcomes (images, values, classes, etc.) The use of multiple convolution kernels to \"filter\" the image involves computing a  product to extract different features from the images.\n\nFor an image $f(m,n)$, and a kernel $g(k,l)$ defined over an integer grid $\\{m,n,k,l\\in \\mathbb{Z}\\}$, the [discrete convolution](https://en.wikipedia.org/wiki/Multidimensional_discrete_convolution) of $f$ and $g$ is:\n\n$$\\underbrace{(f*g)}_{convolution}[m,n]=\\sum_{m=-\\infty}^{\\infty} {\\sum_{n=-\\infty}^{\\infty} {\\left (f[k, l]\\times g[m-k, n-l]\\right )}},$$\nwhere typically, the support of $f$ and $g$ is compact, e.g., $0\\leq m,k\\leq M-1$ and $0\\leq n,l\\leq N-1$.\n\nThe convolution of two finite sequences is defined by extending the sequences to finitely supported functions on the set of integers. When the sequences are the coefficients of two polynomials, then the coefficients of the ordinary product of the two polynomials are the convolution of the original two sequences. This is known as the Cauchy product of the coefficients of the sequences.\n\nFor instance, edge detection in an image can be done using a [Sobel kernel matrix](https://en.wikipedia.org/wiki/Sobel_operator) for vertical ($y$) and horizontal ($x$) edges.\n\n$${\\displaystyle g_{x}={\\begin{bmatrix}+1&0&-1\\\\+2&0&-2\\\\+1&0&-1\\end{bmatrix}} \\quad {\\mbox{and}}\\quad g_{y}={\\begin{bmatrix}+1&+2&+1\\\\0&0&0\\\\-1&-2&-1\\end{bmatrix}}}.$$\n\n\nDuring the DCNN training process, the encoding phase typically included 2D convolutional layers (`layer_conv_2d()`) paired with pooling layers that reduce the size of the tensor shape and transform images by sliding the kernel filter by a stride (1, 2, 3, etc.) pixels to the right and down. The relation between the resulting feature-vector size and the kernel size is represented by:\n\n$$Feature\\ size = \\frac{Image\\ size\\ −\\ Kernel\\ size}{Stride} + 1.$$\nFor instance, a 10x10 square image, a filter of size 4x4, and a stride of 2 pixels, the $Feature\\ size = \\frac{10 − 4}{2} + 1 = 3$. Similarly, during the decoding phase, we include deconvolutional layers (`layer_conv_2d_transpose()`) that reverse the process by increasing the grid-size (tensor shape sizes) until we reach the desired output layer shape, usually the same as the input images, but could also be different. More information about [`tensorflow/keras` layers](https://tensorflow.rstudio.com/reference/keras/#section-core-layers), [loss functions](https://tensorflow.rstudio.com/reference/keras/#section-losses), and [DCNN model performance metrics](https://tensorflow.rstudio.com/reference/keras/#section-metrics) is available on the [RStudio Tensorflow/Keras website](https://tensorflow.rstudio.com/reference/keras).\n\n - **Max Pooling Layer**. Max pooling layers shrink the spatial extent of the convolved features and reduce overfitting by providing an abstracted feature representation. Instead of convolving (i.e., dot-product multiplying the image and the kernel) between the input and the kernel, Max-Pooling layers take the maximum value of image intensity over the region covered by the kernel filter. There are many alternatives to max-pooling, e.g., average-pooling, which computes the mean (arithmetic-average) of all image intensities covered by the kernel filter.\n\n\n - **Fully Connected layers**: Input nodes (from the left) in fully connected layers are connected to every node in the subsequent layer to the right. One or several fully connected layers may be common towards the end of a DCNN to provide support for learning non-linear affinities between high-level features generated as outputs of the prior convolutional layer. Good network designs typically include *dropout layers* between two consecutive fully connected layers (to reduce overfitting) and specify *activation functions* to capture non-linearity.\n\nThe final fully connected layer allows us to control the output tensor shape size which reflects the expected type of classification, prediction, or forecasting. For instance, if the outp[ut is expected to be 6-class labeling, the final layer will output a vector of size 6, i.e., one node for each possible class label. A *softmax* of this 6-feature vector would yield a 6D vector containing probabilities ($0\\leq p_i\\leq 1$, $\\forall 1\\leq i\\leq 6$) one for each class label. Dropout layers provide a mechanism for regularizing the model and reducing overfitting of the DCNN. Dropout layers may follow fully connected layers or appear after other max-pooling layers to generate image noise augmentation. Dropout layers randomly annihilate (set to zero) some of the connections of the input tensor, according to a Bernoulli distribution; hence some inputs are triaged with probability $p$.\n\n#### Model Tracking and Network Visualization\n\nOne can use `tensorboard` to dynamically track the progression of an ongoing training process as well as to visualize a neural network structure as a graph. See these examples for more details, [example 1](https://www.tensorflow.org/tensorboard/graphs) and [example 2](https://cran.r-project.org/web/packages/tfestimators/vignettes/tensorboard.html). The basic mechanism for this involves the following steps.\n\n - Install `tensorboard` (in a terminal/shell outside R/RStudio): This can be done in different ways and is system/OS dependent. Some examples include:\n    + `python -m pip install --user --upgrade pip`\n    + `conda install -c conda-forge tensorboard`\n    + `conda activate tensorflow`\n - Launch the `tensorboard` UI (from terminal shell): `> tensorboard --logdir logs/run_a`. Alternatively, you can launch tensorboard from RStudio directly via *Rstudio --> Tools --> Shell* and entering this command in the shell `tensorboard --logdir logs/run_a`.\n - Open a local browser and point to this URL address: `http://localhost:6006/`\n - Your code has to use callback mechanism for tracking, see the example above (`print_dot_callback()`) with printing periods or [this example](https://tensorflow.rstudio.com/guide/keras/training_callbacks/).\n - Start the NN training process in the Rmd/R/RStudio environment and observe the tracking metrics dynamically updating in the browser. Note that your python/conda/anaconda shell needs to be open/live for this (*localhost*) process to work and to keep the browser portal active and listening to python updates during the fitting/training process.",
      "word_count": 5371
    },
    {
      "title": "References",
      "content": "- Chollet and Allaire's [Deep Learning with R](https://www.manning.com/books/deep-learning-with-r) textbook (ISBN 9781617295546) and the corresponding [code notebook](https://github.com/jjallaire/deep-learning-with-r-notebooks/tree/master/notebooks)\n - [Deep Neural Networks](https://github.com/ledell/useR-machine-learning-tutorial/blob/master/deep-neural-networks.Rmd)\n - [Google's TensorFlow API](http://playground.tensorflow.org)\n - Olaf Ronneberger, Philipp Fischer, Thomas Brox (2015). [U-Net: Convolutional Networks for Biomedical Image Segmentation](https://lmb.informatik.uni-freiburg.de/people/ronneber/u-net/), Medical Image Computing and Computer-Assisted Intervention (MICCAI), Springer, LNCS, Vol.9351: 234--241, 2015, [arXiv:1505.04597](http://arxiv.org/abs/1505.04597). \n\n\n\n<!-- ----------------Manual Pandoc MD to HTML conversion ----------------------------------\nC:/PROGRA~1/Pandoc/pandoc\" +RTS -K512m -RTS 14_DeepLearning.knit.md --to html4 --from markdown+autolink_bare_uris+tex_math_single_backslash --output 14_DeepLearning.html --lua-filter \"C:\\Users\\Dinov\\Documents\\R\\R-4.1.0\\library\\rmarkdown\\rmarkdown\\lua\\pagebreak.lua\" --lua-filter \"C:\\Users\\Dinov\\Documents\\R\\R-4.1.0\\library\\rmarkdown\\rmarkdown\\lua\\latex-div.lua\" --self-contained --variable bs3=TRUE --standalone --section-divs --table-of-contents --toc-depth 4 --variable toc_float=1 --variable toc_selectors=h1,h2,h3,h4 --variable toc_smooth_scroll=1 --variable toc_print=1 --template \"C:\\Users\\Dinov\\Documents\\R\\R-4.1.0\\library\\rmarkdown\\rmd\\h\\default.html\" --highlight-style tango --number-sections --variable theme=spacelab --mathjax --variable \"mathjax-url=https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML\" --include-in-header \"C:\\Users\\Dinov\\AppData\\Local\\Temp\\RtmpGYmqwX\\rmarkdown-str29ac4225768a.html\" --variable code_folding=show --variable code_menu=1 --include-before-body SOCR_header.html \n-->\n\n<!--html_preserve-->\n<div>\n    \t<footer><center>\n\t\t\t<a href=\"https://www.socr.umich.edu/\">SOCR Resource</a>\n\t\t\t\tVisitor number \n\t\t\t\t<img class=\"statcounter\" src=\"https://c.statcounter.com/5714596/0/038e9ac4/0/\" alt=\"Web Analytics\" align=\"middle\" border=\"0\">\n\t\t\t\t<script type=\"text/javascript\">\n\t\t\t\t\tvar d = new Date();\n\t\t\t\t\tdocument.write(\" | \" + d.getFullYear() + \" | \");\n\t\t\t\t</script> \n\t\t\t\t<a href=\"https://socr.umich.edu/img/SOCR_Email.png\"><img alt=\"SOCR Email\"\n\t \t\t\ttitle=\"SOCR Email\" src=\"https://socr.umich.edu/img/SOCR_Email.png\"\n\t \t\t\tstyle=\"border: 0px solid ;\"></a>\n\t \t\t </center>\n\t \t</footer>\n\n\t<!-- Start of StatCounter Code -->\n\t\t<script type=\"text/javascript\">\n\t\t\tvar sc_project=5714596; \n\t\t\tvar sc_invisible=1; \n\t\t\tvar sc_partition=71; \n\t\t\tvar sc_click_stat=1; \n\t\t\tvar sc_security=\"038e9ac4\"; \n\t\t</script>\n\t\t\n\t\t<script type=\"text/javascript\" src=\"https://www.statcounter.com/counter/counter.js\"></script>\n\t<!-- End of StatCounter Code -->\n\t\n\t<!-- GoogleAnalytics -->\n\t\t<script src=\"https://www.google-analytics.com/urchin.js\" type=\"text/javascript\"> </script>\n\t\t<script type=\"text/javascript\"> _uacct = \"UA-676559-1\"; urchinTracker(); </script>\n\t<!-- End of GoogleAnalytics Code -->\n</div>\n<!--/html_preserve-->",
      "word_count": 205
    }
  ],
  "tables": [
    {
      "section": "before_body: SOCR_header.html",
      "content": "    self_contained: yes\n---",
      "row_count": 2
    },
    {
      "section": "Simple Neural Net Examples",
      "content": "InputX|InputY|XOR Output(Z)    \n------|------|-------------   \n0 | 0 |\t0\n0 | 1 | 1\n1 | 0 | 1\n1 | 1 | 0",
      "row_count": 6
    },
    {
      "section": "Simple Neural Net Examples",
      "content": "InputX|InputY|NAND Output(Z)\n------|------|------------- \n0 | 0 |\t1 \n0 | 1 | 1\n1 | 0 | 1\n1 | 1 | 0",
      "row_count": 6
    },
    {
      "section": "Neural Network Modeling using `Keras`",
      "content": "Package     | Description\n----------  | --------------------------------------------------------------------\nnnet \t      |   Feed-forward neural networks using 1 hidden layer\nneuralnet \t| \tTraining backpropagation neural networks\ntensorflow  |   Google TensorFlow used in TensorBoard (see [SOCR UKBB Demo](https://socr.umich.edu/HTML5/SOCR_TensorBoard_UKBB/))\ndeepnet     |  \tDeep learning toolkit\ndarch       | \tDeep Architectures based on Restricted Boltzmann Machines\nrnn         |   Recurrent Neural Networks (RRNs)\nrcppDL      |   Multi-layer machine learning methods including dA (Denoising Autoencoder), SdA (Stacked Denoising Autoencoder), RBM (Restricted Boltzmann machine), and DBN (Deep Belief Nets)\ndeepr       |   DL training, fine-tuning and predicting processes using darch and deepnet\nMXNetR \t    | \tFlexible and efficient ML/DL tools utilizing CPU/GPU computing\nkerasR      |   RStudio's keras DL implementation wrapping C++/Python executable libraries\nKeras       |   Python based neural networks API, connecting Google TensorFlow, Microsoft Cognitive Toolkit (CNTK), and Theano",
      "row_count": 13
    },
    {
      "section": "Neural Network Modeling using `Keras`",
      "content": "Iteration    |  Description\n------------ | -----------------------------------------------------------------------\nSample       | A singleton from the dataset, i.e., one element such as a patient, case, image, file, etc.\nBatch        | An n-tuple, a set of $n$ samples. All samples in a batch are typically processed independently, e.g., in parallel.  AI training on a batch yields a single model (or model update). Dataset batches should accurately represent the underlying input data distribution, whereas a single sample represents one input. Larger batch sizes correspond to better model fits; however, they require significantly more computing processing power (cf. algorithmic complexity).\nEpoch        | A user-specified iterator that controls the number of passes over the entire dataset. Epochs separate training into independent model estimators and provide mechanisms for performance tracking and algorithmic evaluation.",
      "row_count": 5
    },
    {
      "section": "Case-Studies",
      "content": "Row  | Col0 | Col1 | Col2 | Col3 | Col4 | ... | Col26 | Co27\n-----|------|------|------|------|------|------|------|-----\nRow0 | 000 | 001 | 002 | 003 | 004 | ... | 026 | 027\nRow1 | 028 | 029 | 030 | 031 | 032 | ... | 054 | 055\n**Row2** | 056 | 057 | 058 | 059 | **060** | ... | 082 | 083\nRowK | ...|...|...|...|...|...|...|...| ...\nRow26| 728 | 729 | 730 | 731 | 732 | ... | 754 | 755\nRow27| 756 | 757 | 758 | 759 | 760 | ... | 782 | 783",
      "row_count": 8
    },
    {
      "section": "Data Generation:  simulating synthetic data",
      "content": "map | $A_{1,1}$ | $A_{1,2}$ | $A_{2,1}$ | $A_{2,2}$ | $B_{1}$ | $B_{2}$ | probability\n----|-----------|-----------|-----------|-----------|---------|---------|-----------\nw |\ta |\tb |\tc |\td |\te |\tf |\tp",
      "row_count": 3
    },
    {
      "section": "Data Generation:  simulating synthetic data",
      "content": "map | $A_{1,1}$ | $A_{1,2}$ | $A_{2,1}$ | $A_{2,2}$ | $B_{1}$ | $B_{2}$ | probability | Fern Portion\n----|-----------|-----------|-----------|-----------|---------|---------|-------------|-------------\n$f_1$ | \t0 |\t0 |\t0 |\t0.16 |\t0 |\t0 |\t0.01 |\tStem \n$f_2$ | \t0.85 |\t0.02 |\t−0.02 |\t0.85 |\t0 |\t1.60 |\t0.85 |\tSuccessively smaller leaflets\n$f_3$ | \t0.20 |\t−0.26 |\t0.23 \t| 0.22 |\t0 |\t1.60 |\t0.1 |\tLargest left-hand leaflet\n$f_4$ | −0.15 |\t0.28 |\t0.26 |\t0.24 |\t0 |\t0.44 |\t0.05 |\tLargest right-hand leaflet ",
      "row_count": 6
    },
    {
      "section": "Transfer Learning",
      "content": "| Discrete sets $X$ and $Y$ | (Boolean) Binary Data | Probabilities (e.g., quantiles) |\n|----------------|---------------|-------------------|\n| $D=\\frac{2 |X\\cap Y|}{|X|+|Y|}$, $|\\cdot |$ is set cardinality |  TP=true positive, FP=false positive, FN=false negative, $D=\\frac {2TP}{2TP+FP+FN}$ | $D=\\frac {2|{\\bf{p}}\\cdot {\\bf {q}}|}{|{\\bf{p}}|^{2}+|{\\bf {q}}|^{2}}$ |",
      "row_count": 3
    }
  ],
  "r_code": [
    {
      "section": "Deep Learning Training",
      "code": "library(plotly)\n\nsigmoid <- function(x) { 1 / (1 + exp(-x)) }\nrelu <- function(y) { pmin(pmax(0, y), 1) }\nx_Llimit <- -5; x_Rlimit <- 5; y_Llimit <- 0; y_Rlimit <- 1\nx <- seq(x_Llimit, x_Rlimit, 0.01)\n# plot(c(x_Llimit,x_Rlimit), c(y_Llimit,y_Rlimit), type=\"n\", xlab=\"Input/Domain\", ylab=\"Output/Range\" ) \n# lines(x, sigmoid(x), col=\"blue\", lwd=3)\n# lines(x, (1/2)*(tanh(x)+1), col=\"green\", lwd=3)\n# lines(x, relu(x), col=\"red\", lwd=3)\n# legend(\"left\", title=\"Probability Transform Functions\",\n#        c(\"sigmoid\",\"tanh\",\"relu\"), fill=c(\"blue\", \"green\", \"red\"),\n#       ncol = 1, cex = 0.75)\ny <- sigmoid(x)\n\nplot_ly(type=\"scatter\")  %>%\n  add_trace(x = ~x, y=~y, name = 'Sigmoid()', mode = 'lines') %>%\n  add_trace(x = ~x, y = ~(1/2)*(tanh(x)+1), name = 'Tanh()', mode = 'lines') %>%\n  add_trace(x = ~x, y = ~relu(x+1/2), name = 'Relu()', mode = 'lines')%>%\n  layout(legend = list(orientation = 'h'), title=\"Probability Transformation Functions\")\n",
      "line_count": 21
    },
    {
      "section": "Deep Learning Training",
      "code": "# install.packages(\"GGally\"); install.packages(\"sna\"); install.packages(\"network\")\n# library(\"GGally\"); library(network); library(sna); library(ggplot2)\n\nlibrary('igraph')\n#define node names\nnodes <- c('a(1,1)','a(2,1)','a(3,1)','a(4,1)', 'a(5,1)', 'a(6,1)', 'a(7,1)',\n           'a(1,2)','a(2,2)','a(3,2)','a(4,2)', 'a(5,2)',\n           'a(1,3)','a(2,3)','a(3,3)',\n           'a(1,4)','a(2,4)'\n           )\n# define node x,y coordinates\nx <- c(rep(0,7), rep(2,5), rep(4,3), rep(6,2)\n       )\ny <- c(1:7, 2:6, 3:5, 4:5)\n# x;y  # print x & y coordinates of all nodes\n\n#define edges\nfrom <- c('a(1,1)','a(2,1)','a(3,1)','a(4,1)', 'a(5,1)', 'a(6,1)', 'a(7,1)',\n          'a(1,1)','a(2,1)','a(3,1)','a(4,1)', 'a(5,1)', 'a(6,1)', 'a(7,1)',\n          'a(1,1)','a(2,1)','a(3,1)','a(4,1)', 'a(5,1)', 'a(6,1)', 'a(7,1)',\n          'a(1,1)','a(2,1)','a(3,1)','a(4,1)', 'a(5,1)', 'a(6,1)', 'a(7,1)',\n          'a(1,1)','a(2,1)','a(3,1)','a(4,1)', 'a(5,1)', 'a(6,1)', 'a(7,1)',\n          'a(1,2)','a(2,2)','a(3,2)','a(4,2)', 'a(5,2)',\n          'a(1,2)','a(2,2)','a(3,2)','a(4,2)', 'a(5,2)',\n          'a(1,2)','a(2,2)','a(3,2)','a(4,2)', 'a(5,2)',\n          'a(1,3)','a(2,3)','a(3,3)',\n          'a(1,3)','a(2,3)','a(3,3)'\n          )\nto <- c('a(1,2)','a(1,2)','a(1,2)','a(1,2)', 'a(1,2)', 'a(1,2)', 'a(1,2)',\n        'a(2,2)','a(2,2)','a(2,2)','a(2,2)', 'a(2,2)', 'a(2,2)', 'a(2,2)',\n        'a(3,2)','a(3,2)','a(3,2)','a(3,2)', 'a(3,2)', 'a(3,2)', 'a(3,2)',\n        'a(4,2)','a(4,2)','a(4,2)','a(4,2)', 'a(4,2)', 'a(4,2)', 'a(4,2)',\n        'a(5,2)','a(5,2)','a(5,2)','a(5,2)', 'a(5,2)', 'a(5,2)', 'a(5,2)',\n        'a(1,3)','a(1,3)','a(1,3)','a(1,3)', 'a(1,3)',\n        'a(2,3)','a(2,3)','a(2,3)','a(2,3)', 'a(2,3)',\n        'a(3,3)','a(3,3)','a(3,3)','a(3,3)', 'a(3,3)',\n        'a(1,4)','a(1,4)','a(1,4)',\n        'a(2,4)','a(2,4)', 'a(2,4)'\n        )\nedge_names <- c(\"w(i=1,k=1,l=2)\",\"\",\"\",\"\", \"\", \"\", \"\",\n        \"\",\"\",\"\",\"\", \"\", \"\", \"\",\n        \"\",\"\",\"\",\"w(i=4,k=3,l=2)\", \"\", \"\", \"\",\n        \"\",\"\",\"\",\"\", \"\", \"\", \"\",\n        \"\",\"\",\"\",\"\", \"\", \"\", \"w(i=5,k=7,l=2)\",\n        \"\",\"\",\"\",\"\", \"\",\n        \"\",\"\",\"\",\"\", \"\",\n        \"\",\"w(i=2,k=3,l=3)\",\"\", \"\", \"\",\n        \"w(i=1,k=1,l=4)\",\"\",\"\",\n        \"\",\"\", \"w(i=2,k=3,l=4)\"\n        )\n  \nNodeList <- data.frame(nodes, x ,y)\nEdgeList <- data.frame(from, to, edge_names)\nnn.graph <- graph_from_data_frame(vertices = NodeList, d= EdgeList, directed = TRUE) %>% set_edge_attr(\"label\", value = edge_names)\n# plot(nn.graph)",
      "line_count": 55
    },
    {
      "section": "Deep Learning Training",
      "code": "# igraph examples: http://michael.hahsler.net/SMU/LearnROnYourOwn/code/igraph.html\nmap <- function(x, range = c(0,1), from.range=NA) {\n    if(any(is.na(from.range))) from.range <- range(x, na.rm=TRUE)\n    \n    ## check if all values are the same\n    if(!diff(from.range)) return(\n\t    matrix(mean(range), ncol=ncol(x), nrow=nrow(x), \n\t\t    dimnames = dimnames(x)))\n    \n    ## map to [0,1]\n    x <- (x-from.range[1])\n    x <- x/diff(from.range)\n    ## handle single values\n    if(diff(from.range) == 0) x <- 0 \n    \n    ## map from [0,1] to [range]\n    if (range[1]>range[2]) x <- 1-x\n    x <- x*(abs(diff(range))) + min(range)\n    x[x<min(range) | x>max(range)] <- NA\n    \n    return(x)\n}\n\ncol <- rep(\"gray\",length(V(nn.graph))) # input layer\ncol[c(1:7, 16:17)] <- \"lightblue\"      # hidden layer\ncol[16:17] <- \"lightgreen\"             # output layer\nplot(nn.graph, vertex.color=col, vertex.size=map(betweenness(nn.graph),c(25,30)), ylab=\"Input Layer\", xlab=\"A schematic of fully-connected feed-forward neural network\")\n\n# plot(nn.graph, vertex.size=map(betweenness(nn.graph),c(20,30)), edge.width=map(edge.betweenness(nn.graph), c(1,5)))",
      "line_count": 29
    },
    {
      "section": "Deep Learning Training",
      "code": "col <- rep(\"gray\",length(V(nn.graph))) # input layer\ncol[c(1:7, 16:17)] <- \"lightblue\"      # hidden layer\ncol[16:17] <- \"lightgreen\"             # output layer\nplot(nn.graph, vertex.color=col)\ntitle(main=\"A schematic of fully-connected feed-forward neural network\")\nmtext(\"Input Layer (l=1)\", side=2, line=-1, col=\"blue\")\nmtext(\"     Output Layer (l=4)\", side=4, line=-2, col=\"green\")\nmtext(\"Hidden Layers (l=2,3)\", side=1, line=0, col=\"gray\")",
      "line_count": 8
    },
    {
      "section": "Simple Neural Net Examples",
      "code": "# install.packages(\"network\")\nlibrary('igraph')\n#define node names\nnodes <- c('X', 'Y',                            # Inputs (0,1)\n           'H_1_1_th1','H_1_2_th2','H_1_3_th1', # Hidden Layer\n           'Z'                                  # Output Layer (0,1)\n           )\n# define node x,y coordinates\nx <- c(rep(0,2), rep(2,3), 4)\ny <- c(c(1.5, 2.5), 1:3, 2)\n##x;y  # print x & y coordinates of all nodes\n\n#define edges\nfrom <- c('X', 'X', \n          'Y', 'Y',\n          'H_1_1_th1', 'H_1_2_th2', 'H_1_3_th1',\n          'Z'\n          )\nto <- c('H_1_1_th1', 'H_1_2_th2',\n        'H_1_2_th2', 'H_1_3_th1', \n        'Z', 'Z', 'Z', 'Z'\n        )\nedge_names <- c(\n        '1', '1',\n        '1', '1',\n        '1', '-2', '1', '1'\n        )\n  \nNodeList <- data.frame(nodes, x ,y)\nEdgeList <- data.frame(from, to, edge_names)\nnn.graph <- graph_from_data_frame(vertices = NodeList, d= EdgeList, directed = TRUE) %>% set_edge_attr(\"label\", value = edge_names)\n# plot(nn.graph)\n\n# See the iGraph specs here: http://kateto.net/networks-r-igraph\n\ncol <- rep(\"gray\",length(V(nn.graph))) # input layer\ncol[c(3:5)] <- \"lightblue\"             # hidden layer\ncol[6] <- \"lightgreen\"                 # output layer\nplot(nn.graph, vertex.color=col, vertex.shape=\"sphere\", vertex.size=c(35, 35,   80, 80, 80, 35), edge.label.cex=1.5)\ntitle(main=\"XOR Operator\")\nmtext(\"Input Layer: Bivariate (0,1)\", side=2, line=-1, col=\"blue\")\nmtext(\"     Output Layer (XOR)\", side=4, line=-2, col=\"green\")\nmtext(\"Hidden Layers (Neurons)\", side=1, line=0, col=\"gray\")",
      "line_count": 43
    },
    {
      "section": "Simple Neural Net Examples",
      "code": "par(mfrow=c(2,2))    # 2 x 2 design\nnodes <- c('X=0', 'Y=0',                        # Inputs \n           'H_1_1_th1','H_1_2_th2','H_1_3_th1', # Hidden Layer\n           'Z=0'                                # Output Layer (0,1)\n           )\n# define node x,y coordinates\nx <- c(rep(0,2), rep(2,3), 4)\ny <- c(c(1.5, 2.5), 1:3, 2)\n# x;y  # print x & y coordinates of all nodes\n\n######### (0,0)\n#define edges\nfrom <- c('X=0', 'X=0', \n          'Y=0', 'Y=0',\n          'H_1_1_th1', 'H_1_2_th2', 'H_1_3_th1',\n          'Z=0'\n          )\nto <- c('H_1_1_th1', 'H_1_2_th2',\n        'H_1_2_th2', 'H_1_3_th1', \n        'Z=0', 'Z=0', 'Z=0', 'Z=0'\n        )\nedge_names <- c(\n        '1', '1',\n        '1', '1',\n        '1', '-2', '1', '1'\n        )\n  \nNodeList <- data.frame(nodes, x ,y)\nEdgeList <- data.frame(from, to, edge_names)\nnn.graph <- graph_from_data_frame(vertices = NodeList, d= EdgeList, directed = TRUE) %>% set_edge_attr(\"label\", value = edge_names)\n\ncol <- rep(\"gray\",length(V(nn.graph))) # input layer\ncol[c(3:5)] <- \"lightblue\"             # hidden layer\ncol[6] <- \"lightgreen\"                 # output layer\nplot(nn.graph, vertex.color=col, vertex.shape=\"pie\", vertex.size=c(30, 30,   40, 40, 40, 30), edge.label.cex=2,\n     edge.arrow.size=0.25)\ntitle(main=\"XOR Operator\")\nmtext(\"Input Layer: Bivariate (X=0,Y=0)\", side=2,line=-1, col=\"blue\")\nmtext(\"     Output Layer (XOR), Z=0\", side=4, line=-2, col=\"green\")\nmtext(\"Hidden Layers (Neurons)\", side=1, line=0, col=\"gray\")\n\n######### (0,1)\nnodes <- c('X=0', 'Y=1',                        # Inputs \n           'H_1_1_th1','H_1_2_th2','H_1_3_th1', # Hidden Layer\n           'Z=1'                                # Output Layer (0,1)\n           )\n#define edges\nfrom <- c('X=0', 'X=0', \n          'Y=1', 'Y=1',\n          'H_1_1_th1', 'H_1_2_th2', 'H_1_3_th1',\n          'Z=1'\n          )\nto <- c('H_1_1_th1', 'H_1_2_th2',\n        'H_1_2_th2', 'H_1_3_th1', \n        'Z=1', 'Z=1', 'Z=1',\n        'Z=1'\n        )\n\nNodeList <- data.frame(nodes, x ,y)\nEdgeList <- data.frame(from, to, edge_names)\nnn.graph <- graph_from_data_frame(vertices = NodeList, d= EdgeList, directed = TRUE) %>% set_edge_attr(\"label\", value = edge_names)\n\ncol <- rep(\"gray\",length(V(nn.graph))) # input layer\ncol[c(3:5)] <- \"lightblue\"             # hidden layer\ncol[6] <- \"lightgreen\"                 # output layer\nplot(nn.graph, vertex.color=col, vertex.shape=\"pie\", vertex.size=c(30, 30,   40, 40, 40, 30), edge.label.cex=1,\n     edge.arrow.size=0.25)\ntitle(main=\"XOR Operator\")\nmtext(\"Input Layer: Bivariate (X=0,Y=1)\",side=2,line=-1, col=\"blue\")\nmtext(\"     Output Layer (XOR), Z=1\", side=4, line=-2, col=\"green\")\nmtext(\"Hidden Layers (Neurons)\", side=1, line=0, col=\"gray\")\n\n######### (1,0)\nnodes <- c('X=1', 'Y=0',                        # Inputs \n           'H_1_1_th1','H_1_2_th2','H_1_3_th1', # Hidden Layer\n           'Z=1'                                # Output Layer (0,1)\n           )\n#define edges\nfrom <- c('X=1', 'X=1', \n          'Y=0', 'Y=0',\n          'H_1_1_th1', 'H_1_2_th2', 'H_1_3_th1',\n          'Z=1'\n          )\nto <- c('H_1_1_th1', 'H_1_2_th2',\n        'H_1_2_th2', 'H_1_3_th1', \n        'Z=1', 'Z=1', 'Z=1',\n        'Z=1'\n        )\n\nNodeList <- data.frame(nodes, x ,y)\nEdgeList <- data.frame(from, to, edge_names)\nnn.graph <- graph_from_data_frame(vertices = NodeList, d= EdgeList, directed = TRUE) %>% set_edge_attr(\"label\", value = edge_names)\n\ncol <- rep(\"gray\",length(V(nn.graph))) # input layer\ncol[c(3:5)] <- \"lightblue\"             # hidden layer\ncol[6] <- \"lightgreen\"                 # output layer\nplot(nn.graph, vertex.color=col, vertex.shape=\"pie\", vertex.size=c(30, 30,   40, 40, 40, 30), edge.label.cex=1,\n     edge.arrow.size=0.25)\ntitle(main=\"XOR Operator\")\nmtext(\"Input Layer: Bivariate (X=1,Y=0)\", side=2,line=-1, col=\"blue\")\nmtext(\"     Output Layer (XOR), Z=1\", side=4, line=-2, col=\"green\")\nmtext(\"Hidden Layers (Neurons)\", side=1, line=0, col=\"gray\")\n\n######### (1,1)\nnodes <- c('X=1', 'Y=1',                        # Inputs \n           'H_1_1_th1','H_1_2_th2','H_1_3_th1', # Hidden Layer\n           'Z=0'                                # Output Layer (1,1)\n           )\n#define edges\nfrom <- c('X=1', 'X=1', \n          'Y=1', 'Y=1',\n          'H_1_1_th1', 'H_1_2_th2', 'H_1_3_th1',\n          'Z=0'\n          )\nto <- c('H_1_1_th1', 'H_1_2_th2',\n        'H_1_2_th2', 'H_1_3_th1', \n        'Z=0', 'Z=0', 'Z=0',\n        'Z=0'\n        )\n\nNodeList <- data.frame(nodes, x ,y)\nEdgeList <- data.frame(from, to, edge_names)\nnn.graph <- graph_from_data_frame(vertices = NodeList, d= EdgeList, directed = TRUE) %>% set_edge_attr(\"label\", value = edge_names)\n\ncol <- rep(\"gray\",length(V(nn.graph))) # input layer\ncol[c(3:5)] <- \"lightblue\"             # hidden layer\ncol[6] <- \"lightgreen\"                 # output layer\nplot(nn.graph, vertex.color=col, vertex.shape=\"pie\", vertex.size=c(30, 30,   40, 40, 40, 30), edge.label.cex=1.5,\n     edge.arrow.size=0.25)\ntitle(main=\"XOR Operator\")\nmtext(\"Input Layer: Bivariate (X=1,Y=1)\",side=2,line=-1, col=\"blue\")\nmtext(\"     Output Layer (XOR), Z=0\", side=4, line=-2, col=\"green\")\nmtext(\"Hidden Layers (Neurons)\", side=1, line=0, col=\"gray\")",
      "line_count": 133
    },
    {
      "section": "Simple Neural Net Examples",
      "code": "\n# install.packages(\"network\")\nlibrary('igraph')\n#define node names\nnodes <- c('X', 'Y',                            # Inputs (0,1)\n           'H_th=1.3-(X+Y)',            # Hidden Layer\n           'Z'                                  # Output Layer (0,1)\n           )\n# define node x,y coordinates\nx <- c(rep(0,2), 2, 4)\ny <- c(c(1.5, 2.5), 2, 2)\n#x;y  # print x & y coordinates of all nodes\n\n#define edges\nfrom <- c('X', 'Y', \n          'H_th=1.3-(X+Y)'\n          )\nto <- c('H_th=1.3-(X+Y)', 'H_th=1.3-(X+Y)',\n        'Z'\n        )\nedge_names <- c(\n        '-1', '-1',\n        '1'\n        )\n  \nNodeList <- data.frame(nodes, x ,y)\nEdgeList <- data.frame(from, to, edge_names)\nnn.graph <- graph_from_data_frame(vertices = NodeList, d= EdgeList, directed = TRUE) %>% set_edge_attr(\"label\", value = edge_names)\n# plot(nn.graph)\n\n# See the iGraph specs here: http://kateto.net/networks-r-igraph\n\ncol <- rep(\"gray\",length(V(nn.graph))) # input layer\ncol[c(3)] <- \"lightblue\"             # hidden layer\ncol[4] <- \"lightgreen\"                 # output layer\nplot(nn.graph, vertex.color=col, vertex.shape=\"sphere\", vertex.size=c(35, 35,   80,    35), edge.label.cex=2)\ntitle(main=\"NAND Operator\")\nmtext(\"Input Layer: Bivariate (X,Y)\", side=2, line=-1, col=\"blue\")\nmtext(\"     Output Layer (NAND)\", side=4, line=-2, col=\"green\")\nmtext(\"Hidden Layers (Neurons)\", side=1, line=0, col=\"gray\")",
      "line_count": 40
    },
    {
      "section": "Neural Network Modeling using `Keras`",
      "code": "# Install Git on the system, outside RStudio: https://git-scm.com/download/win\n\nreticulate::install_python()\nlibrary(reticulate)\ninstall.packages(\"keras\")\nlibrary(keras)\ninstall_keras()",
      "line_count": 7
    },
    {
      "section": "Neural Network Modeling using `Keras`",
      "code": "\nvenv_name <- \"r-tensorflow\"\nreticulate::use_virtualenv(virtualenv = venv_name, required = TRUE)\nlibrary(reticulate)\n\n# install.packages(\"remotes\")\nremotes::install_github(\"rstudio/tfds\")\ntfds::install_tfds()",
      "line_count": 8
    },
    {
      "section": "Neural Network Modeling using `Keras`",
      "code": "venv_name <- \"r-tensorflow\"\nreticulate::use_virtualenv(virtualenv = venv_name, required = TRUE)\nlibrary(reticulate)\n\n# Install tensofrlow addons\nreticulate::py_install(c('tensorflow-addons'), pip = TRUE)\ndevtools::install_github('henry090/tfaddons')\ntfaddons::install_tfaddons()",
      "line_count": 8
    },
    {
      "section": "Neural Network Modeling using `Keras`",
      "code": "venv_name <- \"r-tensorflow\"\nreticulate::use_virtualenv(virtualenv = venv_name, required = TRUE)\nlibrary(reticulate)\n\n# use_condaenv(condaenv = \"pytorch_env\", required = TRUE)\n\n# devtools::install_github(\"rstudio/keras\")\nlibrary(\"keras\")\n# install_keras()\n\n# install.packages(\"tensorflow\")\n# remotes::install_github(\"rstudio/tensorflow\")\nlibrary(tensorflow)\n\n# install_tensorflow()\n# tfaddons::install_tfaddons() \nlibrary(tfaddons)",
      "line_count": 17
    },
    {
      "section": "Neural Network Modeling using `Keras`",
      "code": "mnist <- dataset_mnist()\nimdb <- dataset_imdb()",
      "line_count": 2
    },
    {
      "section": "Neural Network Modeling using `Keras`",
      "code": "library(reshape)\nlibrary(caret)\ndat <- read.csv(\"https://umich.instructure.com/files/9372716/download?download_frd=1\")\n\n# Inspect for missing values (empty or NA):\ndat.miss <- melt(apply(dat[, -2], 2, function(x) sum(is.na(x) | x==\"\")))\ncbind(row.names(dat.miss)[dat.miss$value>0], dat.miss[dat.miss$value>0,])\n\n# We can exclude the \"Cabin\" feature which includes 80% missing values. \n\n# Impute the few missing Embarked values using the most common value (S)\ntable(dat$embarked)\ndat$embarked[which(is.na(dat$embarked) | dat$embarked==\"\")] <- \"S\"\n\n# Some \"fare\"\" values may represent total cost of group purchases\n# We can derive a new variable \"price\" representing fare per person\n# Update missing fare value with 0\ndat$fare[which(is.na(dat$fare))] <- 0 \n# calculate ticket Price (Fare per person)\nticket.count <- aggregate(dat$ticket, by=list(dat$ticket), function(x) sum( !is.na(x) ))\ndat$price <- apply(dat, 1, function(x) as.numeric(x[\"fare\"]) /\n            ticket.count[which(ticket.count[, 1] == x[\"ticket\"]), 2])\n\n# Impute missing prices (price=0) using the median price per passenger class\npclass.price<-aggregate(dat$price, by = list(dat$pclass), FUN = function(x) median(x, na.rm = T))\ndat[which(dat$price==0), \"price\"] <- \n  apply(dat[which(dat$price==0), ] , 1, function(x)\n    pclass.price[pclass.price[, 1]==x[\"pclass\"], 2])\n\n# Define a new variable \"ticketcount\" coding the number of passengers sharing the same ticket number\ndat$ticketcount <- \n  apply(dat, 1, function(x) ticket.count[which(ticket.count[, 1] ==\n                                                 x[\"ticket\"]), 2])\n\n# Capture the passenger title\ndat$title <- \n  regmatches(as.character(dat$name),\n             regexpr(\"\\\\,[A-z ]{1,20}\\\\.\", as.character(dat$name)))\ndat$title <-\n  unlist(lapply(dat$title,\n            FUN=function(x) substr(x, 3, nchar(x)-1)))\ntable(dat$title)\n\n# Bin the 17 alternative title groups into 4 common 4 titles (factors)\ndat$title[which(dat$title %in% c(\"Mme\", \"Mlle\"))] <- \"Miss\"\ndat$title[which(dat$title %in% \n                  c(\"Lady\", \"Ms\", \"the Countess\", \"Dona\"))] <- \"Mrs\"\ndat$title[which(dat$title==\"Dr\" & dat$sex==\"female\")] <- \"Mrs\"\ndat$title[which(dat$title==\"Dr\" & dat$sex==\"male\")] <- \"Mr\"\ndat$title[which(dat$title %in% c(\"Capt\", \"Col\", \"Don\", \n                  \"Jonkheer\", \"Major\", \"Rev\", \"Sir\"))] <- \"Mr\"\ndat$title <- as.factor(dat$title) \ntable(dat$title)\n\n# Impute missing ages using median age for each title group\ntitle.age <- aggregate(dat$age, by = list(dat$title), \n                    FUN = function(x) median(x, na.rm = T))\ndat[is.na(dat$age), \"age\"] <- apply(dat[is.na(dat$age), ] , 1, \n              function(x) title.age[title.age[, 1]==x[\"title\"], 2])",
      "line_count": 59
    },
    {
      "section": "Neural Network Modeling using `Keras`",
      "code": "library(ggplot2)\nlibrary(plotly)\nsummary(dat)\n\n# cols <- c(\"red\",\"green\")[unclass(dat$survived)]\n# \n# plot(dat$ticketcount, dat$fare, pch=21, cex=1.5,\n#      bg=alpha(cols, 0.4),\n#      xlab=\"Number of Tickets per Party\", ylab=\"Passenger Fare\", \n#      main=\"Titanic Passenger Data (TicketCount vs. Fare) Color Coded by Survival\")\n# legend(\"topright\", inset=.02, title=\"Survival\",\n#    c(\"0\",\"1\"), fill=c(\"red\", \"green\"), horiz=F, cex=0.8)\n\nplot_ly(dat, type=\"scatter\", mode=\"markers\")  %>%\n    add_trace(x = ~ticketcount, y=~fare, mode = 'markers', \n              color = ~as.character(survived), colors=~survived) %>%\n    layout(legend = list(title=list(text='<b> Survival </b>'), orientation = 'h'), \n           title=\"Titanic Passenger Data (TicketCount vs. Fare) Color Coded by Survival\")\n\n# plot_ly(dat, x = ~ticketcount, color = ~survived) %>% add_histogram()\n# \n# plot_ly(dat, x = ~ticketcount, y = ~fare, color = ~survived, name=~survived) %>% add_bars() %>% layout(barmode = \"stack\")\n\n\n# ggplot(dat, aes(x=survived, y=fare, fill=sex)) + \n#   #geom_dotplot(binaxis='y', stackdir='center',\n#   #               position=position_dodge(1)) +\n#   #scale_fill_manual(values=c(\"#999999\", \"#E69F00\")) +\n#   geom_violin(trim=FALSE) +\n#   theme(legend.position=\"top\")\n\n\nfig <- dat %>% plot_ly(type = 'violin') \nfig <- fig %>% add_trace(x = ~survived[dat$survived == '1'], y = ~fare[dat$survived == '1'],\n    legendgroup = 'survived',   scalegroup = 'survived',  name = 'survived',  \n    box = list(visible = T),  meanline = list(visible = T ),  color = I(\"green\")) \nfig <- fig %>% add_trace(x = ~survived[dat$survived == '0'], y = ~fare[dat$survived == '0'],\n    legendgroup = 'died',   scalegroup = 'died',  name = 'died',  \n    box = list(visible = T),  meanline = list(visible = T ),  color = I(\"red\"))\nfig <- fig %>% layout( xaxis = list(title=\"Survival\"), yaxis = list(title=\"Fare\"),\n                       title='<b> Titanic Passenger Survival vs. Fare </b>', orientation = 'h')\nfig\n\n# library(GGally)\n# ggpairs(dat[ , c(\"pclass\", \"age\", \"sibsp\", \"parch\", \n#                  \"fare\", \"price\", \"ticketcount\", \"survived\")], \n#         aes(colour = as.factor(survived), alpha = 0.4))\n\ndims <- dplyr::select_if(dat, is.numeric)\ndims <- purrr::map2(dims, names(dims), ~list(values=.x, label=.y))\nplot_ly(type = \"splom\", dimensions = setNames(dims, NULL), showupperhalf = FALSE, \n        diagonal = list(visible = FALSE) ) %>% \n  layout( title='<b> Titanic Passengers Pairs-Plots </b>')",
      "line_count": 53
    },
    {
      "section": "Neural Network Modeling using `Keras`",
      "code": "dat1 <- dat[ , c(\"pclass\", \"age\", \"sibsp\", \"parch\", \"fare\", \n                 \"price\", \"ticketcount\", \"survived\")]\ndat1$pclass <- as.factor(dat1$pclass)\ndat1$age <- as.numeric(dat1$age)\ndat1$sibsp <- as.factor(dat1$sibsp)\ndat1$parch <- as.factor(dat1$parch)\ndat1$fare <- as.numeric(dat1$fare)\ndat1$price <- as.numeric(dat1$price)\ndat1$ticketcount <- as.numeric(dat1$ticketcount)\ndat1$survived <- as.factor(dat1$survived)\n\n# Set the `dimnames` to `NULL`\n# dimnames(dat1) <- NULL\ndim(dat1)",
      "line_count": 14
    },
    {
      "section": "Neural Network Modeling using `Keras`",
      "code": "### library(tensorflow)\n#   tensorflow::install_tensorflow()\n# reticulate::py_module_available(\"tensorflow\")\n# reticulate::conda_list()\nlibrary(tensorflow)\n# use_virtualenv(\"r-tensorflow\")\n\n# devtools::install_github(\"rstudio/keras\")\n# First install Anaconda/Python: https://www.anaconda.com/download/#windows\n# install_keras()\n# reticulate::py_config()\n# library(\"keras\")\n# use_python(\"C:/Users/Dinov/AppData/Local/Programs/Python/Python37/python.exe\")\n# install_keras()\n# install_keras(method = \"conda\")\n# install_tensorflow()\n\n# reticulate::virtualenv_starter(all = TRUE)\n\nlibrary(\"keras\")\n\n# Check Conda/Python Environments on the system\n# conda_list()\n\n# For local PC testing use  conda...\n# Create a new \"pytorch_env\" environment first\n#   https://rstudio.github.io/reticulate/articles/python_packages.html\n#    library(reticulate)\n#    conda_create(name = \"pytorch_env\", \n#       packages = c(\"python=3.8\", \"torch\", \"pillow\", \"numpy\", \"pybase64\", \"uuid\"))\n\n#    in terminal\n#        %> conda create --name pytorch_env python=3.8 \n#        %> conda activate pytorch_env\n#        %> pip install torch pillow numpy pybase64 uuid tensorflow typing-extensions tensorflow-addons\n#\n# use_condaenv(condaenv = \"pytorch_env\", required = TRUE)\n\n# py_path = \"C:/Users/IvoD/Anaconda3/\"  # manual\n# py_path = \"C:/Users/IvoD/Documents/.virtualenvs/r-tensorflow/Scripts/python.exe\"\n\n# py_path = Sys.which(\"python3\")       # automated\n#  use_python(py_path, required = T) \n# Sys.setenv(RETICULATE_PYTHON = \"C:/Users/IvoD/Anaconda3/\")\n\n# library(\"tensorflow\")\n# Normalize the data\nsummary(dat1[ , c(2,5,6,7)])\ndat2 <- dat1[ , c(2,5,6,7)]\ndat2 <- as.matrix(dat2)\ndimnames(dat2) <- NULL\n# May be best to avoid normalizing the ordinal variable \"ticketcount\"\ndat2.norm <- normalize(dat2, axis=2)\n\n# report the summary`\nsummary(dat2.norm)\ncolnames(dat2.norm) <- c(\"age\", \"fare\", \"price\", \"ticketcount\")",
      "line_count": 57
    },
    {
      "section": "Neural Network Modeling using `Keras`",
      "code": "train_set_ind <- sample(nrow(dat2.norm), floor(nrow(dat2.norm)*0.8)) # 80:20 plot training:testing\ntrain_dat2.X <- dat2.norm[train_set_ind, ]\ntrain_dat2.Y <- dat1[train_set_ind , 8]  # Outcome \"survived\" column:8\n\ntest_dat2.X <- dat2.norm[-train_set_ind, ]\ntest_dat2.Y <- dat1[-train_set_ind , 8]  # Outcome \"survived\" column:8\n\n# double check the size/dimensions of the training and testing data (predictors and responses)\ndim(train_dat2.X); length(train_dat2.Y); dim(test_dat2.X); length(test_dat2.Y)",
      "line_count": 9
    },
    {
      "section": "Neural Network Modeling using `Keras`",
      "code": "model.1 <- keras_model_sequential() \n# library(keras3)\n\n# Add layers to the model\nmodel.1 %>% \n    layer_dense(units = 8, activation = 'relu', input_shape = c(4)) %>% \n    layer_dense(units = 2, activation = 'softmax')\n\n# NN model summary\nsummary(model.1)\n# Report model configuration\nget_config(model.1)\n# report layer configuration\nget_layer(model.1, index = 1)\n# Report model layers\nmodel.1$layers\n# List the input tensors\nmodel.1$inputs\n# List the output tensors\nmodel.1$outputs",
      "line_count": 20
    },
    {
      "section": "Neural Network Modeling using `Keras`",
      "code": "# \"Compile\" the model\nmodel.1 %>% compile(\n     loss = 'binary_crossentropy',\n     optimizer = 'adam',\n     metrics = 'accuracy'\n )",
      "line_count": 6
    },
    {
      "section": "Neural Network Modeling using `Keras`",
      "code": "# convert the labels to categorical values\ntrain_dat2.Y <- to_categorical(train_dat2.Y)\ntest_dat2.Y <- to_categorical(test_dat2.Y)\n\n# library(keras3)\n\n# Fit the model & Store the fitting history\ntrack.model.1 <- model.1 %>% fit(\n     train_dat2.X, \n     train_dat2.Y, \n     epochs = 200, \n     batch_size = 10, \n     validation_split = 0.2\n )",
      "line_count": 14
    },
    {
      "section": "Neural Network Modeling using `Keras`",
      "code": "# Plot the history\n# plot(track.model.1)\n# \n# # NN model loss on the training data\n# plot(track.model.1$metrics$loss, main=\"Model 1 Loss\", \n#      xlab = \"Epoch\", ylab=\"Loss\", col=\"green\", type=\"l\", ylim=c(0.54, 0.6))\n# \n# # NN model loss of the 20% validation data\n# lines(track.model.1$metrics$val_loss, col=\"blue\", type=\"l\")\n# \n# # Add legend\n# legend(\"right\", c(\"train\", \"test\"), col=c(\"green\", \"blue\"), lty=c(1,1))\n# \n# # Plot the accuracy of the training data \n# plot(track.model.1$metrics$acc, main=\"Model 1 Accuracy\", \n#      xlab = \"Epoch\", ylab=\"Accuracy\", col=\"blue\", type=\"l\", ylim=c(0.65, 0.75))\n# \n# # Plot the accuracy of the validation data\n# lines(track.model.1$metrics$val_acc, col=\"green\")\n# \n# # Add Legend\n# legend(\"bottom\", c(\"Training\", \"Testing\"), col=c(\"blue\", \"green\"), lty=c(1,1))\n\n## plot_ly\nepochs <- 200\ntime <- 1:epochs\nhist_df <- data.frame(time=time, loss=track.model.1$metrics$loss, acc=track.model.1$metrics$acc,\n                      valid_loss=track.model.1$metrics$val_loss, valid_acc=track.model.1$metrics$val_acc)\n\nplot_ly(hist_df, x = ~time)  %>%\n  add_trace(y = ~loss, name = 'training loss', mode = 'lines') %>%\n  add_trace(y = ~acc, name = 'training accuracy', mode = 'lines+markers') %>%\n  add_trace(y = ~valid_loss, name = 'validation loss',mode = 'lines+markers') %>%\n  add_trace(y = ~valid_acc, name = 'validation accuracy', mode = 'lines+markers') %>% \n  layout(title=\"Titanic NN Model Performance\",\n           legend = list(orientation = 'h'), yaxis=list(title=\"metric\"))",
      "line_count": 36
    },
    {
      "section": "Neural Network Modeling using `Keras`",
      "code": "# Predict the classes for the test data\npredict.survival <- model.1 %>% predict(test_dat2.X, batch_size = 30) %>%  k_argmax()\n\n# Confusion matrix\ntest_dat2.Y <- dat1[-train_set_ind , 8]\ntable(test_dat2.Y, predict.survival$numpy())\ncaret::confusionMatrix(test_dat2.Y, as.factor(predict.survival$numpy()))",
      "line_count": 7
    },
    {
      "section": "Neural Network Modeling using `Keras`",
      "code": "# Evaluate on test data and labels\ntest_dat2.Y <- to_categorical(test_dat2.Y)\nmodel1.qual <- model.1 %>% evaluate(test_dat2.X, test_dat2.Y, batch_size = 30)\nprint(model1.qual)",
      "line_count": 4
    },
    {
      "section": "Neural Network Modeling using `Keras`",
      "code": "# Initialize the sequential model\nmodel.2 <- keras_model_sequential() \n\n# Add layers to model\nmodel.2 %>% \n    layer_dense(units = 8, activation = 'relu', input_shape = c(4)) %>% \n    layer_dense(units = 6, activation = 'relu') %>% \n    layer_dense(units = 2, activation = 'softmax')\n\n# Compile the model\nmodel.2 %>% compile(\n     loss = 'binary_crossentropy',\n     optimizer = 'adam',\n     metrics = 'accuracy'\n )\n\n# Fit NN model to training data & Save the training history\ntrack.model.2 <- model.2 %>% fit(\n     train_dat2.X, \n     train_dat2.Y, \n     epochs = 200, \n     batch_size = 10, \n     validation_split = 0.2\n )\n\n# Evaluate the model\nmodel2.qual <- model.2 %>% evaluate(test_dat2.X, test_dat2.Y, batch_size = 30)\nprint(model2.qual)\n\n# EDA on the loss and accuracy metrics of this model.2\n# Plot the history\n# plot(track.model.2)\n# \n# # NN model loss on the training data\n# plot(track.model.2$metrics$loss, main=\"Model Loss\", \n#      xlab = \"Epoch\", ylab=\"Loss\", col=\"green\", type=\"l\", ylim=c(0.54, 0.6))\n# \n# # NN model loss of the 20% validation data\n# lines(track.model.2$metrics$val_loss, col=\"blue\", type=\"l\")\n# \n# # Add legend\n# legend(\"right\", c(\"Training\", \"Testing\"), col=c(\"green\", \"blue\"), lty=c(1,1))\n# \n# # Plot the accuracy of the training data \n# plot(track.model.2$metrics$acc, main=\"Model 2 (Extra Layer) Accuracy\", \n#      xlab = \"Epoch\", ylab=\"Accuracy\", col=\"blue\", type=\"l\", ylim=c(0.65, 0.76))\n# \n# # Plot the accuracy of the validation data\n# lines(track.model.2$metrics$val_acc, col=\"green\")\n# \n# # Add Legend\n# legend(\"top\", c(\"Training\", \"Testing\"), col=c(\"blue\", \"green\"), lty=c(1,1))\n\n## plot_ly\nepochs <- 200\ntime <- 1:epochs\nhist_df2 <- data.frame(time=time, loss=track.model.2$metrics$loss, acc=track.model.2$metrics$acc,\n                      valid_loss=track.model.2$metrics$val_loss, valid_acc=track.model.2$metrics$val_acc)\n\nplot_ly(hist_df2, x = ~time)  %>%\n  add_trace(y = ~loss, name = 'training loss', mode = 'lines') %>%\n  add_trace(y = ~acc, name = 'training accuracy', mode = 'lines+markers') %>%\n  add_trace(y = ~valid_loss, name = 'validation loss',mode = 'lines+markers') %>%\n  add_trace(y = ~valid_acc, name = 'validation accuracy', mode = 'lines+markers') %>% \n  layout(title=\"Titanic (model.2) Model Performance\",\n           legend = list(orientation = 'h'), yaxis=list(title=\"metric\"))",
      "line_count": 66
    },
    {
      "section": "Neural Network Modeling using `Keras`",
      "code": "# Initialize a sequential model\nmodel.3 <- keras_model_sequential() \n\n# Add layers and Node-Units to model\nmodel.3 %>% \n    layer_dense(units = 30, activation = 'relu', input_shape = c(4)) %>% \n    layer_dense(units = 15, activation = 'relu') %>% \n    layer_dense(units = 2, activation = 'softmax')\n\n# Compile the model\nmodel.3 %>% compile(\n     loss = 'binary_crossentropy',\n     optimizer = 'adam',\n     metrics = 'accuracy'\n )\n\n# Fit NN model to training data & Save the training history\ntrack.model.3 <- model.3 %>% fit(\n     train_dat2.X, \n     train_dat2.Y, \n     epochs = 200, \n     batch_size = 10, \n     validation_split = 0.2\n )\n\n# Evaluate the model\nmodel3.qual <- model.3 %>% evaluate(test_dat2.X, test_dat2.Y, batch_size = 30)\nprint(model3.qual)\n\n# EDA on the loss and accuracy metrics of this model.2\n# Plot the history\n# plot(track.model.3)\n# \n# # NN model loss on the training data\n# plot(track.model.3$metrics$loss, main=\"Model Loss\", \n#      xlab = \"Epoch\", ylab=\"Loss\", col=\"green\", type=\"l\", ylim=c(0.54, 0.7))\n# \n# # NN model loss of the 20% validation data\n# lines(track.model.3$metrics$val_loss, col=\"blue\", type=\"l\")\n# \n# # Add legend\n# legend(\"top\", c(\"Training\", \"testing\"), col=c(\"green\", \"blue\"), lty=c(1,1))\n# \n# # Plot the accuracy of the training data \n# plot(track.model.3$metrics$acc, main=\"Model 3 (Extra Layer/More Hidden Units)\", \n#      xlab = \"Epoch\", ylab=\"Accuracy\", col=\"blue\", type=\"l\", ylim=c(0.65, 0.76))\n# \n# # Plot the accuracy of the validation data\n# lines(track.model.3$metrics$val_acc, col=\"green\")\n# \n# # Add Legend\n# legend(\"top\", c(\"Training\", \"Testing\"), col=c(\"blue\", \"green\"), lty=c(1,1))\n\n## plot_ly\nepochs <- 200\ntime <- 1:epochs\nhist_df3 <- data.frame(time=time, loss=track.model.3$metrics$loss, acc=track.model.3$metrics$acc,\n                      valid_loss=track.model.3$metrics$val_loss, valid_acc=track.model.3$metrics$val_acc)\n\nplot_ly(hist_df3, x = ~time)  %>%\n  add_trace(y = ~loss, name = 'training loss', mode = 'lines') %>%\n  add_trace(y = ~acc, name = 'training accuracy', mode = 'lines+markers') %>%\n  add_trace(y = ~valid_loss, name = 'validation loss',mode = 'lines+markers') %>%\n  add_trace(y = ~valid_acc, name = 'validation accuracy', mode = 'lines+markers') %>% \n  layout(title=\"Titanic (model.3) NN Model Performance\",\n           legend = list(orientation = 'h'), yaxis=list(title=\"metric\"))",
      "line_count": 66
    },
    {
      "section": "Neural Network Modeling using `Keras`",
      "code": "model.4 <- keras_model_sequential() \n\n# Add layers and Node-Units to model\nmodel.4 %>% \n    layer_dense(units = 30, activation = 'relu', input_shape = c(4)) %>% \n    layer_dense(units = 15, activation = 'relu') %>% \n    layer_dense(units = 2, activation = 'softmax')\n\n# Define an optimizer\nSGD <- optimizer_sgd(learning_rate = 0.001)\n\n# Compile the model\nmodel.4 %>% compile(\n    optimizer=SGD, \n    loss = 'binary_crossentropy',\n    metrics = 'accuracy'\n )\n\n# Fit NN model to training data & Save the training history\nset.seed(1234)\ntrack.model.4 <- model.4 %>% fit(\n     train_dat2.X, \n     train_dat2.Y, \n     epochs = 200, \n     batch_size = 10, \n     validation_split = 0.1\n )\n\n# Evaluate the model\nmodel4.qual <- model.4 %>% evaluate(test_dat2.X, test_dat2.Y, batch_size = 30)\nprint(model4.qual)\n\n# EDA on the loss and accuracy metrics of this model.2\n# Plot the history\n# plot(track.model.4)\n# \n# # NN model loss on the training data\n# plot(track.model.4$metrics$loss, main=\"Model 4 Loss\", \n#      xlab = \"Epoch\", ylab=\"Loss\", col=\"green\", type=\"l\", ylim=c(0.54, 0.7))\n# \n# # NN model loss of the 20% validation data\n# lines(track.model.4$metrics$val_loss, col=\"blue\", type=\"l\")\n# \n# # Add legend\n# legend(\"top\", c(\"Training\", \"Testing\"), col=c(\"green\", \"blue\"), lty=c(1,1))\n# \n# # Plot the accuracy of the training data \n# plot(track.model.4$metrics$acc, main=\"Model 4 (Extra Layer/More Hidden Units/SGD)\", \n#      xlab = \"Epoch\", ylab=\"Accuracy\", col=\"blue\", type=\"l\", ylim=c(0.65, 0.76))\n# \n# # Plot the accuracy of the validation data\n# lines(track.model.4$metrics$val_acc, col=\"green\")\n# \n# # Add Legend\n# legend(\"top\", c(\"Training\", \"Testing\"), col=c(\"blue\", \"green\"), lty=c(1,1))\n\nepochs <- 200\ntime <- 1:epochs\nhist_df4 <- data.frame(time=time, loss=track.model.4$metrics$loss, acc=track.model.4$metrics$acc,\n                      valid_loss=track.model.4$metrics$val_loss, valid_acc=track.model.4$metrics$val_acc)\n\nplot_ly(hist_df4, x = ~time)  %>%\n  add_trace(y = ~loss, name = 'training loss', mode = 'lines') %>%\n  add_trace(y = ~acc, name = 'training accuracy', mode = 'lines+markers') %>%\n  add_trace(y = ~valid_loss, name = 'validation loss',mode = 'lines+markers') %>%\n  add_trace(y = ~valid_acc, name = 'validation accuracy', mode = 'lines+markers') %>% \n  layout(title=\"Titanic (model.4) NN Model Performance\",\n           legend = list(orientation = 'h'), yaxis=list(title=\"metric\"))",
      "line_count": 68
    },
    {
      "section": "Neural Network Modeling using `Keras`",
      "code": "save_model_hdf5(model.4, \"model.4.h5\")\nmodel.new <- load_model_hdf5(\"model.4.h5\")\n\nsave_model_weights_hdf5(\"model_weights.h5\")\nmodel.old %>% load_model_weights_hdf5(\"model_weights.h5\")\n\njson_string <- model_to_json(model.old)\nmodel.new <- model_from_json(json_string)\n\nyaml_string <- model_to_yaml(model.old)\nmodel.new <- model_from_yaml(yaml_string)",
      "line_count": 11
    },
    {
      "section": "Neural Network Modeling using `Keras`",
      "code": "library(keras)\nlibrary(tensorflow)\n\n# get info about local version of Python installation\n# reticulate::py_config()\n# The first time you run this install Pillow!\n# tensorflow::install_tensorflow(extra_packages='pillow')\n\n# load the image\nif (!file.exists(paste(getwd(),\"results\", sep=\"/\"))) {\n  dir.create(paste(getwd(),\"results\", sep=\"/\"), recursive = TRUE)\n} \n\ndownload.file(\"https://upload.wikimedia.org/wikipedia/commons/2/23/Lake_mapourika_NZ.jpeg\", paste(getwd(),\"results/image.png\", sep=\"/\"), mode = 'wb')\nimg <- image_load(paste(getwd(),\"results/image.png\", sep=\"/\"), target_size = c(224,224))\n\n# Preprocess input image\nx <- image_to_array(img)\n# ensure we have a 4d tensor with single element in the batch dimension,\n# the preprocess the input for prediction using resnet50\nx <- array_reshape(x, c(1, dim(x)))\nx <- imagenet_preprocess_input(x)\n\n# Specify and compare Predictions based on different Pre-trained Models\n# Model 1: resnet50\nmodel_resnet50 <- application_resnet50(weights = 'imagenet')\n\n# make predictions then decode and print them\npreds_resnet50 <- model_resnet50 %>% predict(x)\nimagenet_decode_predictions(preds_resnet50, top = 10)\n\n# Model2: VGG19\nmodel_vgg19 <- application_vgg19(weights = 'imagenet')\npreds_vgg19 <- model_vgg19 %>% predict(x)\nimagenet_decode_predictions(preds_vgg19, top = 10)[[1]]\n\n# Model 3: VGG16\nmodel_vgg16 <- application_vgg16(weights = 'imagenet')\npreds_vgg16 <- model_vgg16 %>% predict(x)\nimagenet_decode_predictions(preds_vgg16, top = 10)[[1]]",
      "line_count": 40
    },
    {
      "section": "Classification examples",
      "code": "library(mlbench)\n\ndata(Sonar, package=\"mlbench\")\n\ntable(Sonar[,61])\n\nSonar[,61] = as.numeric(Sonar[,61])-1 # R = \"1\", \"M\" = \"0\"\nset.seed(123)\ntrain.ind = sample(1:nrow(Sonar),0.7*nrow(Sonar))\n\ntrain.x = data.matrix(Sonar[train.ind, 1:60])\ntrain.y = Sonar[train.ind, 61]\ntest.x = data.matrix(Sonar[-train.ind, 1:60])\ntest.y = Sonar[-train.ind, 61]",
      "line_count": 14
    },
    {
      "section": "Classification examples",
      "code": "library(plotly)\ndim(train.x)  # [1] 145  60\ndim(test.x)   # [1] 63 60\n\nmodel <- keras_model_sequential() \n\nmodel %>% \n  layer_dense(units = 256, activation = 'relu', input_shape = ncol(train.x)) %>% \n  layer_dropout(rate = 0.4) %>% \n  layer_dense(units = 128, activation = 'relu') %>%\n  layer_dropout(rate = 0.3) %>%\n  layer_dense(units = 2, activation = 'sigmoid')\n\nmodel %>% compile(\n  loss = 'binary_crossentropy',\n  optimizer = 'adam',\n  metrics = c('accuracy')\n)\n\none_hot_labels <- to_categorical(train.y, num_classes = 2)\n\n# Train the model, iterating on the data in batches of 25 samples\nhistory <- model %>% fit(\n  train.x, one_hot_labels, \n  epochs = 100, \n  batch_size = 5,\n  validation_split = 0.3\n)\n \n# Evaluate model\nmetrics <- model %>% evaluate(test.x, to_categorical(test.y, num_classes = 2))\nmetrics\n\nepochs <- 100\ntime <- 1:epochs\nhist_df <- data.frame(time=time, loss=history$metrics$loss, acc=history$metrics$accuracy,\n                      valid_loss=history$metrics$val_loss, valid_acc=history$metrics$val_accuracy)\n\nplot_ly(hist_df, x = ~time)  %>%\n  add_trace(y = ~loss, name = 'training loss', type=\"scatter\", mode = 'lines') %>%\n  add_trace(y = ~acc, name = 'training accuracy', type=\"scatter\", mode = 'lines+markers') %>%\n  add_trace(y = ~valid_loss, name = 'validation loss', type=\"scatter\",mode = 'lines+markers') %>%\n  add_trace(y = ~valid_acc, name = 'validation accuracy', type=\"scatter\", mode = 'lines+markers') %>% \n  layout(title=\"Sonar Data NN Model Performance\",\n           legend = list(orientation = 'h'), yaxis=list(title=\"metric\"))\n\n# Finally prediction of binary class labels and Confusion Matrix\npredictions <- model %>% predict(test.x) %>%  k_argmax()\ntable(factor(predictions$numpy()),factor(test.y))\n\n# We can also inspect the corresponding probabilities of the automated binary classification labels\nprediction_probabilities <- model %>% predict(test.x)\nprediction_probabilities",
      "line_count": 53
    },
    {
      "section": "Classification examples",
      "code": "library(\"crossval\")\ndiagnosticErrors(crossval::confusionMatrix(predictions$numpy(),test.y, negative = 0))",
      "line_count": 2
    },
    {
      "section": "Classification examples",
      "code": "# install.packages(\"pROC\"); install.packages(\"plotROC\"); install.packages(\"reshape2\")\nlibrary(pROC); library(plotROC); library(reshape2); \n# compute AUC\nget_roc = function(preds){\n  roc_obj <- roc(test.y, preds, quiet=TRUE)\n  auc(roc_obj)\n}\nget_roc(predictions$numpy())\npredictions <- predictions$numpy() \n\n#plot roc\ndt <- data.frame(test.y, predictions)\ncolnames(dt) <- c(\"class\",\"scored.probability\")\n\n# basicplot <- ggplot(dt, aes(d = class, m = scored.probability)) + \n#   geom_roc(labels = FALSE, size = 0.5, alpha.line = 0.6, linejoin = \"mitre\") +  \n#   theme_bw() + coord_fixed(ratio = 1) + style_roc() + ggtitle(\"ROC CURVE\")+\n#   ggplot2::annotate(\"rect\", xmin = 0.4, xmax = 0.9, ymin = 0.1, ymax = 0.5,\n#            alpha = 0.2)+\n#   ggplot2::annotate(\"text\", x = 0.65, y = 0.32, size = 3,\n#            label = paste0(\"AUC: \", round(get_roc(predictions)[[1]], 3)))\n# basicplot\n\n# Compute the AUC and draw the ROC curve\nroc_curve <- function(df) {\n  x <- c()\n  y <- c()\n  true_class = df[, \"class\"]\n  probabilities = df[, \"scored.probability\"]\n  thresholds = seq(0, 1, 0.01)\n  rx <- 0\n  ry <- 0\n  for (threshold in thresholds) {\n    predicted_class <- c()\n    for (val in probabilities) {\n      if (val > threshold) {\n        predicted_class <- c(predicted_class, 1)\n      }\n      else { predicted_class <- c(predicted_class, 0)   }\n    }\n    df2 <- as.data.frame(cbind(true_class, predicted_class))\n    TP <- nrow(filter(df2, true_class == 1 & predicted_class == 1))\n    TN <- nrow(filter(df2, true_class == 0 & predicted_class == 0))\n    FP <- nrow(filter(df2, true_class == 0 & predicted_class == 1))\n    FN <- nrow(filter(df2, true_class == 1 & predicted_class == 0))\n    specm1 <- 1 - ((TN) / (TN + FP))\n    sens <- (TP) / (TP + FN)\n    x <- append(x, specm1)\n    y <- append(y, sens)\n  }\n  dfr <- as.data.frame(cbind(x, y))\n  plot_ly(dfr, x = ~ x, y = ~ y, type = 'scatter', mode = 'lines') %>%\n    layout(title = paste0(\"ROC Curve and AUC\"), annotations = list(\n        text = paste0(\"Area Under Curve = \", round(get_roc(predictions)[[1]], 3)),\n        x = 0.75, y = 0.25, showarrow = FALSE),\n      xaxis = list(showgrid = FALSE, title = \"1-Specificity (false positive rate)\"),\n      yaxis = list(showgrid = FALSE, title = \"Sensitivity (true positive rate)\"),\n      legend = list(orientation = 'h')\n    ) \n}\nroc_curve(data.frame(class=test.y, scored.probability=prediction_probabilities[,2]))",
      "line_count": 61
    },
    {
      "section": "Case-Studies",
      "code": "library(\"XML\"); library(\"xml2\")\nlibrary(\"rvest\");\n\n# Schizophrenia Data\n# UCLA Data is available here: \n# wiki_url <- read_html(\"http://wiki.stat.ucla.edu/socr/index.php/SOCR_Data_Oct2009_ID_NI\")\n# html_nodes(wiki_url, \"#content\")\n# SchizoData<- html_table(html_nodes(wiki_url, \"table\")[[2]])\n# UMich Data is available here\nwiki_url <- read_html(\"https://wiki.socr.umich.edu/index.php/SOCR_Data_Oct2009_ID_NI\")\nhtml_nodes(wiki_url, \"#content\")\nSchizoData<- html_table(html_nodes(wiki_url, \"table\")[[1]])\n\n# View (SchizoData): Select an outcome response \"DX\"(3), \"FS_IQ\" (5)\nset.seed(1234)\ntest.ind = sample(1:63, 10, replace = F)  # select 10/63 of cases for testing, train on remaining (63-10)/63 cases\ntrain.x = scale(data.matrix(SchizoData[-test.ind, c(2, 4:9)])) #, 11:66)]) # exclude outcome\ntrain.y = ifelse(SchizoData[-test.ind, 3] < 2, 0, 1) # Binarize the outcome, Controls=0\ntest.x = scale(data.matrix(SchizoData[test.ind, c(2, 4:9)])) #, 11:66)])\ntest.y = ifelse(SchizoData[test.ind, 3] < 2, 0, 1)\n\n# View(data.frame(test.x, test.y))\n# View(data.frame(train.x, train.y))\n\nmodel <- keras_model_sequential() \n\nmodel %>% \n  layer_dense(units = 256, activation = 'relu', input_shape = ncol(train.x)) %>% \n  layer_dropout(rate = 0.4) %>% \n  layer_dense(units = 128, activation = 'relu') %>%\n  layer_dropout(rate = 0.3) %>%\n  layer_dense(units = 64, activation = 'relu') %>%\n  layer_dropout(rate = 0.1) %>%\n  layer_dense(units = 32, activation = 'relu') %>%\n  layer_dropout(rate = 0.1) %>%\n  layer_dense(units = 2, activation = 'sigmoid')\n\nmodel %>% compile(\n  loss = 'binary_crossentropy',\n  optimizer = 'adam',\n  metrics = c('accuracy')\n)\n\none_hot_labels <- to_categorical(train.y[,1])\n\n# Train the model, iterating on the data in batches of 25 samples\nhistory <- model %>% fit(\n  train.x, one_hot_labels, \n  epochs = 100, \n  batch_size = 5,\n  validation_split = 0.1\n)\n \n# Evaluate model\nmetrics <- model %>% evaluate(test.x, to_categorical(test.y[ , 1]))\nmetrics\n\nplot(history)\n\nepochs <- 100\ntime <- 1:epochs\nhist_df <- data.frame(time=time, loss=history$metrics$loss, acc=history$metrics$accuracy,\n                      valid_loss=history$metrics$val_loss, valid_acc=history$metrics$val_accuracy)\n\nplot_ly(hist_df, x = ~time)  %>%\n  add_trace(y = ~loss, name = 'training loss', type=\"scatter\", mode = 'lines') %>%\n  add_trace(y = ~acc, name = 'training accuracy', type=\"scatter\", mode = 'lines+markers') %>%\n  add_trace(y = ~valid_loss, name = 'validation loss', type=\"scatter\",mode = 'lines+markers') %>%\n  add_trace(y = ~valid_acc, name = 'validation accuracy', type=\"scatter\", mode = 'lines+markers') %>% \n  layout(title=\"Schizophrenia Study NN Model Performance\",\n           legend = list(orientation = 'h'), yaxis=list(title=\"metric\"))\n\n# Finally prediction of binary class labels and Confusion Matrix\npredictions <- model %>% predict(test.x) %>%  k_argmax()\n\n# We can also inspect the corresponding probabilities of the automated binary classification labels\n# prediction_probabilities <- model %>% predict(test.x) %>% `>`(0.5) %>% k_cast(\"int32\")\n# prediction_probabilities$numpy()\nprediction_probabilities <- model %>% predict(test.x)\nprediction_probabilities\n\ntable(factor(predictions$numpy()),factor(test.y))",
      "line_count": 82
    },
    {
      "section": "Case-Studies",
      "code": "# devtools::install_github(\"andrie/deepviz\")\nlibrary(deepviz)\nmodel %>% plot_model()",
      "line_count": 3
    },
    {
      "section": "Case-Studies",
      "code": "library(tfdatasets)\n\nals <- read.csv(\"https://umich.instructure.com/files/1789624/download?download_frd=1\")\nALSFRS_slope <- als[,7]\nals <- as.data.frame(als[,-c(1,7,94)])\ncolnames(als)\n\nspec <- feature_spec(als, ALSFRS_slope ~ . ) %>% \n  step_numeric_column(all_numeric(), normalizer_fn = scaler_standard()) %>% \n  fit()\nspec",
      "line_count": 11
    },
    {
      "section": "Case-Studies",
      "code": "layer <- layer_dense_features(feature_columns = dense_features(spec), dtype = tf$float32)\n# layer(als)",
      "line_count": 2
    },
    {
      "section": "Case-Studies",
      "code": "input <- layer_input_from_dataset(als)\n\noutput <- input %>% \n  layer_dense_features(dense_features(spec)) %>% \n  layer_dense(units = 256, activation = \"relu\") %>%\n  layer_dense(units = 128, activation = \"relu\") %>%\n  layer_dense(units = 64, activation = \"relu\") %>%\n  layer_dense(units = 16, activation = \"relu\") %>%\n  layer_dense(units = 1) \n\nmodel <- keras_model(input, output)\n\n# summary(model)",
      "line_count": 13
    },
    {
      "section": "Case-Studies",
      "code": "model %>% compile(loss = \"mse\", optimizer = optimizer_rmsprop(), metrics = list(\"mean_absolute_error\"))\n\nbuild_model <- function() {\n  input <- layer_input_from_dataset(als)\n  output <- input %>% \n  layer_dense_features(dense_features(spec)) %>% \n  layer_dense(units = 256, activation = \"relu\") %>%\n  layer_dense(units = 128, activation = \"relu\") %>%\n  layer_dense(units = 64, activation = \"relu\") %>%\n  layer_dense(units = 16, activation = \"relu\") %>%\n  layer_dense(units = 1) \n\n  model <- keras_model(input, output)\n  \n  model %>% compile(loss = \"mse\", optimizer = optimizer_rmsprop(), metrics = list(\"mean_absolute_error\"))\n  \n  model\n}",
      "line_count": 18
    },
    {
      "section": "Case-Studies",
      "code": "# Display training progress by printing a single dot for each completed epoch.\nprint_dot_callback <- callback_lambda(\n  on_epoch_end = function(epoch, logs) {\n    if (epoch %% 80 == 0) cat(\"\\n\")\n    cat(\".\")\n  }\n)    \n\nmodel <- build_model()\n\nhistory <- model %>% fit(\n  x = als,\n  y = ALSFRS_slope,\n  epochs = 200,\n  validation_split = 0.2,\n  verbose = 0,\n  callbacks = list(print_dot_callback)\n)",
      "line_count": 18
    },
    {
      "section": "Case-Studies",
      "code": "#plot(history)\n\nepochs <- 200\ntime <- 1:epochs\nhist_df <- data.frame(time=time, loss=history$metrics$loss, mae=history$metrics$mean_absolute_error,\n                      valid_loss=history$metrics$val_loss, valid_mae=history$metrics$val_mean_absolute_error)\n\nplot_ly(hist_df, x = ~time)  %>%\n  add_trace(y = ~loss, name = 'training loss', type=\"scatter\", mode = 'lines') %>%\n  add_trace(y = ~mae, name = 'training MAE', type=\"scatter\", mode = 'lines+markers') %>%\n  add_trace(y = ~valid_loss, name = 'validation loss', type=\"scatter\", mode = 'lines+markers') %>%\n  add_trace(y = ~valid_mae, name = 'validation MAE', type=\"scatter\", mode = 'lines+markers') %>% \n  layout(title=\"ALS Study NN Model Performance\",\n           legend = list(orientation = 'h'), yaxis=list(title=\"metric\"))\n\n# # Note that this graph shows little improvement in the model after about 100 epochs. \n# # hence, we can update the fit method to automatically *stop training* when the validation score \n# # doesn’t improve. The callback that tests a training condition for every epoch. \n# # If a set amount of epochs elapses without showing improvement, it automatically stops the training.\n# \n# # The patience parameter is the amount of epochs to check for improvement.\n# early_stop <- callback_early_stopping(monitor = \"val_loss\", patience = 20)\n# \n# model <- build_model()\n# \n# history <- model %>% fit(\n#   x = train_df %>% select(-label),\n#   y = train_df$label,\n#   epochs = 500,\n#   validation_split = 0.2,\n#   verbose = 0,\n#   callbacks = list(early_stop)\n# )\n\n# library(deepviz)\n# model %>% plot_model()",
      "line_count": 36
    },
    {
      "section": "Case-Studies",
      "code": "cases <- 100\ntest_sample <- sample(1:dim(als)[1], size=cases)\ntest_predictions <- model %>% predict(als[test_sample, ])\n# test_predictions[ , 1]\n\nprint(paste0(\"Corr(real_ALSFRS_Slope, predicted_ALSFRS_Slope)=\", \n             round(cor(test_predictions, ALSFRS_slope[test_sample]), 3)))\n\ncases <- 1:cases\nhist_df <- data.frame(cases=cases, real=ALSFRS_slope[test_sample], predicted=test_predictions)\ncorr1 <- round(cor(hist_df$real, hist_df$predicted), 2)\n\nplot_ly(hist_df, x = ~real)  %>%\n  add_trace(y = ~predicted, name = 'Scatter (Real vs. Predicted ALSFRS_Slope)', type=\"scatter\", mode = 'markers') %>%\n  add_lines(x = ~real, y = ~fitted(lm(predicted ~ real, hist_df)), name=\"LM(Pred ~ Real)\") %>% \n  layout(title=paste0(\"ALS Study NN Model Prediction (ALSFRS-slope correlation=\", corr1,\")\"),\n           legend = list(orientation = 'h'), yaxis=list(title=\"predicted\"))",
      "line_count": 17
    },
    {
      "section": "Case-Studies",
      "code": "# IBS NI Data\nlibrary(xml2)\nlibrary(rvest)\n\n# UCLA Data\n# wiki_url <- read_html(\"http://wiki.stat.ucla.edu/socr/index.php/SOCR_Data_April2011_NI_IBS_Pain\")\n# UMich Data\nwiki_url <- read_html(\"https://wiki.socr.umich.edu/index.php/SOCR_Data_April2011_NI_IBS_Pain\")\n\nIBSData <- html_table(html_nodes(wiki_url, \"table\")[[2]]) # table 2\nset.seed(1234)\ntest.ind = sample(1:354, 50, replace = F)  # select 50/354 of cases for testing, train on remaining (354-50)/354 cases\n\n# UMich Data (includes MISSING data): use `mice` to impute missing data with mean: newData <- mice(data,m=5,maxit=50,meth='pmm',seed=500); summary(newData)\n# wiki_url <- read_html(\"https://wiki.socr.umich.edu/index.php/SOCR_Data_April2011_NI_IBS_Pain\")\n# IBSData<- html_table(html_nodes(wiki_url, \"table\")[[1]]) # load Table 1\n# set.seed(1234)\n# test.ind = sample(1:337, 50, replace = F)  # select 50/337 of cases for testing, train on remaining (337-50)/337 cases\n# summary(IBSData); IBSData[IBSData==\".\"] <- NA; newData <- mice(IBSData,m=5,maxit=50,meth='pmm',seed=500); summary(newData)\n\nhtml_nodes(wiki_url, \"#content\")\n\n# View (IBSData); dim(IBSData): Select an outcome response \"DX\"(3), \"FS_IQ\" (5)\n\n# scale/normalize all input variables\nIBSData <- na.omit(IBSData) \nIBSData[,4:66] <- scale(IBSData[,4:66])  # scale the entire dataset\ntrain.x = data.matrix(IBSData[-test.ind, c(4:66)]) # exclude outcome\ntrain.y = IBSData[-test.ind, 3]-1\ntest.x = data.matrix(IBSData[test.ind, c(4:66)])\ntest.y = IBSData[test.ind, 3]-1\n\ntrain.y <- train.y$Group\ntest.y <- test.y$Group\n\n# View(data.frame(test.x, test.y))\n# View(data.frame(train.x, train.y))\n\nmodel <- keras_model_sequential() \n\nmodel %>% \n  layer_dense(units = 256, activation = 'relu', input_shape = ncol(train.x)) %>% \n  layer_dropout(rate = 0.4) %>% \n  layer_dense(units = 128, activation = 'relu') %>%\n  layer_dropout(rate = 0.3) %>%\n  layer_dense(units = 64, activation = 'relu') %>%\n  layer_dropout(rate = 0.1) %>%\n  layer_dense(units = 32, activation = 'relu') %>%\n  layer_dropout(rate = 0.1) %>%\n  layer_dense(units = 16, activation = 'relu') %>%\n  layer_dropout(rate = 0.1) %>%\n  layer_dense(units = 2, activation = 'sigmoid')\n\nmodel %>% compile(\n  loss = 'binary_crossentropy',\n  optimizer = 'adam',\n  metrics = c('accuracy')\n)\n\none_hot_labels <- to_categorical(train.y, num_classes = 2)\n\n# Train the model, iterating on the data in batches of 25 samples\nhistory <- model %>% fit(\n  train.x, one_hot_labels, \n  epochs = 100, \n  batch_size = 5,\n  validation_split = 0.1\n)\n \n# Evaluate model\nmetrics <- model %>% evaluate(test.x, to_categorical(test.y, num_classes = 2))\nmetrics\n\nplot(history)\n\nepochs <- 100\ntime <- 1:epochs\nhist_df <- data.frame(time=time, loss=history$metrics$loss, acc=history$metrics$accuracy,\n                      valid_loss=history$metrics$val_loss, valid_acc=history$metrics$val_accuracy)\n\nplot_ly(hist_df, x = ~time)  %>%\n  add_trace(y = ~loss, name = 'training loss', type=\"scatter\", mode = 'lines') %>%\n  add_trace(y = ~acc, name = 'training accuracy', type=\"scatter\", mode = 'lines+markers') %>%\n  add_trace(y = ~valid_loss, name = 'validation loss', type=\"scatter\",mode = 'lines+markers') %>%\n  add_trace(y = ~valid_acc, name = 'validation accuracy', type=\"scatter\", mode = 'lines+markers') %>% \n  layout(title=\"IBS Study NN Model Performance\",\n           legend = list(orientation = 'h'), yaxis=list(title=\"metric\"))\n\n# Finally prediction of binary class labels and Confusion Matrix\npredictions <- model %>% predict(test.x) %>%  k_argmax()\ntable(factor(predictions$numpy()),factor(test.y))\n\n# We can also inspect the corresponding probabilities of the automated binary classification labels\n# prediction_probabilities <- model %>% predict(test.x)",
      "line_count": 94
    },
    {
      "section": "Case-Studies",
      "code": "\n# install.packages(\"xml2\")\n# install.packages(\"rvest\")\n\n# Load the rvest package\nlibrary(rvest)\n# Load the xml2 package\nlibrary(xml2)\n\nlibrary(plotly)\n\nwiki_url <- read_html(\"http://wiki.stat.ucla.edu/socr/index.php/SOCR_Data_2008_World_CountriesRankings\")\nhtml_nodes(wiki_url, \"#content\")\nCountryRankingData<- html_table(html_nodes(wiki_url, \"table\")[[2]])\n\n# View (CountryRankingData); dim(CountryRankingData): Select an appropriate\n# outcome \"OA\": Overall country ranking (13)\n# Dichotomize outcome, Top-countries OA<20, bottom countries OA>=20\nset.seed(1234)\ntest.ind = sample(1:100, 30, replace = F)  # select 15/100 of cases for testing, train on remaining 85/100 cases\n\nCountryRankingData[,c(8:12,14)] <- scale(CountryRankingData[,c(8:12,14)])\n# scale/normalize all input variables\ntrain.x = data.matrix(CountryRankingData[-test.ind, c(8:12,14)]) # exclude outcome\ntrain.y = ifelse(CountryRankingData[-test.ind, 13] < 50, 1, 0)\ntest.x = data.matrix(CountryRankingData[test.ind, c(8:12,14)])\ntest.y = ifelse(CountryRankingData[test.ind, 13] < 50, 1, 0) # developed (high OA rank) country\n\nmodel <- keras_model_sequential() \n\nmodel %>% \n  layer_dense(units = 16, activation = 'relu', input_shape = ncol(train.x)) %>% \n  layer_dropout(rate = 0.4) %>% \n  layer_dense(units = 4, activation = 'relu') %>%\n  layer_dropout(rate = 0.1) %>%\n  layer_dense(units = 2, activation = 'sigmoid')\n\nmodel %>% compile(\n  loss = 'binary_crossentropy',\n  optimizer = 'adam',\n  metrics = c('accuracy')\n)\n\none_hot_labels <- to_categorical(train.y, num_classes = 2)\n\n# Train the model, iterating on the data in batches of 25 samples\nhistory <- model %>% fit(\n  train.x, one_hot_labels, \n  epochs = 50, \n  batch_size = 5,\n  validation_split = 0.1\n)\n \n# Evaluate model\nmetrics <- model %>% evaluate(test.x, to_categorical(test.y, num_classes = 2))\nmetrics\n\n# plot(history)\n\nepochs <- 50\ntime <- 1:epochs\nhist_df <- data.frame(time=time, loss=history$metrics$loss, acc=history$metrics$accuracy,\n                      valid_loss=history$metrics$val_loss, valid_acc=history$metrics$val_accuracy)\n\nplot_ly(hist_df, x = ~time)  %>%\n  add_trace(y = ~loss, name = 'training loss', type=\"scatter\", mode = 'lines') %>%\n  add_trace(y = ~acc, name = 'training accuracy', type=\"scatter\", mode = 'lines+markers') %>%\n  add_trace(y = ~valid_loss, name = 'validation loss', type=\"scatter\", mode = 'lines+markers') %>%\n  add_trace(y = ~valid_acc, name = 'validation accuracy', type=\"scatter\", mode = 'lines+markers') %>% \n  layout(title=\"Country QoL Ranking NN Model Performance\",\n           legend = list(orientation = 'h'), yaxis=list(title=\"metric\"))\n\n# Finally prediction of binary class labels and Confusion Matrix\npredictions <- model %>% predict(test.x) %>%  k_argmax()\ntable(factor(predictions$numpy()),factor(test.y))\n\n# We can also inspect the corresponding probabilities of the automated binary classification labels\n# prediction_probabilities <- model %>% predict(test.x)",
      "line_count": 78
    },
    {
      "section": "Case-Studies",
      "code": "K <- 60\nX <- K %% 28 # X= K mod 28, remainder of integer division 60/28\nY <- K%/%28  # integer part of the division\n# This validates that the application of both, the back and forth transformations, leads to an identity\nK; X; Y; Y * 28 + X",
      "line_count": 5
    },
    {
      "section": "Case-Studies",
      "code": "# train.csv\npathToZip <- tempfile()\ndownload.file(\"https://www.socr.umich.edu/people/dinov/2017/Spring/DSPA_HS650/data/DigitRecognizer_TrainingData.zip\", pathToZip)\ntrain <- read.csv(unzip(pathToZip))\ndim(train)\nunlink(pathToZip)\n\n# test.csv\npathToZip <- tempfile()\ndownload.file(\"https://www.socr.umich.edu/people/dinov/2017/Spring/DSPA_HS650/data/DigitRecognizer_TestingData.zip\", pathToZip)\ntest <- read.csv(unzip(pathToZip))\ndim(test)\nunlink(pathToZip)\n\ntrain <- data.matrix(train)\ntest <- data.matrix(test)\n\ntrain.x <- train[,-1]\ntrain.y <- train[,1]\n\n# Scaling will be discussed below\ntrain.x <- t(train.x/255)\ntest <- t(test/255)\n\n# Note that you can also load the MNIST dataset (training & testing directly from keras)\n# mnist <- dataset_mnist()\n# train.x <- mnist$train$x\n# train.y <- mnist$train$y\n# test <- mnist$test$x\n# test.y <- mnist$test$y",
      "line_count": 30
    },
    {
      "section": "Case-Studies",
      "code": "library(\"imager\")\n# first convert the CSV data (one row per image, 28,000 rows)\narray_3D <- array(test, c(28, 28, 28000))\nmat_2D <- matrix(array_3D[,,1], nrow = 28, ncol = 28)\nplot(as.cimg(mat_2D))\n\n# extract all N=28,000 images\nN <- 28000\nimg_3D <- as.cimg(array_3D[,,], 28, 28, N)\n\n# plot the k-th image (1<=k<=N)\nk <- 5\nplot(img_3D, k)\n\nimage_2D <- function(img,index)\n{\n    img[,,index,,drop=FALSE]\n}\n\nplot(image_2D(img_3D, 1))\n\n# Plot a collage of the first 4 images\nimappend(list(image_2D(img_3D, 1), image_2D(img_3D, 2), image_2D(img_3D, 3), image_2D(img_3D, 4)),\"y\") %>% plot\n\n# img <- image_2D(img_3D, 1)\n# for (i in 10:20)  { imappend(list(img, image_2D(img_3D, i)),\"x\") }",
      "line_count": 26
    },
    {
      "section": "Case-Studies",
      "code": "# We already scaled earlier\n# train.x <- t(train.x/255)\n# test <- t(test/255)",
      "line_count": 3
    },
    {
      "section": "Case-Studies",
      "code": "table(train.y); prop.table(table(train.y))",
      "line_count": 1
    },
    {
      "section": "Case-Studies",
      "code": "network <- keras_model_sequential() %>%\n  layer_dense(units = 512, activation = \"relu\", input_shape = c(28 * 28)) %>%\n  layer_dense(units = 10, activation = \"softmax\")\n\nnetwork %>% compile(optimizer = \"rmsprop\", loss = \"categorical_crossentropy\", metrics = c(\"accuracy\"))",
      "line_count": 5
    },
    {
      "section": "Case-Studies",
      "code": "train_images <- t(train.x)  # (42000, 28 * 28))\ntest_images <- t(test)    # (28000, 28 * 28))\n# Note: we can also use the `array_reshape()` tensor-reshaping function to reshape the array.\n\n# categorically encode the training-image labels\ntrain_labels <- to_categorical(train.y)",
      "line_count": 6
    },
    {
      "section": "Case-Studies",
      "code": "network %>% fit(train_images, train_labels, epochs = 10, batch_size = 128)",
      "line_count": 1
    },
    {
      "section": "Case-Studies",
      "code": "# Load and preprocess the testing data\nmnist <- dataset_mnist()\ntest_images <- mnist$test$x\ntest_labels <- mnist$test$y\ndim(test_images)    # [1] 10000    28    28\nlength(test_labels) # [1] 10000\ntest_images <- array_reshape(test_images, c(10000, 28 * 28))\ntest_images <- test_images / 255\ntest_labels <- to_categorical(test_labels)\n\nmetrics <- network %>% evaluate(test_images, test_labels)\nmetrics\n# metrics \n#       loss   accuracy \n# 0.04423446 0.98860002 ",
      "line_count": 15
    },
    {
      "section": "Case-Studies",
      "code": "pred.label <- network %>% predict(test_images) %>%  k_argmax()\nheat <- table(factor(pred.label$numpy()),factor(mnist$test$y))\nkeys = c(0:9)\nplot_ly(x =~keys, y = ~keys, z = ~matrix(heat, 10,10), name=\"NN Model Performance\",\n        hovertemplate = paste('<i>Matching</i>: %{z:.0f}', \n                              '<br><b>True</b>: %{x}<br>', '<b>Pred</b>: %{y}'),\n        colors = 'Reds', type = \"heatmap\") %>% \n  layout(title=\"MNIST Predicated Number Classes vs. True Labels\", \n         xaxis=list(title=\"Actual Class\"), yaxis=list(title=\"Predicted Class\"))",
      "line_count": 9
    },
    {
      "section": "Case-Studies",
      "code": "# For example, the ML-classification labels assigned to the first 7 images (from the 28,000 testing data collection) are:\npred.label <- pred.label$numpy()\n\nhead(pred.label, n = 7L)\nlibrary(knitr)\nkable(head(pred.label, n = 7L), format = \"markdown\", align='c')\n\nlabel.names <- c(\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\")\n\n#initialize a list of m=7 images from the N=28,000 available images\nm_start <- 4\nm_end <- 10\nif (m_end <= m_start) \n  { m_end = m_start+1 }  # check that m_end > m_start\n\nlabel_Ypositons <- vector()  # initialize the array of label positions on the plot\nfor (i in m_start:m_end) {\n  if (i==m_start) { \n    img1 <- as.cimg(test_images[m_start,], 28, 28)\n    # img1 <- image_2D(img_3D, m_start) \n  }\n  else img1 <- imappend(list(img1, as.cimg(test_images[i,], 28, 28)),\"y\")\n  # else img1 <- imappend(list(img1, image_2D(img_3D, i)),\"y\")\n  label.names[i+1-m_start] <- pred.label[i]\n  label_Ypositons[i+1-m_start] <- 15 + 28*(i-m_start)\n}\n\nplot(img1, axes=FALSE)\ntext(40, label_Ypositons, labels=label.names[1:(m_end-m_start)], cex= 1.2, col=\"blue\")\nmtext(paste((m_end+1-m_start), \" Random Images \\n Indices (m_start=\", m_start, \" : m_end=\", m_end, \")\"), side=2, line=-6, col=\"black\")\nmtext(\"NN Classification Labels\", side=4, line=-5, col=\"blue\") ",
      "line_count": 31
    },
    {
      "section": "Case-Studies",
      "code": "#  Linear stacks of network layers\nnetwork <- keras_model_sequential() %>%\n  layer_dense(units = 512, activation = \"relu\", input_shape = c(28 * 28)) %>%\n  layer_dense(units = 10, activation = \"softmax\")\n\n# vs. functional API network (DAG)\ninput_tensor  <- layer_input(shape = c(784))\noutput_tensor <- input_tensor %>%\n  layer_dense(units = 32, activation = \"relu\") %>%\n  layer_dense(units = 10, activation = \"softmax\")\nmodel <- keras_model(inputs = input_tensor, outputs = output_tensor)\n\nmodel %>% compile(\n    optimizer = optimizer_adam(),\n    loss = \"mse\",\n    metrics = c(\"accuracy\")\n)\n\nmodel %>% fit(train_images, train_labels, epochs = 10, batch_size = 128)",
      "line_count": 19
    },
    {
      "section": "Case-Studies",
      "code": "val_indices <- sample(1:dim(train_images)[1], size=10000)  # randomly choose 10K images\nx_val <- train_images[val_indices, ]\ny_val <- to_categorical(train.y[val_indices])\n\npartial_x_train <- train_images[-val_indices, ]\npartial_y_train <- to_categorical(train.y[-val_indices])\n\n# train the model for 20 iterations over all samples in the x_train and y_train tensors (20 epochs), \n# using mini-batches of 512 samples and track the loss and accuracy on the 10,000 validation samples \n\nmodel %>% compile(optimizer = \"rmsprop\", loss = \"binary_crossentropy\", metrics = c(\"accuracy\"))\nhistory <- model %>% fit(partial_x_train, partial_y_train, epochs = 20, batch_size = 512, \n                         validation_data = list(x_val, y_val) )\ntic <- proc.time()\nprint(paste0(\"Total Compute Time: \", proc.time() - tic))\n\nlibrary(plotly)\nepochs <- 20\ntime <- 1:epochs\nhist_df <- data.frame(time=time, loss=history$metrics$loss, acc=history$metrics$accuracy, \n                      valid_loss=history$metrics$val_loss, valid_acc=history$metrics$val_accuracy)\n\nplot_ly(hist_df, x = ~time)  %>% \n  add_trace(y = ~loss, name = 'training loss', mode = 'lines') %>% \n  add_trace(y = ~acc, name = 'training accuracy', mode = 'lines+markers') %>% \n  add_trace(y = ~valid_loss, name = 'validation loss',mode = 'lines+markers') %>% \n  add_trace(y = ~valid_acc, name = 'validation accuracy', mode = 'lines+markers') %>% \n  layout(title=\"MNIST Digits NN Model Performance\",\n           legend = list(orientation = 'h'), yaxis=list(title=\"metric\"))\n\n# Finally prediction of MNIST testing image classification (auto-labeling):\npred.label <- model %>% predict(t(test))\nfor (i in 1:9) {\n  print(sprintf(\"NN predicted Label for image %d is %s\", i, which.max(pred.label[i,])-1))\n}\n\narray_3D <- array(t(test), c(28000, 28, 28))\nplot(as.cimg(array_3D[1,,], nrow = 28, ncol = 28))\n\n#initialize a list of m=9 testing images from the N=28,000 available images\nm_start <- 1\nm_end <- 9\nlabel_Ypositons <- vector()  # initialize the array of label positions on the plot\nfor (i in m_start:m_end) {\n  if (i==m_start) { \n    img1 <- as.cimg(array_3D[1,,], nrow = 28, ncol = 28)\n  }\n  else img1 <- imappend(list(img1, as.cimg(array_3D[i,,], nrow = 28, ncol = 28)), \"y\")\n  label.names[i] <- which.max(pred.label[i,])-1\n  label_Ypositons[i+1-m_start] <- 15 + 28*(i-m_start)\n}\n\nplot(img1, axes=FALSE)\ntext(40, label_Ypositons, labels=label.names[1:(m_end-m_start+1)], cex= 1.2, col=\"blue\")\nmtext(paste((m_end+1-m_start), \" Random Images \\n Indices (m_start=\", m_start, \" : m_end=\", m_end, \")\"), side=2, line=-6, col=\"black\")\nmtext(\"NN Classification Labels\", side=4, line=-5, col=\"blue\") ",
      "line_count": 56
    },
    {
      "section": "Classifying Real-World Images using *Tensorflow* and *Keras*",
      "code": "# install.packages(\"imager\")\n# library(imager)",
      "line_count": 2
    },
    {
      "section": "Classifying Real-World Images using *Tensorflow* and *Keras*",
      "code": "# if (!require(\"BiocManager\", quietly = TRUE))\n#     install.packages(\"BiocManager\")\n# BiocManager::install(\"EBImage\")\n\n# library(\"imager\")\n# library(\"EBImage\")\nlibrary(\"keras\")\n\n# Check system python config\n# reticulate::py_config()\n\n# One should be able to load the image directly from the web (but sometimes there may be problems, in which case, we need to first download the image and then load it in R:\n# im <- imager::load.image(\"https://wiki.socr.umich.edu/images/6/69/DataManagementFig1.png\")\n\n# download file to local working directory, use \"wb\" mode to avoid problems\ndownload.file(\"https://wiki.socr.umich.edu/images/6/69/DataManagementFig1.png\", paste(getwd(),\"results/image.png\", sep=\"/\"), mode = 'wb')\n\n# report download image path\npaste(getwd(),\"results/image.png\", sep=\"/\")\n\nimg <- image_load(paste(getwd(),\"results/image.png\", sep=\"/\"), target_size = c(224,224)) \n\n# # dim(image_to_array(img))  # [1] 1084 1875    3\n# # img <- rgbImage(red=t(image_to_array(img)[,,1]/255), \n# #                           green=t(image_to_array(img)[,,2]/255), blue=t(image_to_array(img)[,,3]/255))\n# img <- rgb(red=t(image_to_array(img)[,,1]/255), \n#                           green=t(image_to_array(img)[,,2]/255), blue=t(image_to_array(img)[,,3]/255))\n# str(img)\n# # display(img)\n\n# img1 = load.image(paste(getwd(),\"results/image.png\", sep=\"/\"))\n# img2 <- rgb(red=t(grayscale(img1[,,1,1]/255)), \n#            green=t(grayscale(img1[,,1,2]/255)), blue=t(grayscale(img1[,,1,3]/255)))\n\nlibrary(plotly)\n# plot_ly(z=(img1[,,1,3]), type=\"heatmap\", transpose=TRUE) %>% \n#   layout(title=paste0(\"Original Image, dim=(\", dim(img1[,,1,3])[1], \", \",\n#                       dim(img1[,,1,3])[2], \")\"),\n#          xaxis=list(range=c(1, dim(img1[,,1,3])[1])), \n#          yaxis = list(range=c(1, dim(img1[,,1,3])[2]), \n#                       autorange = \"reversed\", scaleanchor  = \"x\")) %>% \n#   hide_colorbar()\n# ar <- keras3::image_to_array(img)\nar <- image_to_array(img)\nplot_ly(z=ar, type=\"image\") %>% \n  layout(title=paste0(\"Original Image, dim=(\", dim(ar[,,1])[1], \", \",\n                      dim(ar[,,1])[2], \")\"),\n         xaxis=list(range=c(1, dim(ar[,,1])[1])), \n         yaxis = list(range=c(1, dim(ar[,,1])[2]), \n                      autorange = \"reversed\", scaleanchor  = \"x\")) ",
      "line_count": 50
    },
    {
      "section": "Classifying Real-World Images using *Tensorflow* and *Keras*",
      "code": "# library(imager)   # for image resizing\n\npreproc.image <-function(im) {\n     # # crop the image\n     # mean.img <- mean(im)\n     # shape <- dim(im)\n     # # short.edge <- min(shape[1:2])\n     # # xx <- floor((shape[1] - short.edge) / 2)\n     # # yy <- floor((shape[2] - short.edge) / 2)\n     # # resize to 224 x 224, needed by input of the model.\n     # #### resized <- resize(im, 224, 224)\n     # \n     # # take the first RGB-color channel; transpose to get it anatomically correct Viz\n     # img4 <- t(apply(im, 2, rev)) \n     # # dim(img1)[1:2]  #  width and height of the original image\n     # olddim <- c(dim(img4)[1], dim(img4)[2])\n     # newdim <- c(224, 224)  # new smaller image dimensions\n     # img5 <- array(img4, dim=c(dim(img4)[1], dim(img4)[2], 1, 1))  # 2D img --> 4D hyper-volume\n     # \n     # # resized <- resize(img5, size_x = newdim[1], size_y = newdim[2])\n     # # plot(resized)\n     # \n     # img6 <- resize(img5, size_x = newdim[1], size_y = newdim[2])\n     # # dim(img1)  # [1] 64 64  1  1\n     # resized <- array(img6, dim=c(dim(img6)[1], dim(img6)[2]))  # 4D hyper-volume --> 2D img\n     # \n     # plot_ly(z=(resized), type=\"heatmap\", transpose=TRUE) %>%\n     #   layout(title=paste0(\"Resized Image, dim=(\", dim(resized)[1], \", \",\n     #                  dim(resized)[2], \")\"),\n     #          xaxis=list(range=c(1, dim(resized)[1])), \n     #          yaxis = list(range=c(1, dim(resized)[2]), \n     #                       autorange = \"reversed\", scaleanchor  = \"x\")) %>%\n     #   hide_colorbar()\n     # \n     # # Reshape to format (width, height, channel, num)\n     # dim(resized) <- c(224, 224, 3, 1)\n     # return(resized)\n  \n     # crop the image\n     mean.img <- mean(im)\n     shape <- dim(im)\n     resized <- resize(im, 224, 224)\n     # plot(resized)\n     # Reshape to format (width, height, channel, num)\n     dim(resized) <- c(224, 224, 3, 1)\n     return(resized)\n}",
      "line_count": 47
    },
    {
      "section": "Classifying Real-World Images using *Tensorflow* and *Keras*",
      "code": "ar2 <- array(ar, dim=c(dim(ar)[1], dim(ar)[2], dim(ar)[3], 1))\nnormed <- preproc.image(ar2)\nplot_ly(z=ar2[,,,1], type=\"image\")\n# plot(normed)",
      "line_count": 4
    },
    {
      "section": "Classifying Real-World Images using *Tensorflow* and *Keras*",
      "code": "# get info about local version of Python installation\n# reticulate::py_config()\n# The first time you run this install Pillow!\n# tensorflow::install_tensorflow(extra_packages='pillow')\n\n# Preprocess input image\nx <- image_to_array(img)\n# ensure we have a 4d tensor with single element in the first (batch) dimension,\n# then preprocess the input for prediction using resnet50\nx <- array_reshape(x, c(1, dim(x)))\nx <- imagenet_preprocess_input(x)   # note centralization: display(100*(x[1,,,1]+103))\n\n# Specify and compare Predictions based on different Pre-trained Models\n# Model 1: resnet50\nmodel_resnet50 <- application_resnet50(weights = 'imagenet')\n\n# make predictions then decode and print them\npreds_resnet50 <- model_resnet50 %>% predict(x)\nimagenet_decode_predictions(preds_resnet50, top = 10)\n\n# Model2: VGG19\nmodel_vgg19 <- application_vgg19(weights = 'imagenet')\npreds_vgg19 <- model_vgg19 %>% predict(x)\nimagenet_decode_predictions(preds_vgg19, top = 10)[[1]]\n\n# Model 3: VGG16\nmodel_vgg16 <- application_vgg16(weights = 'imagenet')\npreds_vgg16 <- model_vgg16 %>% predict(x)\nimagenet_decode_predictions(preds_vgg16, top = 10)[[1]]\n\ndim(preds_vgg16)",
      "line_count": 31
    },
    {
      "section": "Classifying Real-World Images using *Tensorflow* and *Keras*",
      "code": "# load the image\ndownload.file(\"https://upload.wikimedia.org/wikipedia/commons/2/23/Lake_mapourika_NZ.jpeg\", paste(getwd(),\"results/image.png\", sep=\"/\"), mode = 'wb')\nimg <- image_load(paste(getwd(),\"results/image.png\", sep=\"/\"), target_size = c(224,224))\n\n# imgRGB <- rgbImage(red=t(image_to_array(img)[,,1]/255), \n#                           green=t(image_to_array(img)[,,2]/255), blue=t(image_to_array(img)[,,3]/255))\n# display(imgRGB)\n\n# img1 = load.image(paste(getwd(),\"results/image.png\", sep=\"/\"))\n# \n# plot_ly(z=(img1[,,1,3]), type=\"heatmap\", transpose=TRUE) %>% \n#   layout(title=paste0(\"Original Image, dim=(\", dim(img1[,,1,3])[1], \", \",\n#                       dim(img1[,,1,3])[2], \")\"),\n#          xaxis=list(range=c(1, dim(img1[,,1,3])[1])), a\n#          yaxis = list(range=c(1, dim(img1[,,1,3])[2]), \n#                       autorange = \"reversed\", scaleanchor  = \"x\")) %>% \n#   hide_colorbar()\n\n# ar <- keras3::image_to_array(img)\nar <- image_to_array(img)\nplot_ly(z=ar, type=\"image\") %>% \n  layout(title=paste0(\"Original Image, dim=(\", dim(ar[,,1])[1], \", \",\n                      dim(ar[,,1])[2], \")\"),\n         xaxis=list(range=c(1, dim(ar[,,1])[1])), \n         yaxis = list(range=c(1, dim(ar[,,1])[2]), \n                      autorange = \"reversed\", scaleanchor  = \"x\")) \n\n\n# Preprocess input image\nx <- image_to_array(img)\n# ensure we have a 4d tensor with single element in the batch dimension,\n# the preprocess the input for prediction using resnet50\nx <- array_reshape(x, c(1, dim(x)))\nx <- imagenet_preprocess_input(x)\n\n# Specify and compare Predictions based on different Pre-trained Models\n# Model 1: resnet50\nmodel_resnet50 <- application_resnet50(weights = 'imagenet')\n\n# make predictions then decode and print them\npreds_resnet50 <- model_resnet50 %>% predict(x)\nimagenet_decode_predictions(preds_resnet50, top = 10)\n\n# Model2: VGG19\nmodel_vgg19 <- application_vgg19(weights = 'imagenet')\npreds_vgg19 <- model_vgg19 %>% predict(x)\nimagenet_decode_predictions(preds_vgg19, top = 10)[[1]]\n\n# Model 3: VGG16\nmodel_vgg16 <- application_vgg16(weights = 'imagenet')\npreds_vgg16 <- model_vgg16 %>% predict(x)\nimagenet_decode_predictions(preds_vgg16, top = 10)[[1]]\n\ndim(preds_vgg16)",
      "line_count": 54
    },
    {
      "section": "Classifying Real-World Images using *Tensorflow* and *Keras*",
      "code": "download.file(\"https://upload.wikimedia.org/wikipedia/commons/9/90/Holloways_beach_1920x1080.jpg\", paste(getwd(),\"results/image.png\", sep=\"/\"), mode = 'wb')\nimg <- image_load(paste(getwd(),\"results/image.png\", sep=\"/\"), target_size = c(224,224))\n\n# imgRGB <- rgbImage(red=t(image_to_array(img)[,,1]/255), \n#                           green=t(image_to_array(img)[,,2]/255), blue=t(image_to_array(img)[,,3]/255))\n# display(imgRGB)\n# img1 = load.image(paste(getwd(),\"results/image.png\", sep=\"/\"))\n\n# ar <- keras3::image_to_array(img)\nar <- image_to_array(img)\nplot_ly(z=ar, type=\"image\") %>% \n  layout(title=paste0(\"Original Image, dim=(\", dim(ar[,,1])[1], \", \",\n                      dim(ar[,,1])[2], \")\"),\n         xaxis=list(range=c(1, dim(ar[,,1])[1])), \n         yaxis = list(range=c(1, dim(ar[,,1])[2]), \n                      autorange = \"reversed\", scaleanchor  = \"x\")) \n\n\n# Preprocess input image\nx <- image_to_array(img)\n# ensure we have a 4d tensor with single element in the batch dimension,\n# the preprocess the input for prediction using resnet50\nx <- array_reshape(x, c(1, dim(x)))\nx <- imagenet_preprocess_input(x)\n\n# Specify and compare Predictions based on different Pre-trained Models\n# Model 1: resnet50\nmodel_resnet50 <- application_resnet50(weights = 'imagenet')\n\n# make predictions then decode and print them\npreds_resnet50 <- model_resnet50 %>% predict(x)\nimagenet_decode_predictions(preds_resnet50, top = 10)\n\n# Model2: VGG19\nmodel_vgg19 <- application_vgg19(weights = 'imagenet')\npreds_vgg19 <- model_vgg19 %>% predict(x)\nimagenet_decode_predictions(preds_vgg19, top = 10)[[1]]\n\n# Model 3: VGG16\nmodel_vgg16 <- application_vgg16(weights = 'imagenet')\npreds_vgg16 <- model_vgg16 %>% predict(x)\nimagenet_decode_predictions(preds_vgg16, top = 10)[[1]]",
      "line_count": 42
    },
    {
      "section": "Classifying Real-World Images using *Tensorflow* and *Keras*",
      "code": "download.file(\"https://upload.wikimedia.org/wikipedia/commons/thumb/d/dc/MSH82_st_helens_plume_from_harrys_ridge_05-19-82.jpg/1200px-MSH82_st_helens_plume_from_harrys_ridge_05-19-82.jpg\", paste(getwd(),\"results/image.png\", sep=\"/\"), mode = 'wb')\nimg <- image_load(paste(getwd(),\"results/image.png\", sep=\"/\"), target_size = c(224,224))\n\n# imgRGB <- rgbImage(red=t(image_to_array(img)[,,1]/255), \n#                           green=t(image_to_array(img)[,,2]/255), blue=t(image_to_array(img)[,,3]/255))\n# display(imgRGB)\n\n# ar <- keras3::image_to_array(img)\nar <- image_to_array(img)\nplot_ly(z=ar, type=\"image\") %>% \n  layout(title=paste0(\"Original Image, dim=(\", dim(ar[,,1])[1], \", \",\n                      dim(ar[,,1])[2], \")\"),\n         xaxis=list(range=c(1, dim(ar[,,1])[1])), \n         yaxis = list(range=c(1, dim(ar[,,1])[2]), \n                      autorange = \"reversed\", scaleanchor  = \"x\")) \n\n# Preprocess input image\nx <- image_to_array(img)\n# ensure we have a 4d tensor with single element in the batch dimension,\n# the preprocess the input for prediction using resnet50\nx <- array_reshape(x, c(1, dim(x)))\nx <- imagenet_preprocess_input(x)\n\n# Specify and compare Predictions based on different Pre-trained Models\n# Model 1: resnet50\nmodel_resnet50 <- application_resnet50(weights = 'imagenet')\n\n# make predictions then decode and print them\npreds_resnet50 <- model_resnet50 %>% predict(x)\nimagenet_decode_predictions(preds_resnet50, top = 10)\n\n# Model2: VGG19\nmodel_vgg19 <- application_vgg19(weights = 'imagenet')\npreds_vgg19 <- model_vgg19 %>% predict(x)\nimagenet_decode_predictions(preds_vgg19, top = 10)[[1]]\n\n# Model 3: VGG16\nmodel_vgg16 <- application_vgg16(weights = 'imagenet')\npreds_vgg16 <- model_vgg16 %>% predict(x)\nimagenet_decode_predictions(preds_vgg16, top = 10)[[1]]",
      "line_count": 40
    },
    {
      "section": "Classifying Real-World Images using *Tensorflow* and *Keras*",
      "code": "download.file(\"https://wiki.socr.umich.edu/images/e/ea/BrainCortex2.png\", paste(getwd(),\"results/image.png\", sep=\"/\"), mode = 'wb')\nim <- load.image(paste(getwd(),\"results/image.png\", sep=\"/\"))\n\ndownload.file(\"https://wiki.socr.umich.edu/images/e/ea/BrainCortex2.png\", paste(getwd(),\"results/image.png\", sep=\"/\"), mode = 'wb')\nimg <- image_load(paste(getwd(),\"results/image.png\", sep=\"/\"), target_size = c(224,224))\n\n# imgRGB <- rgbImage(red=t(image_to_array(img)[,,1]/255), \n#                           green=t(image_to_array(img)[,,2]/255), blue=t(image_to_array(img)[,,3]/255))\n# display(imgRGB)\n\n# ar <- keras3::image_to_array(img)\nar <- image_to_array(img)\nplot_ly(z=ar, type=\"image\") %>% \n  layout(title=paste0(\"Original Image, dim=(\", dim(ar[,,1])[1], \", \",\n                      dim(ar[,,1])[2], \")\"),\n         xaxis=list(range=c(1, dim(ar[,,1])[1])), \n         yaxis = list(range=c(1, dim(ar[,,1])[2]), \n                      autorange = \"reversed\", scaleanchor  = \"x\")) \n# Preprocess input image\nx <- image_to_array(img)\n# ensure we have a 4d tensor with single element in the batch dimension,\n# the preprocess the input for prediction using resnet50\nx <- array_reshape(x, c(1, dim(x)))\nx <- imagenet_preprocess_input(x)\n\n# Specify and compare Predictions based on different Pre-trained Models\n# Model 1: resnet50\nmodel_resnet50 <- application_resnet50(weights = 'imagenet')\n\n# make predictions then decode and print them\npreds_resnet50 <- model_resnet50 %>% predict(x)\nimagenet_decode_predictions(preds_resnet50, top = 10)\n\n# Model2: VGG19\nmodel_vgg19 <- application_vgg19(weights = 'imagenet')\npreds_vgg19 <- model_vgg19 %>% predict(x)\nimagenet_decode_predictions(preds_vgg19, top = 10)[[1]]\n\n# Model 3: VGG16\nmodel_vgg16 <- application_vgg16(weights = 'imagenet')\npreds_vgg16 <- model_vgg16 %>% predict(x)\nimagenet_decode_predictions(preds_vgg16, top = 10)[[1]]",
      "line_count": 42
    },
    {
      "section": "Classifying Real-World Images using *Tensorflow* and *Keras*",
      "code": "download.file(\"https://wiki.socr.umich.edu/images/f/fb/FaceMask1.png\", paste(getwd(),\"results/image.png\", sep=\"/\"), mode = 'wb')\nimg <- image_load(paste(getwd(),\"results/image.png\", sep=\"/\"), target_size = c(224,224))\n\n# imgRGB <- rgbImage(red=t(image_to_array(img)[,,1]/255), \n#                           green=t(image_to_array(img)[,,2]/255), blue=t(image_to_array(img)[,,3]/255))\n# display(imgRGB)\n\n# ar <- keras3::image_to_array(img)\nar <- image_to_array(img)\nplot_ly(z=ar, type=\"image\") %>% \n  layout(title=paste0(\"Original Image, dim=(\", dim(ar[,,1])[1], \", \",\n                      dim(ar[,,1])[2], \")\"),\n         xaxis=list(range=c(1, dim(ar[,,1])[1])), \n         yaxis = list(range=c(1, dim(ar[,,1])[2]), \n                      autorange = \"reversed\", scaleanchor  = \"x\")) \n\n# Preprocess input image\nx <- image_to_array(img)\n# ensure we have a 4d tensor with single element in the batch dimension,\n# the preprocess the input for prediction using resnet50\nx <- array_reshape(x, c(1, dim(x)))\nx <- imagenet_preprocess_input(x)\n\n# Specify and compare Predictions based on different Pre-trained Models\n# Model 1: resnet50\nmodel_resnet50 <- application_resnet50(weights = 'imagenet')\n\n# make predictions then decode and print them\npreds_resnet50 <- model_resnet50 %>% predict(x)\nimagenet_decode_predictions(preds_resnet50, top = 10)\n\n# Model2: VGG19\nmodel_vgg19 <- application_vgg19(weights = 'imagenet')\npreds_vgg19 <- model_vgg19 %>% predict(x)\nimagenet_decode_predictions(preds_vgg19, top = 10)[[1]]\n\n# Model 3: VGG16\nmodel_vgg16 <- application_vgg16(weights = 'imagenet')\npreds_vgg16 <- model_vgg16 %>% predict(x)\nimagenet_decode_predictions(preds_vgg16, top = 10)[[1]]",
      "line_count": 40
    },
    {
      "section": "Data Generation:  simulating synthetic data",
      "code": "# Barnsley's Fern\n# (1) create the 4-IFS functions of the probability and the current point\nfractal_BarnsleyFern <- function(x, p){\n    if (p <= 0.01) {\n        A <- matrix(c(0, 0, 0, 0.16), 2, 2)\n        B <- c(0, 0)\n    } else if (p <= 0.86) {\n        A <- matrix(c(.85, -.02, .02, .85), 2, 2)\n        B <- c(0, 1.6)\n    } else if (p <= 0.95) {\n        A <- matrix(c(.2, .23, -.26, .22), 2, 2)\n        B <- c(0, 1.6)\n    } else {\n        A <- matrix(c(-.15, .26, .28, .24), 2, 2)\n        B <- c(0, .44)\n    }\n    return(A %*% x + B)\n}\n\n# Fern Resolution depends on the number of iterative applications of the IFS system\nreps <- 100000\n\n# create a vector with probability values, and a matrix to store coordinates\np <- runif(reps)\n\n# initialize a point at the origin\ninit_coords <- c(0, 0)\n\n# compute the list of reps fractal coordinates: (X,Y) pairs\nA <- Reduce(fractal_BarnsleyFern, p, accumulate = T, init = init_coords)\nA <- t(do.call(cbind, A)) # unwind the list of (X,Y) pairs as (reps * 2) array\n\n# Plot\n# plot(A, type = \"p\", cex = 0.1, col = \"darkgreen\",\n#      xlim = c(-3, 3), ylim = c(0, 15), \n#      xlab = NA, ylab = NA, axes = FALSE)\nplot_ly(x=~A[,1], y=~A[,2], type=\"scatter\", mode=\"markers\", name=\"Barnsley's Fern\",\n        marker = list(color = 'rgb(157, 255, 157)', size = 1))\n\n# export Fern as JPG image\njpeg(paste(getwd(), sep=\"/\", \"results/FernPlot.jpg\"))\nplot(A, type = \"p\", cex = 0.1, col = \"darkgreen\", xlim = c(-3, 3), ylim = c(0, 15), \n     xlab = NA, ylab = NA, axes = FALSE)\ndev.off()\n\n# Load the image back in and test the DNN classification\nimg <- image_load(paste(getwd(),\"results/FernPlot.jpg\", sep=\"/\"), target_size = c(224,224))\n# Plot Fern\n\n# Preprocess the Fern image and predict its class (label)\n# imgRGB <- rgbImage(red=t(image_to_array(img)[,,1]/255), \n#                           green=t(image_to_array(img)[,,2]/255), blue=t(image_to_array(img)[,,3]/255))\n# display(imgRGB)\n\n# ar <- keras3::image_to_array(img)\nar <- image_to_array(img)\nplot_ly(z=ar, type=\"image\") %>% \n  layout(title=paste0(\"Original Image, dim=(\", dim(ar[,,1])[1], \", \",\n                      dim(ar[,,1])[2], \")\"),\n         xaxis=list(range=c(1, dim(ar[,,1])[1])), \n         yaxis = list(range=c(1, dim(ar[,,1])[2]), \n                      autorange = \"reversed\", scaleanchor  = \"x\")) \n\n# Preprocess input image\nx <- image_to_array(img)\n# ensure we have a 4d tensor with single element in the batch dimension,\n# the preprocess the input for prediction using resnet50\nx <- array_reshape(x, c(1, dim(x)))\nx <- imagenet_preprocess_input(x)\n\n# Specify and compare Predictions based on different Pre-trained Models\n# Model 1: resnet50\nmodel_resnet50 <- application_resnet50(weights = 'imagenet')\n\n# make predictions then decode and print them\npreds_resnet50 <- model_resnet50 %>% predict(x)\nimagenet_decode_predictions(preds_resnet50, top = 10)\n\n# Model2: VGG19\nmodel_vgg19 <- application_vgg19(weights = 'imagenet')\npreds_vgg19 <- model_vgg19 %>% predict(x)\nimagenet_decode_predictions(preds_vgg19, top = 10)[[1]]\n\n# Model 3: VGG16\nmodel_vgg16 <- application_vgg16(weights = 'imagenet')\npreds_vgg16 <- model_vgg16 %>% predict(x)\nimagenet_decode_predictions(preds_vgg16, top = 10)[[1]]",
      "line_count": 87
    },
    {
      "section": "Data Generation:  simulating synthetic data",
      "code": "library(keras)\nlatent_dim <- 32\nheight <- 32\nwidth <- 32\nchannels <- 3\ngenerator_input <- layer_input(shape = c(latent_dim))\ngenerator_output <- generator_input %>%\n  layer_dense(units = 128 * 16 * 16) %>%                             \n  layer_activation_leaky_relu() %>%                                  \n  layer_reshape(target_shape = c(16, 16, 128)) %>%                   \n  layer_conv_2d(filters = 256, kernel_size = 5,\n                padding = \"same\") %>%\n  layer_activation_leaky_relu() %>%\n  layer_conv_2d_transpose(filters = 256, kernel_size = 4,            \n                          strides = 2, padding = \"same\") %>%         \n  layer_activation_leaky_relu() %>%                                  \n  layer_conv_2d(filters = 256, kernel_size = 5,\n                padding = \"same\") %>%\n  layer_activation_leaky_relu() %>%\n  layer_conv_2d(filters = 256, kernel_size = 5,\n                padding = \"same\") %>%\n  layer_activation_leaky_relu() %>%\n  layer_conv_2d(filters = channels, kernel_size = 7,                 \n                activation = \"tanh\", padding = \"same\")               \ngenerator <- keras_model(generator_input, generator_output)          \n\ndiscriminator_input <- layer_input(shape = c(height, width, channels))\ndiscriminator_output <- discriminator_input %>%\n  layer_conv_2d(filters = 128, kernel_size = 3) %>%\n  layer_activation_leaky_relu() %>%\n  layer_conv_2d(filters = 128, kernel_size = 4, strides = 2) %>%\n  layer_activation_leaky_relu() %>%\n  layer_conv_2d(filters = 128, kernel_size = 4, strides = 2) %>%\n  layer_activation_leaky_relu() %>%\n  layer_conv_2d(filters = 128, kernel_size = 4, strides = 2) %>%\n  layer_activation_leaky_relu() %>%\n  layer_flatten() %>%\n  layer_dropout(rate = 0.4) %>%                                            \n  layer_dense(units = 1, activation = \"sigmoid\")                           \ndiscriminator <- keras_model(discriminator_input, discriminator_output)    \ndiscriminator_optimizer <- optimizer_rmsprop(\n  learning_rate = 0.0008,\n  clipvalue = 1.0,                                                         \n  # decay = 1e-8   \n  momentum = 1 - 1e-8\n)\ndiscriminator %>% compile(\n  optimizer = discriminator_optimizer,\n  loss = \"binary_crossentropy\"\n)\n\n# freeze_weights(discriminator)                         1\ngan_input <- layer_input(shape = c(latent_dim))\ngan_output <- discriminator(generator(gan_input))\ngan <- keras_model(gan_input, gan_output)\ngan_optimizer <- optimizer_rmsprop(\n  learning_rate = 0.0004,\n  clipvalue = 1.0,\n  # decay = 1e-8   \n  momentum = 1 - 1e-8\n)\ngan %>% compile(\n  optimizer = gan_optimizer,\n  loss = \"binary_crossentropy\"\n)\n\n# mnist_fashion <- keras::dataset_fashion_mnist()  # shape (num_samples, 28, 28) \ncifar10 <- dataset_cifar10()  # shape (num_samples, 3, 32, 32)                                          \nc(c(x_train, y_train), c(x_test, y_test)) %<-% cifar10\nx_train <- x_train[as.integer(y_train) == 6,,,]                           \nx_train <- x_train / 255                                                  \niterations <- 100\nbatch_size <- 20\nsave_dir <- getwd()                                                   \nstart <- 1\nfor (step in 1:iterations) {\n  random_latent_vectors <- matrix(rnorm(batch_size * latent_dim),         \n                                  nrow = batch_size, ncol = latent_dim)\n  generated_images <- generator %>% predict(random_latent_vectors)        \n  stop <- start + batch_size - 1                                          \n  real_images <- x_train[start:stop,,,]                                   \n  rows <- nrow(real_images)                                               \n  combined_images <- array(0, dim = c(rows * 2, dim(real_images)[-1]))    \n  combined_images[1:rows,,,] <- generated_images                          \n  combined_images[(rows+1):(rows*2),,,] <- real_images                    \n  labels <- rbind(matrix(1, nrow = batch_size, ncol = 1),                 \n                  matrix(0, nrow = batch_size, ncol = 1))                 \n  labels <- labels + (0.5 * array(runif(prod(dim(labels))),               \n                                  dim = dim(labels)))                     \n  d_loss <- discriminator %>% train_on_batch(combined_images, labels)     \n  random_latent_vectors <- matrix(rnorm(batch_size * latent_dim),         \n                                  nrow = batch_size, ncol = latent_dim)   \n  misleading_targets <- array(0, dim = c(batch_size, 1))                  \n  a_loss <- gan %>% train_on_batch(                                       \n    random_latent_vectors,                                                \n    misleading_targets                                                    \n  )                                                                       \n  start <- start + batch_size\n  if (start > (nrow(x_train) - batch_size))\n    start <- 1\n  if (step %% 10 == 0) {                                                 \n    # save_model_weights_hdf5(gan, \"gan.h5\")                                \n    # Status Reporting\n    cat(\"Completion Status: \", round((100*step)/iterations,0), \"% \\n\")\n    cat(\"\\t discriminator loss:\", d_loss, \"\\n\")\n    cat(\"\\t adversarial loss:\", a_loss, \"\\n\")\n\n    # Optionally save the real/generated images\n    # image_array_save(generated_images[1,,,]*255,path=file.path(save_dir,paste0(\"generated_img\",step,\".png\")))\n    # image_array_save(real_images[1,,,]*255,path = file.path(save_dir, paste0(\"real_img\", step, \".png\")))\n  }\n}\n\n# Generated images are: generated_images[batch_size=20, x=32, y=32, channels=3]\n# Upscale the last generated image 32*32 -> 128*128*\n#### normed <- EBImage::resize(generated_images[10,,,2]*255, w = 224, h = 224)\n\nlibrary(imager)   # for image resizing\n# take the first RGB-color channel; transpose to get it anatomically correct Viz\nimg1 <- t(apply(generated_images[10,,,2]*255, 2, rev)) \n# dim(img1)[1:2]  #  width and height of the original image\nolddim <- c(dim(img1)[1], dim(img1)[2])\nnewdim <- c(224, 224)  # new smaller image dimensions\nimg2 <- array(img1, dim=c(dim(img1)[1], dim(img1)[2], 1, 1))  # 2D img --> 4D hyper-volume\nnormed <- resize(img2, size_x = newdim[1], size_y = newdim[2])\n\n\n# image(normed, asp = 1, xaxt='n', yaxt='n', ann=FALSE, frame.plot=F)\n# title(main = \"Synthetic Image\", font.main = 10)\nplot_ly(z=~generated_images[15,,,1], type=\"contour\", showscale=F)\n# plot_ly(z=~generated_images[10,,,2], type=\"image\")\n\n#convert the image to 4D\nnormed4D <- rbind (normed, normed, normed)\ndim(normed4D) <- c(224, 224, 3, 1)\n\n# predict class label of synth image (normed4D)\nx <- image_to_array(img)\n# ensure we have a 4d tensor with single element in the batch dimension,\n# the preprocess the input for prediction using resnet50\nx <- array_reshape(x, c(1, dim(x)))\nx <- imagenet_preprocess_input(x)\n\n# Specify and compare Predictions based on different Pre-trained Models\n# Model 1: resnet50\nmodel_resnet50 <- application_resnet50(weights = 'imagenet')\n\n# make predictions then decode and print them\npreds_resnet50 <- model_resnet50 %>% predict(x)\nimagenet_decode_predictions(preds_resnet50, top = 10)",
      "line_count": 150
    },
    {
      "section": "Generative Adversarial Networks (GANs)",
      "code": "library(keras)\nlibrary(tensorflow)\n# install_tensorflow(version = \"gpu\")\n# install_keras(tensorflow = \"gpu\")\n# library(EBImage)\n\n# CIFAR10 original labels: https://www.cs.toronto.edu/~kriz/cifar.html \n# The label data is just a list of 10,000 numbers ranging from 0 to 9, which corresponds to each of the 10 classes in CIFAR-10.\n#     airplane : 0\n#     automobile : 1\n#     bird : 2\n#     cat : 3\n#     deer : 4\n#     dog : 5\n#     frog : 6\n#     horse : 7\n#     ship : 8\n#     truck : 9\n# Focus on CIFAR10 BIRD images(label 2)!\n\n# Loads CIFAR10 data\ncifar10 <- dataset_cifar10()                                              \nc(c(x_train, y_train), c(x_test, y_test)) %<-% cifar10\n\n# Selects bird images (class 2)\nx_train <- x_train[as.integer(y_train) == 2,,,]                           \n\n# Normalizes image intensities (bytes [0,255] --> [0,1])\nx_train <- x_train / 255                                                  \n\n# Display a grid of 10*10 Bird images\n# img_real <- list()\n# bird_images <- x_train[1:(10*10),,,]\n# for (i in 1:10) {\n#   for (j in 1:10) {\n#     img_real[[i+ (j-1)*10]] <- rotate(rgbImage(   # normalize the RGB values to [0,1] to use EBImage::display()\n#       normalize(bird_images[i+ (j-1)*10,,,1]), normalize(bird_images[i+ (j-1)*10,,,2]), \n#       normalize(bird_images[i+ (j-1)*10,,,3])), 90) \n#   }\n# } \n# img_comb = EBImage::combine(img_real)\n# # Display the Bird images\n# EBImage::display(img_comb, method=\"raster\", all = TRUE)\n# \n# plt_list <- list()\n# N=100 \n# for (i in 1:10) {\n#   for (j in 1:10) {\n#     plt_list[[i+(j-1)*10]] <- \n#       plot_ly(z=bird_images[i+ (j-1)*10,,,1], type=\"heatmap\", showscale=FALSE) %>% \t\n#       layout(showlegend=FALSE,  # hovermode = \"y unified\",\n#              xaxis=list(zeroline=F, showline=F, showticklabels=F, showgrid=F),\n#              yaxis=list(autorange = \"reversed\", zeroline=F,showline=F,showticklabels=F,showgrid=F)) #,\t\n#              # yaxis = list(scaleratio = 1, scaleanchor = 'x'))\t\n#   }\n# }\n# \n# # plt_list[[2]] \t\n# plt_list %>%\t\n#   subplot(nrows = 10, margin = 0.001, which_layout=1) %>%\t\n#   layout(title=\"CIFAR-10 - a collage of random birds\")\t\n\nbird_images <- x_train[1:(10*10),,,]\nplt_list <- list()\nN=100 \nfor (i in 1:10) {\n  for (j in 1:10) {\n    plt_list[[i+(j-1)*10]] <- \n      plot_ly(z=255*bird_images[i+ (j-1)*10,,,], type=\"image\", showscale=FALSE) %>% \t\n      layout(showlegend=FALSE,  # hovermode = \"y unified\",\n             xaxis=list(zeroline=F, showline=F, showticklabels=F, showgrid=F),\n             yaxis=list(zeroline=F,showline=F,showticklabels=F,showgrid=F)) #,\n             # yaxis = list(scaleratio = 1, scaleanchor = 'x'))\n  }\n}\n\n# plt_list[[2]] \t\nplt_list %>%\t\n  subplot(nrows = 10, margin = 0.0001, which_layout=1) %>%\t\n  layout(title=\"CIFAR-10 - a collage of random birds\")",
      "line_count": 80
    },
    {
      "section": "Generative Adversarial Networks (GANs)",
      "code": "latent_dim <- 32\nheight <- 32\nwidth <- 32\nchannels <- 3\ngenerator_input <- layer_input(shape = c(latent_dim))\ngenerator_output <- generator_input %>%\n  # transforms the input into a 16 × 16, 128 channel feature\n  layer_dense(units = 128 * 16 * 16) %>%                             \n  layer_activation_leaky_relu() %>%                                  \n  layer_reshape(target_shape = c(16, 16, 128)) %>%    \n  layer_conv_2d(filters = 256, kernel_size = 5,\n                padding = \"same\") %>%\n  layer_activation_leaky_relu() %>%\n  # Upsample images 16 x 16 --> 32 × 32\n  layer_conv_2d_transpose(filters = 256, kernel_size = 4,            \n                          strides = 2, padding = \"same\") %>%         \n  layer_activation_leaky_relu() %>%                                  \n  layer_conv_2d(filters = 256, kernel_size = 5,\n                padding = \"same\") %>%\n  layer_activation_leaky_relu() %>%\n  # generate a 3-channel RGB feature-map 32 × 32 reflecting the dimensions of all CIFAR10 images\n  layer_conv_2d(filters = 256, kernel_size = 5, padding = \"same\") %>%\n  layer_activation_leaky_relu() %>%\n  # instantiate the generator model, mapping the input of latent_dim into an image of dimension (32, 32, 3)\n  layer_conv_2d(filters = channels, kernel_size = 7,                 \n                activation = \"tanh\", padding = \"same\")               \ngenerator <- keras_model(generator_input, generator_output)   ",
      "line_count": 27
    },
    {
      "section": "Generative Adversarial Networks (GANs)",
      "code": "discriminator_input <- layer_input(shape = c(height, width, channels))\ndiscriminator_output <- discriminator_input %>%\n  layer_conv_2d(filters = 128, kernel_size = 3) %>%\n  layer_activation_leaky_relu() %>%\n  layer_conv_2d(filters = 128, kernel_size = 4, strides = 2) %>%\n  layer_activation_leaky_relu() %>%\n  layer_conv_2d(filters = 128, kernel_size = 4, strides = 2) %>%\n  layer_activation_leaky_relu() %>%\n  layer_conv_2d(filters = 128, kernel_size = 4, strides = 2) %>%\n  layer_activation_leaky_relu() %>%\n  layer_flatten() %>%\n  # one dropout layer, see text\n  layer_dropout(rate = 0.4) %>%     \n  # classification layer\n  layer_dense(units = 1, activation = \"sigmoid\")                           \n# instantiate the discriminator model, taking a (32, 32, 3) input into a binary classification decision (fake/real)\ndiscriminator <- keras_model(discriminator_input, discriminator_output)    \ndiscriminator_optimizer <- optimizer_rmsprop(\n  learning_rate = 0.0008,\n  # gradient clipping (by value) in the optimizer\n  clipvalue = 1.0,  \n  # to stabilize training, specify a learning-rate decay\n  # decay = 1e-8   \n  momentum = 1 - 1e-8                                                           \n)\ndiscriminator %>% compile(\n  optimizer = discriminator_optimizer,\n  loss = \"binary_crossentropy\"\n)",
      "line_count": 29
    },
    {
      "section": "Generative Adversarial Networks (GANs)",
      "code": "# For the GAN model, set the discriminator weights to non-trainable\nfreeze_weights(discriminator)                         \ngan_input <- layer_input(shape = c(latent_dim))\ngan_output <- discriminator(generator(gan_input))\ngan <- keras_model(gan_input, gan_output)\ngan_optimizer <- optimizer_rmsprop(\n  learning_rate = 0.0004,\n  clipvalue = 1.0,\n  # decay = 1e-8   \n  momentum = 1 - 1e-8\n)\ngan %>% compile(\n  optimizer = gan_optimizer,\n  loss = \"binary_crossentropy\"\n)",
      "line_count": 15
    },
    {
      "section": "Generative Adversarial Networks (GANs)",
      "code": "iterations <- 200 # 10000 increase  to get better results (improved synthetic images)\n# build the layout matrix with additional separating cells\nnx <- 10 # number of images in a row\nny <- 10 # number of images in a column\nbatch_size <- 20\nstart <- 1\n\n# List of nx*ny synthetic and real images (as matrices)\nimg_gan <- list()\n#img_gan[[1]] <- x_train[1,,,1]; image(img_gan[[1]])\nimg_real <- list()\nplt_list <- list()\n\nfor (step in 1:iterations) {\n  # First-tier sampling of random points in the latent space\n  random_latent_vectors <- matrix(rnorm(batch_size*latent_dim),  nrow=batch_size, ncol=latent_dim)\n  \n  # str(generated_images) (Batch-size, 2D-grid, RGB-colors)\n  # Array[1:20, 1:32, 1:32, 1:3]\n  # decode/generate and save synth-generated images\n  generated_images <- generator %>% predict(random_latent_vectors)  \n  \n  # Combine synth and real images\n  stop <- start + batch_size - 1                                          \n  real_images <- x_train[start:stop,,,]                                   \n  rows <- nrow(real_images)                                               \n  combined_images <- array(0, dim = c(rows * 2, dim(real_images)[-1]))    \n  combined_images[1:rows,,,] <- generated_images                          \n  combined_images[(rows+1):(rows*2),,,] <- real_images                    \n  \n  # Assemble the labels discriminating synth from real images\n  labels <- rbind(matrix(1, nrow = batch_size, ncol = 1),                 \n                  matrix(0, nrow = batch_size, ncol = 1))                 \n  \n  # Add random noise to the image-labels to avoid trapping in local minima\n  labels <- labels + (0.5 * array(runif(prod(dim(labels))),               \n                                  dim = dim(labels)))                     \n  \n  # First, train the discriminator, $D$\n  d_loss <- discriminator %>% train_on_batch(combined_images, labels)     \n  \n  # Second-tier sampling of random points in the latent space\n  random_latent_vectors <- matrix(rnorm(batch_size*latent_dim), nrow = batch_size, ncol = latent_dim)   \n  \n  # Assemble labels = \"real images” (fake incorrect labels)\n  misleading_targets <- array(0, dim = c(batch_size, 1))                  \n  \n  # Second, train the generator $G$ using the GAN model. Note that the discriminator weights are fixed (static) during this optimization\n  a_loss <- gan %>% train_on_batch(                                       \n    random_latent_vectors,                                                \n    misleading_targets                                                    \n  )                                                                       \n  start <- start + batch_size\n  if (start > (nrow(x_train) - batch_size))   start <- 1\n  \n  # Display some of the generated images for visual inspection (number = iterations/(nx*ny))\n  if (step %% (nx*ny) == 0) {                                                 \n    # Save the GAN model weights in h5 format\n    save_model_weights_hdf5(gan, \"gan.h5\")                                \n    \n    # Report metrics\n    cat(\"Step=\", step, \"; discriminator loss=\", d_loss, \"\\n\")                              \n    cat(\"Step=\", step, \"; adversarial loss=\", a_loss, \"\\n\")                                \n\n    # # Save one synth-generated image, Need to normalize the RGB values to [0,1] \n    # img_gan[[step/(nx*ny)]] <- rotate(rgbImage(generated_images[1,,,1],\n    #                           generated_images[1,,,2], generated_images[1,,,3]), 90)                         # Save one real (bird) image\n    # img_real[[step/(nx*ny)]] <- rotate(rgbImage(real_images[1,,,1], \n    #                           real_images[1,,,2], real_images[1,,,3]), 90) \n    \n    # plot_ly rendering\n    pl1 <- plot_ly(z=255*real_images[step/(nx*ny), , , ], type=\"image\") %>% \t\n        layout(showlegend=FALSE,  # hovermode = \"y unified\",\n             xaxis=list(zeroline=F, showline=F, showticklabels=F, showgrid=F),\n             yaxis=list(zeroline=F,showline=F,showticklabels=F,showgrid=F))\n    pl2 <- plot_ly(z=255*generated_images[step/(nx*ny), , , ], type=\"image\") %>% \t\n        layout(showlegend=FALSE,  # hovermode = \"y unified\",\n             xaxis=list(zeroline=F, showline=F, showticklabels=F, showgrid=F),\n             yaxis=list(zeroline=F,showline=F,showticklabels=F,showgrid=F))\n    plt_list[[step/(nx*ny)]] <- subplot(pl1, pl2, nrows = 1, margin = 0.0001, which_layout=1)\n  }\n}\n\n# img_comb = EBImage::combine(c(img_real, img_gan))\n# # Display the Bird images\n# EBImage::display(img_comb, method=\"raster\", all = TRUE)\n\n# plt_list[[2]] \t\nplt_list %>%\t\n  subplot(nrows = 2, margin = 0.0001, which_layout=1) %>%\t\n  layout(title=\"Observed (left) and Synthetic (right) Bird Images\")",
      "line_count": 91
    },
    {
      "section": "Transfer Learning",
      "code": "venv_name <- \"r-tensorflow\"\nreticulate::use_virtualenv(virtualenv = venv_name, required = TRUE)\nlibrary(reticulate)\n\n# load the necessary libraries\n# May need some installations first, e.g., \n#    in conda%> pip install tensorflow_datasets\n#    install.packages(\"remotes\")\n#    remotes::install_github(\"rstudio/tfds\")\n#    tfds::install_tfds()\n\nlibrary(keras)\n# library(reticulate)\n\n# Install package TFhub: https://github.com/rstudio/tfhub\n# devtools::install_github(\"rstudio/tfhub\")\nlibrary(tfhub)\n# library(tfds)\n\n# Install TFdatasets: https://cran.r-project.org/web/packages/tfdatasets/vignettes/introduction.html\n# devtools::install_github(\"rstudio/tfdatasets\")\nlibrary(tfdatasets)\nlibrary(utf8)\n\n# specify r-reticulate or r-tensorflow python Anaconda environment\n# use_condaenv(\"r-tensorflow\")\n# use_condaenv(\"r-reticulate\", required = TRUE)\n# there are many ways to \"finding\" your conda environments, and using the reticulate package to set them\n\n# conda_list()[[1]][1] %>%  use_condaenv(required = TRUE)\n\n# Check tensorflow install configuration\ntensorflow::tf_config()\n# py_module_available(\"tensorflow_hub\")\n\n# py_install(\"tensorflow_hub\", pip = TRUE) # py_install(\"tensorflow_hub\")\n# py_install(\"tfds\", pip = TRUE) # py_install(\"tfds\")\n# py_install(\"tensorflow_datasets\", pip = TRUE)\n\n# py_module_available(\"tensorflow_datasets\")\n# py_module_available(\"tfds\")  # tensorflow_datasets",
      "line_count": 41
    },
    {
      "section": "Transfer Learning",
      "code": "# install.packages(\"SnowballC\")\n\nlibrary(keras)\nlibrary(SnowballC)\ndataCT <- read.csv('https://umich.instructure.com/files/21152999/download?download_frd=1', header=T) \nstr(dataCT)\n\n# 'data.frame':\t4999 obs. with  6 variables\ncolnames(dataCT)\n\n# Binarize the 40 hospital units as Surgery-type and Non-Surgery types\ndataCT$surgLabel <- ifelse(grepl('Surg', dataCT$medical_specialty), 1, 0)\ntable(grepl('Surg', dataCT$medical_specialty))\n\n# Fix the descriptions to UTF-8 encoding\nlibrary(stringi)\n# table(stri_enc_mark(dataCT$description)) # ASCII native #  4994      5\ndataCT$description <- stri_encode(dataCT$description, \"\", \"UTF-8\") \ndataCT$transcription <- stri_encode(dataCT$transcription, \"\", \"UTF-8\") \n\ndataCT$clinicalNotes <- paste(dataCT$description, dataCT$transcription)\n\n# Clean the clinical notes\nlibrary(tm)\n## Vectorize the text\ntrain_corpus <- VCorpus(VectorSource(dataCT$clinicalNotes))\n## Remove Punctuation\ntrain_corpus <- tm_map(train_corpus, content_transformer(removePunctuation))\n## Remove numbers\ntrain_corpus <- tm_map(train_corpus, removeNumbers)\n## Convert text to lower case\ntrain_corpus <- tm_map(train_corpus, content_transformer(tolower))\n## Remove stop words\ntrain_corpus <- tm_map(train_corpus, content_transformer(removeWords), stopwords(\"english\"))\n## Stemming\ntrain_corpus <- tm_map(train_corpus, stemDocument)\n## Remove multiple whitespaces\ntrain_corpus <- tm_map(train_corpus, stripWhitespace)\n# Extract only the simplified text from the complex train_corpus object\ndataCT$clinicalNotes <- unlist(lapply(train_corpus, `[[`, 1))\n\n# Split the data 80:20\ntrain_set_ind <- sample(nrow(dataCT), floor(nrow(dataCT)*0.8)) # 80:20 split training:testing\ntrain_data <- dataCT[train_set_ind , ]\ntest_data <- dataCT[-train_set_ind , ]  \n\nnum_words <- 10000\nmax_length <- 300\ntext_vectorization <- layer_text_vectorization(max_tokens = num_words, output_sequence_length = max_length)\n\n# # `adapt()` the Clinical Notes Text Vectorization layer. Calling adapt allows the input layer to learn about \n# # the unique Medical Text in this dataset and assign an integer value for each word\n# text_vectorization %>%  adapt(train_data$clinicalNotes)\n# \n# # Confirm the Medical Notes vocabulary is in the text vectorization layer.\n# get_vocabulary(text_vectorization)\n# \n# # Input Layer shape - the text vectorization layer transforms it’s inputs\n# trainDataX <- text_vectorization(matrix(train_data$clinicalNotes, ncol = 1))\n# trainDataY_one_hot_labels <- to_categorical(train_data$surgLabel, num_classes = 2)\n\ntext_vectorization %>% adapt(train_data$clinicalNotes)\n\n# Define and fit the model - the input data consists of an array of word-indices. \n# The predicted labels are either 0 or 1.\n# The classifier is based on sequentially stacking the network layers\n# The first embedding layer takes the integer-encoded vocabulary and looks up the embedding vector for each word-index. \n# These vectors are learned as the model trains. \n# The vectors add a dimension to the output array. The resulting dimensions are: (batch, sequence, embedding).\n# A global_average_pooling_1d layer returns a fixed-length output vector for each example by averaging over the sequence dimension. \n# This allows the model to handle *variable-length* inputs\n# The fixed-length output vector is piped through a fully-connected (dense) layer with 16 hidden units.\n# The last output layer is densely connected with a single output node. \n# Sigmoid activation function yields a probability between 0 and 1 indicating the confidence of the binary level.",
      "line_count": 74
    },
    {
      "section": "Transfer Learning",
      "code": "# 1. Define a new fresh model1 de novo\n# input <- layer_input(input_shape = input_shape = c(300))  # For numerical input, e.g., trainDataX\n# library(reticulate)\n# reticulate::repl_python()\n# use_condaenv(condaenv = \"pytorch_env\", required = TRUE)\n\ninput <- layer_input(shape = c(1), dtype = \"string\")   # for raw text input as string, needs to match exp next layer\noutput <- input %>% \n  text_vectorization() %>% \n  layer_embedding(input_dim = num_words + 1, output_dim = 32) %>%\n  layer_global_average_pooling_1d() %>%\n  layer_dense(units = 16, activation = \"relu\") %>%\n  layer_dropout(0.5) %>% \n  layer_dense(units = 1, activation = \"sigmoid\")\nmodel1 <- keras_model(input, output)\n\nmodel1 %>% compile(\n  optimizer = 'adam',\n  loss = 'binary_crossentropy',\n  metrics = list('accuracy')\n)\n\nhistory <- model1 %>% fit(train_data$clinicalNotes,\n          as.numeric(train_data$surgLabel),  \n          epochs = 10, batch_size = 512, validation_split = 0.2, verbose=2)\n\n# Evaluate the model1 performance\nresults <- model1 %>% evaluate(test_data$clinicalNotes, as.numeric(test_data$surgLabel), verbose = 0)\nresults",
      "line_count": 29
    },
    {
      "section": "Transfer Learning",
      "code": "#  2. Naive - out-of-the-box prior-model assessment (without any retraining)\n# Transfer Learning based on nnlm-en-dim128 (prior model) Define only output layer structure\nlibrary(tfhub)\nlibrary(keras) \n####### May have to remove outputs from prior runs!!!!! ########################\n# remove folders here: C:\\Users\\IvoD\\AppData\\Local\\Temp\\tfhub_modules ....#####\nmodel2 <- keras_model_sequential() %>% \n  layer_hub(\n    handle = \"https://tfhub.dev/google/tf2-preview/nnlm-en-dim128/1\",\n    input_shape = list(),\n    dtype = tf$string,\n    trainable = FALSE   # Set to TRUE for full model retraining, we use FALSE for quick transfer learning\n  ) %>%\n  \n  layer_dense(units = 1, activation = \"sigmoid\")  # add the binary labeling output layer format\nsummary(model2)\nmodel2 %>% compile(\n  optimizer = 'adam',\n  loss = 'binary_crossentropy',\n  metrics = list('accuracy')\n)\n# Just estimate the final 128+1 coefficients of the final layer\nhistory <- model2 %>% fit(\n  train_data$clinicalNotes, train_data$surgLabel, \n  epochs = 5, ### increase epochs for better performance\n  batch_size = 128\n)\n\n# Assess performance\nscore <- model2 %>% evaluate(test_data$clinicalNotes, test_data$surgLabel)\nprint(score)\ny_pred <- ifelse((model2 %>% predict(test_data$clinicalNotes)) >0.4, 1, 0)\ntable(y_pred, test_data$surgLabel)",
      "line_count": 33
    },
    {
      "section": "Transfer Learning",
      "code": "# 3. Transfer Learning based on the nnlm-en-dim128 (prior model) Define expanded DNN model structure + 4 layers\nmodel3 <- keras_model_sequential() %>% \n  layer_hub(\n    handle = \"https://tfhub.dev/google/tf2-preview/nnlm-en-dim128/1\",\n    input_shape = list(),\n    dtype = tf$string,\n    trainable = FALSE   # Set to TRUE for full model retraining, we use FALSE for quick transfer learning\n  ) %>% \n  # modify default pre-trained model by adding 4 extra layers at the end tuned for our clinical text (medical notes)\n  layer_dense(units = 64, activation = \"sigmoid\") %>% \n  #layer_dropout(rate = 0.5) %>% \n  layer_dense(units = 32, activation = \"sigmoid\") %>% \n  #layer_dropout(rate = 0.5) %>%\n  layer_dense(units = 16, activation = \"sigmoid\") %>% \n  #layer_dropout(rate = 0.5) %>%\n  layer_dense(units = 1, activation = \"sigmoid\")\n#   layer_dense(units = 16, activation = \"relu\") %>% \n#   layer_dense(units = 6, activation = \"relu\") %>% \n#   layer_dense(units = 1, activation = \"sigmoid\")\n\nsummary(model3)\nmodel3 %>% compile(\n  optimizer = 'adam',\n  loss = 'binary_crossentropy',\n  metrics = list('accuracy')\n)\n\nhistory <- model3 %>% fit(\n  train_data$clinicalNotes, train_data$surgLabel, \n  epochs = 10, ### increase epochs for better performance\n  batch_size = 128\n)\n\n# Assess performance\nscore <- model3 %>% evaluate(test_data$clinicalNotes, test_data$surgLabel)\nprint(score)\ny_pred <- ifelse((model3 %>% predict(test_data$clinicalNotes)) >0.48, 1, 0)\ntable(y_pred, test_data$surgLabel)",
      "line_count": 38
    },
    {
      "section": "Transfer Learning",
      "code": "# 4. Full-scale Transfer learning using the skeleton of the pre-trained model, but estimating all parameters \nmodel4 <- keras_model_sequential() %>% \n  layer_hub(\n    handle = \"https://tfhub.dev/google/tf2-preview/nnlm-en-dim128/1\",\n    input_shape = list(),\n    dtype = tf$string,\n    trainable = TRUE   # Set to FALSE for simple TL-model retraining, we use TRUE for full-transfer learning\n  ) %>% \n  # modify default pre-trained model by adding 4 extra layers at the end tuned for our clinical text (medical notes)\n  layer_dense(units = 64, activation = \"sigmoid\") %>% \n  #layer_dropout(rate = 0.5) %>% \n  layer_dense(units = 32, activation = \"sigmoid\") %>% \n  #layer_dropout(rate = 0.5) %>%\n  layer_dense(units = 16, activation = \"sigmoid\") %>% \n  #layer_dropout(rate = 0.5) %>%\n  layer_dense(units = 1, activation = \"sigmoid\")\n#   layer_dense(units = 16, activation = \"relu\") %>% \n#   layer_dense(units = 6, activation = \"relu\") %>% \n#   layer_dense(units = 1, activation = \"sigmoid\")\n\nsummary(model4)\nmodel4 %>% compile(\n  optimizer = 'adam',\n  loss = 'binary_crossentropy',\n  metrics = list('accuracy')\n)\n\nhistory <- model4 %>% fit(\n  train_data$clinicalNotes, train_data$surgLabel, \n  epochs = 10, ### increase epochs for better performance\n  batch_size = 128\n)\n\n# Assess performance\nscore <- model4 %>% evaluate(test_data$clinicalNotes, test_data$surgLabel)\nprint(score)\ny_pred <- ifelse((model4 %>% predict(test_data$clinicalNotes)) >0.47, 1, 0)\ntable(y_pred, test_data$surgLabel)",
      "line_count": 38
    },
    {
      "section": "Transfer Learning",
      "code": "# Evaluate the model\n# Examine the model performance. \n# mind the trajectories of the Loss (representing the error), \n# lower values are better), and accuracy, high values are better\nlibrary(plotly)\n\nplot_ly(x = ~c(1:history$params$epochs),  y = ~history$metrics$loss,\n        type = \"scatter\", mode=\"markers+lines\", name=\"Loss\") %>% \n  add_trace(x = ~c(1:history$params$epochs),  y = ~history$metrics$accuracy,\n        type = \"scatter\", mode=\"markers+lines\", name=\"Accuracy\") %>%\n  layout(title=\"DNN Training Performance\", xaxis=list(title=\"epoch\"),\n         yaxis=list(title=\"Metric Value\"), legend = list(orientation='h'),\n         hovermode = \"x unified\")\n\n# subplot(pl_loss, pl_acc, nrows=2, shareX = TRUE, titleX = TRUE)",
      "line_count": 15
    },
    {
      "section": "Transfer Learning",
      "code": "library(keras)\n# library(reticulate)\nlibrary(tfhub)\nlibrary(tfds)\nlibrary(tfdatasets)\nlibrary(utf8)\n\n# use_condaenv(\"r-reticulate\", required = TRUE)\ntensorflow::tf_config()\npy_module_available(\"tensorflow_hub\")",
      "line_count": 10
    },
    {
      "section": "Transfer Learning",
      "code": "library(stringi)\ndataCT <- read.csv('https://umich.instructure.com/files/21152999/download?download_frd=1', header=T) \n\ndataCT$description <- stri_encode(dataCT$description, \"\", \"UTF-8\") \ndataCT$transcription <- stri_encode(dataCT$transcription, \"\", \"UTF-8\") \n\n# Concatenate Transcriptions and Descriptions into one string/character: clinicalNotes\ndataCT$clinicalNotes <- paste(dataCT$description, dataCT$transcription)\n\nconvert_specialty <- list()\nkeys <- unique(dataCT$medical_specialty)\nmedical_specialtyNames <- dataCT$medical_specialty\nvalues <- 1:length(keys)\nfor(i in 1:length(keys)) { convert_specialty[keys[i]] <- values[i] }\nspecialty <- c()\nfor (i in 1:length(dataCT$medical_specialty)){\n  specialty[i] <- as.numeric(convert_specialty[dataCT$medical_specialty[i]])\n}\n\ndataCT$medical_specialty <- specialty\ndataCT$medical_specialty <- matrix(dataCT$medical_specialty,\n                                   nrow = length(dataCT$medical_specialty), ncol = 1)\n\n# Convert labels to categorical one-hot encoding\none_hot_SpecialtyLabels <- to_categorical(dataCT$medical_specialty,\n               num_classes = length(unique(dataCT$medical_specialty))+1)\none_hot_SpecialtyLabels <- one_hot_SpecialtyLabels[, -1] # remove empty column 1\n# library(keras)\n# labels <- to_categorical\n# sum(one_hot_SpecialtyLabels)  [1] 4999\n\nnum_words <- 10000\nmax_length <- 300\ntext_vectorization <- layer_text_vectorization(max_tokens = num_words, output_sequence_length = max_length)\n\ntrain_set_ind <- sample(nrow(dataCT), floor(nrow(dataCT)*0.8)) # 80:20 plot training:testing\ntrain_data <- dataCT[train_set_ind, ]\ntest_data <- dataCT[-train_set_ind, ]\none_hot_SpecialtyLabels_trainY <- one_hot_SpecialtyLabels[train_set_ind, ]\none_hot_SpecialtyLabels_testY  <- one_hot_SpecialtyLabels[-train_set_ind, ]\n \n# input <- layer_input(shape = c(1), dtype = \"string\")   # for raw text input as string, needs to match exp next layer\n# output <- input %>% \n#   text_vectorization() %>% \n#   layer_embedding(input_dim = num_words + 1, output_dim = 256) %>%\n#   layer_global_average_pooling_1d() %>%\n#   layer_dense(units = 256, activation = \"relu\") %>%\n#   layer_dropout(0.25) %>% \n#   layer_dense(units = 128, activation = \"relu\") %>%\n#   layer_dropout(0.25) %>% \n#   layer_dense(units = 64, activation = \"relu\") %>%\n#   # layer_dropout(0.25) %>% \n#   layer_dense(units = length(keys), activation = 'softmax')\n# model2 <- keras_model(input, output)\n# \n# model2 %>% compile(\n#   loss = 'categorical_crossentropy', \n#   optimizer = optimizer_sgd(learning_rate = 0.01, decay = 1e-6, momentum = 0.9, nesterov = TRUE),\n#   metrics = list('accuracy')\n# )\n# \n# history2 <- model2 %>% fit(train_data$clinicalNotes, one_hot_SpecialtyLabels_trainY,  \n#                   epochs = 10, batch_size = 512, validation_split = 0.2, verbose=2)\n# \n# # Evaluate the model2 performance\n# results2 <- model2 %>% evaluate(test_data$clinicalNotes, one_hot_SpecialtyLabels_testY, verbose = 2)\n# results2  \n# \n# score <- model2 %>% evaluate(test_data$clinicalNotes, one_hot_SpecialtyLabels_testY)\n# print(score)\n# y_pred <- model2 %>% predict(test_data$clinicalNotes)\n# head(apply(y_pred, 1, which.max))  # table(apply(y_pred, 1, which.max))\n# # hist(y_pred[,8])\n# table(y_pred, test_data$medical_specialty)\n# \n# ============================================\n  \nmodel3 <- keras_model_sequential() %>% \n  layer_hub(\n    handle = \"https://tfhub.dev/google/tf2-preview/gnews-swivel-20dim/1\",\n    input_shape = list(),\n    dtype = tf$string,\n    trainable = TRUE\n  ) %>% \n  layer_dense(units = 256, activation = \"relu\") %>%\n  layer_dropout(0.25) %>% \n  layer_dense(units = 128, activation = \"relu\") %>%\n  layer_dropout(0.25) %>% \n  layer_dense(units = 64, activation = \"relu\") %>%\n  # layer_dropout(0.25) %>% \n  layer_dense(units = length(keys), activation = 'softmax')\n\nsummary(model3)\n\nmodel3 %>% compile(\n  loss = 'categorical_crossentropy', \n  optimizer = optimizer_sgd(learning_rate = 0.01, momentum = 0.9, nesterov = TRUE),\n  metrics = list('accuracy')\n)\n\nhistory3 <- model3 %>% fit(train_data$clinicalNotes, one_hot_SpecialtyLabels_trainY,  \n                  epochs = 100, batch_size = 512, validation_split = 0.2, verbose=2)\n\nresults3 <- model3 %>% evaluate(test_data$clinicalNotes, one_hot_SpecialtyLabels_testY, verbose = 2)\nprint(paste0(\"Mind that the testing-case performance metrics (Loss=\", round(results3[\"loss\"], 3), \n             \" and Accuracy=\", round(results3[\"accuracy\"], 3),\n             \") of the DNN text classification reflect results of \",\n             length(keys), \" medical specialties (classes), not a binary classification!\")) \n\nscore <- model3 %>% evaluate(test_data$clinicalNotes, one_hot_SpecialtyLabels_testY)\nprint(score)\ny_pred <- model3 %>% predict(test_data$clinicalNotes)\nhead(apply(y_pred, 1, which.max))  # table(apply(y_pred, 1, which.max))\ny_pred_class <- apply(y_pred, 1, which.max)\n# hist(y_pred[,8])\ntable(y_pred_class, test_data$medical_specialty[,1])\n# DT::datatable(matrix(table(y_pred_class, test_data$medical_specialty[,1]),40,40) )\n\nheat <- matrix(0, 40, 40)\nfor ( i in 1:length(test_data$clinicalNotes)) { \n  heat[test_data$medical_specialty[i, 1], y_pred_class[i]] =  \n    heat[test_data$medical_specialty[i, 1], y_pred_class[i]] + 1 \n}\n\nplot_ly(x =~keys, y = ~keys, z = ~heat, name=\"Model Performance\",\n        hovertemplate = paste('<i>Matching</i>: %{z:.0f}', \n                              '<br><b>True</b>: %{x}<br>', '<b>Pred</b>: %{y}'),\n        colors = 'Reds', type = \"heatmap\") %>% \n  layout(title=\"Predicated Classes vs. True Clinical Units\", \n         xaxis=list(title=\"Actual Class\"), yaxis=list(title=\"Predicted Class\"))",
      "line_count": 130
    },
    {
      "section": "Transfer Learning",
      "code": "# report the structure of the data\n# str(dataCT)",
      "line_count": 2
    },
    {
      "section": "Transfer Learning",
      "code": "train_set_ind <- sample(nrow(dataCT), floor(nrow(dataCT)*0.8)) # 80:20 plot training:testing\ntrain_data <- dataCT[train_set_ind, ]\ntest_data <- dataCT[-train_set_ind, ]\none_hot_SpecialtyLabels_trainY <- one_hot_SpecialtyLabels[train_set_ind, ]\none_hot_SpecialtyLabels_testY  <- one_hot_SpecialtyLabels[-train_set_ind, ]",
      "line_count": 5
    },
    {
      "section": "Transfer Learning",
      "code": "dataCT_train_test <- list(\n  train=as.data.frame(cbind(x=train_data$clinicalNotes, y=as.numeric(train_data$medical_specialty))),\n  test=as.data.frame(cbind(x=test_data$clinicalNotes, y=as.numeric(test_data$medical_specialty))))",
      "line_count": 3
    },
    {
      "section": "Transfer Learning",
      "code": "# Define the training data DF as TF tensor object\nlibrary(tfdatasets)\ndataCT_train_tf <- tensor_slices_dataset(dataCT_train_test$train) %>% \n  dataset_map(function(x) {\n    x$x <- tf$cast(x$x, tf$string) # medical notes\n    x$y <- tf$strings$to_number(x$y, tf$int64)\n    unname(x)\n  })  ",
      "line_count": 8
    },
    {
      "section": "Transfer Learning",
      "code": "# Define the testing data DF as TF tensor object\ndataCT_test_tf <- tensor_slices_dataset(dataCT_train_test$test) %>% \n  dataset_map(function(x) {\n    x$x <- tf$cast(x$x, tf$string) # medical notes\n    x$y <- tf$strings$to_number(x$y, tf$int64)   # medical_specialty label\n    #x$y <- tf$cast(x$y, tf$string)\n    unname(x)\n  }) ",
      "line_count": 8
    },
    {
      "section": "Transfer Learning",
      "code": "library(magrittr)\nfirst <- dataCT_train_tf %>%\n  dataset_batch(3999L) %>% \n  reticulate::as_iterator() %>%\n  reticulate::iter_next()",
      "line_count": 5
    },
    {
      "section": "Transfer Learning",
      "code": "# TRAINING\n# xtrain <- matrix(NA, nrow = 3999, ncol=128, byrow= TRUE)\n# embedding_layer <- tfhub::layer_hub(handle =\"https://tfhub.dev/google/tf2-preview/nnlm-en-dim128/1\")\n# for (i in 1:3999){\n#   xtrain[i, ] <- embedding_layer(first[[1]])$numpy()[i,]\n# }\nxtrain <- embedding_layer(first[[1]])$numpy()\nytrain <- train_data$medical_specialty",
      "line_count": 8
    },
    {
      "section": "Transfer Learning",
      "code": "# TESTING\nsecond <- dataCT_test_tf %>%\n  dataset_batch(1000) %>% \n  reticulate::as_iterator() %>%\n  reticulate::iter_next()",
      "line_count": 5
    },
    {
      "section": "Transfer Learning",
      "code": "# xtest <- matrix(NA, nrow = 1000, ncol=128, byrow= TRUE)\n# for (i in 1:1000){\n#   xtest[i, ] <- embedding_layer(second[[1]])$numpy()[i,]\n# }\nxtest <- embedding_layer(second[[1]])$numpy()\nytest <- test_data$medical_specialty",
      "line_count": 6
    },
    {
      "section": "Transfer Learning",
      "code": "library(keras)\nlabels <- to_categorical(specialty)\nlabels <- labels[,-1]\nvectorize_sequences <- function(sequences, dimension = 40) {\n  # Creates an all-zero matrix of shape (length(sequences), dimension)\n  results <- matrix(0L, nrow = length(sequences), ncol = dimension,\n                    dimnames=list(c(1:length(sequences)), keys))\n  for (i in 1:length(sequences))\n    # Sets specific indices of results[i] to 1s\n    results[i, sequences[i]] <- 1 \n  results\n}\n\n# ytrainlabels <- vectorize_sequences(ytrain)\n# # colnames(ytrainlabels) <- keys\n# ytestlabels <- vectorize_sequences(ytest)\n# # colnames(ytestlabels) <- keys\n\nytrainlabels <- vectorize_sequences(labels)",
      "line_count": 19
    },
    {
      "section": "Transfer Learning",
      "code": "# ytrainlabels <- labels[train_set_ind, ]\n# ytestlabels <- labels[-train_set_ind,]\nind <- sample(nrow(xtrain), floor(nrow(xtrain)*0.8)) # 80:20 plot training:validation\nxtrain1 <- xtrain[ind, ]\nxval <- xtrain[-ind, ]\n\nytrainlabels1 <- ytrainlabels[ind,]\nyval <- ytrainlabels[-ind, ]",
      "line_count": 8
    },
    {
      "section": "Transfer Learning",
      "code": "model <- keras_model_sequential() \nmodel %>% \n  layer_dense(units = 512, activation = 'relu', input_shape = c(128)) %>% \n  layer_dropout(rate = 0.5) %>% \n  layer_dense(units = 128, activation = 'relu') %>% \n  layer_dropout(rate = 0.5) %>% \n  layer_dense(units = 40, activation = 'softmax') %>% \n  compile(\n    loss = 'categorical_crossentropy',\n    optimizer = optimizer_sgd(learning_rate = 0.1, decay = 1e-6, momentum = 0.8, nesterov = TRUE),\n    metrics = c('accuracy')     \n  )",
      "line_count": 12
    },
    {
      "section": "Transfer Learning",
      "code": "summary(model)",
      "line_count": 1
    },
    {
      "section": "Transfer Learning",
      "code": "history <- model %>% fit(xtrain1, ytrainlabels1, epochs=50, batch_size=512, validation_data = list(xval, yval))",
      "line_count": 1
    },
    {
      "section": "Transfer Learning",
      "code": "pl_loss <- plot_ly(x = ~c(1:history$params$epochs),  y = ~history$metrics$loss,\n                   type = \"scatter\", mode=\"markers+lines\", name=\"Loss\") %>% \n  layout(title=\"DNN Training Performance\", xaxis=list(title=\"epoch\"),\n         yaxis=list(title=\"Metric Value\"), legend = list(orientation='h'))\n\npl_acc <- plot_ly(x = ~c(1:history$params$epochs),  y = ~history$metrics$accuracy,\n                  type = \"scatter\", mode=\"markers+lines\", name=\"Accuracy\") %>% \n  layout(title=\"40-Class DNN Training & Validation Performance\", xaxis=list(title=\"epoch\"),\n         yaxis=list(title=\"Metric Value\"), legend = list(orientation='h'))\n\nsubplot(pl_loss, pl_acc, nrows=2, shareX = TRUE, titleX = TRUE)",
      "line_count": 11
    },
    {
      "section": "Transfer Learning",
      "code": "score <- model %>% evaluate(xtest, ytestlabels, batch_size = 512)\nscore\n\n# Heatmap showing the relation between the 40 true hospital unit labels and their predicted counterparts\ny_pred <- round(model %>% predict(xtest), 1)\npred_class <- c()\nfor (i in 1:1000) { pred_class[i] <- which.max(y_pred[i,]) }\nheat <- matrix(0, 40, 40)\nfor ( i in 1:1000) { heat[ytest[i], pred_class[i]] =  heat[ytest[i], pred_class[i]] + 1 }\n\nplot_ly(x =~names(convert_specialty), y = ~names(convert_specialty), z = ~heat,  colors = 'Reds', type = \"heatmap\") %>% \n  layout(title=\"Predicated Classes vs. True Clinical Units\", \n         xaxis=list(title=\"Actual Class\"), yaxis=list(title=\"Predicted Class\"))",
      "line_count": 13
    },
    {
      "section": "Transfer Learning",
      "code": "# Load Movie Reviews (50K)\n# split the entire dataset into a list of 3 objects:\n# imdb[[1]]=training_set, imdb[[2]]=testing_set, imdb[[3]]=validation_set\nimdb <-\n    tfds::tfds_load\t(\n    \"imdb_reviews:1.0.0\",\n    split = list(\"train[:60%]\", \"train[-40%:]\", \"test\"),\n    as_supervised = TRUE\n)\n\n# Install keras package if you haven't already\n\n\n# Load the keras package\n# library(keras)\n# \n# # Load the IMDb dataset\n# imdb <- dataset_imdb(num_words = 10000)\n# \n# # Split the dataset into train, validation, and test sets\n# train_split <- 0.6\n# validation_split <- 0.4\n# \n# # Calculate the number of samples for each split\n# total_samples <- length(imdb$train$x)[1]\n# train_samples <- round(train_split * total_samples)\n# validation_samples <- round(validation_split * total_samples)\n# \n# # Create train, validation, and test sets\n# train_dataset <- list(x = imdb$train$x[1:train_samples], y = imdb$train$y[1:train_samples])\n# validation_dataset <- list(x = imdb$train$x[(train_samples + 1):(train_samples + validation_samples)], y = imdb$train$y[(train_samples + 1):(train_samples + validation_samples)])\n# test_dataset <- imdb$test\n# \n# # Save train, validation, and test datasets into imdb[[1]], imdb[[2]], and imdb[[3]], respectively\n# imdb[[1]] <- train_dataset\n# imdb[[2]] <- validation_dataset\n# imdb[[3]] <- test_dataset\n\n\n\n\n# imdb <- tfds_load(\n#   \"imdb_reviews:1.0.0\",\n#   split = c(\"train[:60%]\", \"train[-40%:]\", \"test\"),\n#   as_supervised = TRUE\n# )\n# summary(imdb)\n\n# tfds_load returns a TensorFlow Dataset, an abstraction representing a list\n# of elements, in which each element consists of one or more components.\n# To access individual elements of a Dataset:\n# \n# library(tfds)\n# library(magrittr)\nfirstBatch <- imdb[[1]] %>%\n  dataset_batch(1) %>% # Used to get only the first example\n  reticulate::as_iterator() %>%\n  reticulate::iter_next()\nstr(firstBatch)\n\n\n# imdb_train_iterator <- as_iterator(imdb[[1]])\n# \n# # Retrieve the first example from the iterator\n# firstBatch <- iter_next(imdb_train_iterator)\n\n# library(magrittr)\n#   firstBatch <- list(\n#     x = imdb$train$x[[1]],\n#     y = imdb$train$y[[1]]\n#   )\n\nreview1 <- as_utf8(as.character(firstBatch[1][[1]]$numpy()[1][[1]])) # get text-review (string)\nlabel1 <- as.numeric(firstBatch[2][[1]]$numpy())    # get binary class (0/1)\n\nembedding_layer <- layer_hub(\n  handle =\"https://tfhub.dev/google/tf2-preview/nnlm-en-dim128/1\")  \n\nembedding_layer(firstBatch[[1]])\n\n# build the complete model\nmodel <- keras_model_sequential() %>% \n  layer_hub(\n    handle = \"https://tfhub.dev/google/tf2-preview/nnlm-en-dim128/1\",\n    input_shape = list(),\n    dtype = tf$string,\n    trainable = TRUE\n  ) %>% \n  layer_dense(units = 16, activation = \"relu\") %>% \n  layer_dense(units = 8, activation = \"relu\") %>% \n  layer_dense(units = 1, activation = \"sigmoid\")\nsummary(model)\n\n# compile model\nmodel %>% \n  compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=\"accuracy\")\n\n# model training\nhistory <- model %>% \n  fit(\n    imdb[[1]] %>% dataset_shuffle(10000) %>% dataset_batch(512),\n    epochs = 4,  # for convergence, use larger number of epochs (e.g., 20+)\n    validation_data = imdb[[2]] %>% dataset_batch(512), verbose = 2)\n\nlibrary(plotly)\n# plot performance\npl_loss <- plot_ly(x = ~c(1:history$params$epochs),  y = ~history$metrics$loss,\n        type = \"scatter\", mode=\"markers+lines\", name=\"Loss\") %>% \n  add_trace(x = ~c(1:history$params$epochs),  y = ~history$metrics$val_loss,\n        type = \"scatter\", mode=\"markers+lines\", name=\"Validation Loss\") %>%\n  layout(title=\"DNN Training/Validation Performance\", xaxis=list(title=\"epoch\"),\n         yaxis=list(title=\"Metric Value\"), legend = list(orientation='h'),\n         hovermode = \"x unified\")\n\npl_acc <- plot_ly(x = ~c(1:history$params$epochs),  y = ~history$metrics$accuracy,\n        type = \"scatter\", mode=\"markers+lines\", name=\"Accuracy\") %>% \n  add_trace(x = ~c(1:history$params$epochs),  y = ~history$metrics$val_accuracy,\n        type = \"scatter\", mode=\"markers+lines\", name=\"Validation Accuracy\") %>%\n  layout(title=\"DNN Training/Validation Performance\", xaxis=list(title=\"epoch\"),\n         yaxis=list(title=\"Metric Value\"), legend = list(orientation='h'),\n         hovermode = \"x unified\")\n\nsubplot(pl_loss, pl_acc, nrows=2, shareX = TRUE, titleX = TRUE)\n# model evaluation on testing data\nmodel %>% \n  evaluate(imdb[[3]] %>% dataset_batch(512), verbose = 0)",
      "line_count": 126
    },
    {
      "section": "Transfer Learning",
      "code": "# If necessary, download the U-Net package, before you load it into R\n# remotes::install_github(\"r-tensorflow/unet\")\nlibrary(tfdatasets)\nlibrary(tfds)\nlibrary(tfhub)\nlibrary(tfruns)\nlibrary(torch)\n# torch::install_torch()\n\n# remotes::install_github(\"r-tensorflow/unet\")\nlibrary(unet)\nlibrary(tibble)\n\n# The u-Net call takes additional parameters, e.g., number of downsizing blocks, number of filters to start with, \n# number of classes to identify; # ?unet provides details. For instance, we can specify the shape\n# of the input images we will be segmenting tumors for: 256*256 3-channel RGB images.\nmodel <- unet(input_shape = c(256, 256, 3))\n\n# to print the model as text output, run:\n# model\n# Results: # Trainable params: 31,031,745",
      "line_count": 21
    },
    {
      "section": "Transfer Learning",
      "code": "# If you need to start a clean fresh run, remove all old files first! Be careful with this! set eval=T in all R-blocks!\n##### First check > list.files(\"/data/\")\n##### do.call(file.remove, list(list.files(\"/data\", full.names = TRUE)))\n##### unlink(\"/data/*\", recursive=TRUE, force=TRUE)\n\nlibrary(httr)\npathToZip <- tempfile()\npathToZip<-paste0(pathToZip,\".zip\")\n# \n# \nurl <- \"https://umich.instructure.com/files/21813670/download?download_frd=1\"\nresponse <- GET(url)\n\ncontent_type <- http_type(response)\nprint(content_type)\n\n\nif (content_type == \"application/zip\" || content_type == \"application/x-zip-compressed\") {\n  content <- content(response, \"raw\")\n  writeBin(content, pathToZip)\n} else {\n  stop(\"Unexpected content type received.\")\n}\n\n# download.file(\"https://umich.instructure.com/files/21813670/download?download_frd=1\", pathToZip, mode = \"wb\")\nzip::unzip(pathToZip, files=NULL, exdir = paste0(getwd(),'/data'))\n",
      "line_count": 27
    },
    {
      "section": "Transfer Learning",
      "code": "library(tibble)\nlibrary(rsample)\n\ntrain_dir <- file.path(getwd(),\"data\",\"data\")\nvalid_dir <- file.path(getwd(),\"data\",\"mri_valid\")\n\nlibrary(magick)   # Needed for TIFF --> PNG image conversion and other image processing tasks",
      "line_count": 7
    },
    {
      "section": "Transfer Learning",
      "code": "# check if ReadMe file is accessible\n# file.rename(\"/data/ReadMe_TCGA_MRI_Segmentation_Data_Phenotypes.txt\", train_dir)\n\n# Import the meta-data\n# meta_data <- read.csv(paste0(getwd(),\"//data//TCGA_MRI_Segmentation_Data_Phenotypes.csv\"))\n\n\nfile_path <- file.path(getwd(), \"data\", \"TCGA_MRI_Segmentation_Data_Phenotypes.csv\")\n\n# Read the CSV file\nmeta_data <- read.csv(file_path)\n\n# note that these are relative file/directory names. To see the complete local path\n# tempdir(); getwd()\n\n# Create a validation folder\ndir.create(valid_dir)\n\n# Check all n=110 patients are accessible\npatients <- list.dirs(train_dir, recursive = FALSE)\nlength(patients)\n\n# Randomly select 20 Patients for validation, remaining 90=110-20 are for training the DNN model\nvalid_indices <- sample(1:length(patients), 20)\nvalid_indices\npatients[valid_indices] # prints the actual folders where the validation participants' data is\n\n# Extract and Relocate the Validation cases (separate them from training data)\nfor (i in valid_indices) {\n  dir.create(file.path(valid_dir, basename(patients[i])))\n  for (f in list.files(patients[i])) {    \n    file.rename(file.path(train_dir, basename(patients[i]), f), file.path(valid_dir, basename(patients[i]), f))    \n  }\n  unlink(file.path(train_dir, basename(patients[i])), recursive = TRUE) # clean\n}\n\n# Confirm that only 80 patients are left in the standard data folder\n# list all training data imaging files: list.dirs(train_dir, recursive = FALSE)\nlength(list.dirs(train_dir, recursive = FALSE))\n\n# and 30-60 validation cases are in the validation folder\nlength(list.dirs(valid_dir, recursive = FALSE))\n\n# and check validation data\nlength(list.files(valid_dir, recursive = T)) # [1] 1268",
      "line_count": 45
    },
    {
      "section": "Transfer Learning",
      "code": "# Identify the TRAINING and VALIDATION data objects (raw images + tumor masks) as filenames\ndata_train <- tibble(\n  img = grep(list.files(train_dir, full.names = TRUE, pattern = \"tif\", recursive = TRUE),\n        pattern = 'mask', invert = TRUE, value = TRUE),\n  mask = grep(list.files(train_dir, full.names = TRUE, pattern = \"tif\", recursive = TRUE),\n        pattern = 'mask', value = TRUE)\n)\ndata_valid <- tibble(\n  img = grep(list.files(valid_dir, full.names = TRUE, pattern = \"tif\", recursive = TRUE),\n        pattern = 'mask', invert = TRUE, value = TRUE),\n  mask = grep(list.files(valid_dir, full.names = TRUE, pattern = \"tif\", recursive = TRUE),\n        pattern = 'mask', value = TRUE)\n)",
      "line_count": 13
    },
    {
      "section": "Transfer Learning",
      "code": "print(grepl(\"\\\\.tif$\", data_train$img))",
      "line_count": 1
    },
    {
      "section": "Transfer Learning",
      "code": "# If all training + testing data are in one folder, split them by:\n#  data <- initial_split(data_train, prop = 0.8)\n\n# convert all Training Data: TIFF images and masks to PNG format (for easier TF processing downstream)\nfiles_img_tif <- data_train$img[grepl(\"\\\\.tif$\", data_train$img), drop = TRUE]\ndata_train_img_png <- lapply(files_img_tif,\n      function(x) { \n        # image_write(image_read(x), path = gsub(\".tif$\", \".png\", x), format = \"png\") \n        a = image_convert(image_read(x),  format = \"png\")\n        image_write(a, path = gsub(\".tif$\", \".png\", x), format = \"png\") \n    }\n  )\n\nfiles_mask_tif <- data_train$mask[grepl(\"\\\\.tif$\", data_train$mask), drop = TRUE]\ndata_train_mask_png <- lapply(files_mask_tif, \n     function(x) { \n       # image_write(image_read(x), path = gsub(\".tif$\", \".png\", x), format = \"png\") \n       a = image_convert(image_read(x),  format = \"png\")\n       image_write(a, path = gsub(\".tif$\", \".png\", x), format = \"png\") \n    }\n  )\n\n# Similarly convert all Validation Data\n# convert all TIFF images and masks to PNG format (for easier TF processing downstream)\nfiles_valid_img_tif <- data_valid$img[grepl(\"\\\\.tif$\", data_valid$img), drop = TRUE]\ndata_valid_img_png <- lapply(files_valid_img_tif,\n      function(x) { \n        # image_write(image_read(x), path = gsub(\".tif$\", \".png\", x), format = \"png\") \n        a = image_convert(image_read(x),  format = \"png\")\n        image_write(a, path = gsub(\".tif$\", \".png\", x), format = \"png\") \n    }\n  )\n\nfiles_valid_mask_tif <- data_valid$mask[grepl(\"\\\\.tif$\", data_valid$mask), drop = TRUE]\ndata_valid_mask_png <- lapply(files_valid_mask_tif, \n     function(x) { \n       # image_write(image_read(x), path = gsub(\".tif$\", \".png\", x), format = \"png\") \n       a = image_convert(image_read(x),  format = \"png\")\n       image_write(a, path = gsub(\".tif$\", \".png\", x), format = \"png\") \n    }\n  )\n\n# Check that the TIF --> PNG conversion worked, inspect one case\nhead(list.files(\"/data/data/TCGA_HT_A61A_20000127\"))\n# data_valid  # check root directory\n\n# Inspect some of the images/masks\n# image_info(image_read(data_train_img_png[[3]]))\n# image_write(image_read(data_train$img[3]), format = \"tiff\")\n# image_write(image_read(data_train$img[3]), path = paste0(data_train$img[3], \".png\"), format = \"png\")\n# a <- image_read(paste0(data_train$img[3], \".png\"))\n\n# list.files(train_dir) \n# To clean previous file references\n# # delete a directory -- must add recursive = TRUE\n# unlink(\"/data\", recursive = TRUE); # Clean space # gc(full=T)",
      "line_count": 56
    },
    {
      "section": "Transfer Learning",
      "code": "# Compute a new binary outcome variable 1=Brain Tumor (mask has at least 1 white pixel), 0=Normal Brain, no white pixels in the mask\npos_neg_diagnosis <- sapply(data_train$mask,\n     function(x) {   value = max(imager::magick2cimg(image_read(x)))\n         ifelse (value > 0, 1, 0)  }\n  )\ntable(pos_neg_diagnosis)   #; head(data_train)\n# pos_neg_diagnosis\n#    0    1 \n# 2046 1103 \n\n# Add the normal vs. cancer label to training and testing datasets\ndata_train$label <- pos_neg_diagnosis\n\npos_neg_diagnosis_valid <- sapply(data_valid$mask,\n     function(x) {   value = max(imager::magick2cimg(image_read(x)))\n         ifelse (value > 0, 1, 0)  }\n  )\ntable(pos_neg_diagnosis_valid)\ndata_valid$label <- pos_neg_diagnosis_valid\n# head(data_valid)",
      "line_count": 20
    },
    {
      "section": "Transfer Learning",
      "code": "# # First check that all brain imaging data is already downloaded and unzipped, if not, see the \"Data Import\" section above\n# \n# # train_dir <- \"/data/data\"\n# # valid_dir <- \"/data/mri_valid\"\n# #\n# # library(magick)   # Needed for TIFF --> PNG image conversion and other image processing tasks\n# #\n# # # check if ReadMe file is accessible\n# # #file.rename(\"/data/ReadMe_TCGA_MRI_Segmentation_Data_Phenotypes.txt\", train_dir)\n# # # Import the meta-data\n# # meta_data <- read.csv(\"/data/TCGA_MRI_Segmentation_Data_Phenotypes.csv\")\n# \n# # note that these are relative file/directory names. To see the complete local path\n# # tempdir(); getwd()\n# \n# # Create a validation folder\n# # dir.create(valid_dir)\n# \n# # Check all n=110 = 90+20 patients are accessible\n# patients <- list.dirs(train_dir, recursive = FALSE)\n# length(patients)\n# \n# # Confirm that only 80 patients are left in the standard data folder\n# # list all training data imaging files: list.dirs(train_dir, recursive = FALSE)\n# length(list.dirs(train_dir, recursive = FALSE))\n# \n# # and 20-70 validation cases are in the validation folder\n# length(list.dirs(valid_dir, recursive = FALSE))\n# \n# # and check validation data\n# length(list.files(valid_dir, recursive = T))\n# \n# library(tibble)\n# # Identify the TRAINING and VALIDATION data objects (raw images + tumor masks) as filenames\n# data_train <- tibble(\n#   img = grep(list.files(train_dir, full.names = TRUE, pattern = \"png\", recursive = TRUE),\n#         pattern = 'mask', invert = TRUE, value = TRUE),\n#   mask = grep(list.files(train_dir, full.names = TRUE, pattern = \"png\", recursive = TRUE),\n#         pattern = 'mask', value = TRUE)\n# )\n# data_valid <- tibble(\n#   img = grep(list.files(valid_dir, full.names = TRUE, pattern = \"png\", recursive = TRUE),  # or \"tif\"\n#         pattern = 'mask', invert = TRUE, value = TRUE),\n#   mask = grep(list.files(valid_dir, full.names = TRUE, pattern = \"png\", recursive = TRUE),\n#         pattern = 'mask', value = TRUE)\n# )\n# \n# # library(rsample)\n# #\n# # # Compute a new binary outcome variable 1=Brain Tumor (mask has at least 1 white pixel), 0=Normal Brain, no white pixels in the mask\n# pos_neg_diagnosis <- sapply(data_train$mask,\n#      function(x) {   value = max(imager::magick2cimg(image_read(x)))\n#          ifelse (value > 0, 1, 0)  }\n#   )\n# table(pos_neg_diagnosis)   #; head(data_train)\n# # pos_neg_diagnosis\n# #    0    1\n# # 2046 1103\n# \n# # Add the normal vs. cancer label to training and testing datasets\n# data_train$label <- pos_neg_diagnosis\n# \n# pos_neg_diagnosis_valid <- sapply(data_valid$mask,\n#      function(x) {   value = max(imager::magick2cimg(image_read(x)))\n#          ifelse (value > 0, 1, 0)  }\n#   )\n# table(pos_neg_diagnosis_valid)\n# data_valid$label <- pos_neg_diagnosis_valid\n# head(data_valid)",
      "line_count": 69
    },
    {
      "section": "Transfer Learning",
      "code": "# install.packages(torch)\nlibrary(torch)\nlibrary(torchvision)\n\n# data wrangling\nlibrary(tidyverse)\nlibrary(zeallot)   # needed for the piping function \"%<-%\" in \"brain_dataset()\"\n\n# image processing and visualization\nlibrary(magick)\n#library(cowplot)\n\n# dataset loading \nlibrary(pins)\nlibrary(zip)\n\ntorch_manual_seed(1234)\nset.seed(1234)\n\n\n\ntrain_dir <- file.path(getwd(),\"data\",\"data\")\nvalid_dir <- file.path(getwd(),\"data\",\"mri_valid\")\n\n\nbrain_dataset <- dataset(\n  name = \"brain_dataset\",\n  # 1. Initialize\n  initialize = function(img_dir, augmentation_params = NULL, random_sampling = FALSE) {\n    self$images <- tibble(img = grep(list.files(img_dir, full.names = TRUE, \n                                                pattern = \"tif\", recursive = TRUE),\n                                     pattern = 'mask', invert = TRUE, value = TRUE),\n                          mask = grep(list.files(img_dir, full.names = TRUE,\n                                                 pattern = \"tif\", recursive = TRUE),\n                                      pattern = 'mask',value = TRUE)\n                          )\n    self$slice_weights <- self$calc_slice_weights(self$images$mask)\n    self$augmentation_params <- augmentation_params\n    self$random_sampling <- random_sampling\n  },\n  \n  # 2. Load and transform images from files into TF object elements (tensors)\n  .getitem = function(i) {index <- if (self$random_sampling == TRUE) sample(1:self$.length(), 1, prob = self$slice_weights)\n    else i\n    img <- self$images$img[index] %>% image_read() %>% transform_to_tensor() \n    mask <- self$images$mask[index] %>% image_read() %>% transform_to_tensor() %>% transform_rgb_to_grayscale() %>%\n      torch_unsqueeze(1)\n    img <- self$min_max_scale(img)\n    \n    if (!is.null(self$augmentation_params)) {\n      scale_param <- self$augmentation_params[1]\n      c(img, mask) %<-% self$resize(img, mask, scale_param)\n      \n      rot_param <- self$augmentation_params[2]\n      c(img, mask) %<-% self$rotate(img, mask, rot_param)\n      \n      flip_param <- self$augmentation_params[3]\n      c(img, mask) %<-% self$flip(img, mask, flip_param)\n    }\n    list(img = img, mask = mask)\n  },\n  \n  # 3. Save the total number of imaging files\n  .length = function() { nrow(self$images)  },\n  \n  # 4. Estimate 2D image weights: Bigger tumor-masks correspond to higher weights\n  calc_slice_weights = function(masks) {\n    weights <- map_dbl(masks, function(m) {\n      img <- as.integer(magick::image_data(image_read(m), channels = \"gray\"))\n      sum(img / 255)\n    })\n    \n    sum_weights <- sum(weights)\n    num_weights <- length(weights)\n    \n    weights <- weights %>% map_dbl(function(w) {\n      w <- (w + sum_weights * 0.1 / num_weights) / (sum_weights * 1.1)\n    })\n    weights\n  },\n  \n  # 5. Estimate the image intensity range (min, max)\n  min_max_scale = function(x) {\n    min = x$min()$item()\n    max = x$max()$item()\n    x$clamp_(min = min, max = max)\n    x$add_(-min)$div_(max - min + 1e-5)\n    x\n  },\n  \n  # 6. Image tensor shape resizing (when necessary)\n  resize = function(img, mask, scale_param) {\n    img_size <- dim(img)[2]\n    rnd_scale <- runif(1, 1 - scale_param, 1 + scale_param)\n    img <- transform_resize(img, size = rnd_scale * img_size)\n    mask <- transform_resize(mask, size = rnd_scale * img_size)\n    diff <- dim(img)[2] - img_size\n    if (diff > 0) {\n      top <- ceiling(diff / 2)\n      left <- ceiling(diff / 2)\n      img <- transform_crop(img, top, left, img_size, img_size)\n      mask <- transform_crop(mask, top, left, img_size, img_size)\n    } else {\n      img <- transform_pad(img,padding = -c(ceiling(diff/2),floor(diff/2),ceiling(diff/2),floor(diff/2)))\n      mask <- transform_pad(mask, padding = -c(ceiling(diff/2), floor(diff/2),ceiling(diff/2),floor(diff/2)))\n    }\n    list(img, mask)\n  },\n  \n  # 7. Rotation (if/when augmentation is requested)\n  rotate = function(img, mask, rot_param) {\n    rnd_rot <- runif(1, 1 - rot_param, 1 + rot_param)\n    img <- transform_rotate(img, angle = rnd_rot)\n    mask <- transform_rotate(mask, angle = rnd_rot)\n    list(img, mask)\n  },\n  \n  # 8. Flipping (if/when augmentation is requested)\n  flip = function(img, mask, flip_param) {\n    rnd_flip <- runif(1)\n    if (rnd_flip > flip_param) {\n      img <- transform_hflip(img)\n      mask <- transform_hflip(mask)\n    }\n    list(img, mask)\n  }\n)",
      "line_count": 127
    },
    {
      "section": "Transfer Learning",
      "code": "train_ds <- brain_dataset(\n  train_dir,\n  augmentation_params = c(0.05, 15, 0.5),\n  random_sampling = TRUE\n)\n\nlength(train_ds)\n# ~3K\n\nvalid_ds <- brain_dataset(\n  valid_dir,\n  augmentation_params = NULL,\n  random_sampling = FALSE\n)\nlength(valid_ds)\n# ~700",
      "line_count": 16
    },
    {
      "section": "Transfer Learning",
      "code": "\n# if (!require(\"BiocManager\", quietly = TRUE))\n#     install.packages(\"BiocManager\")\n# \n# BiocManager::install(\"EBImage\")\n\nlibrary (plotly)\nrasterPlotly <- function (image, name=\"\", hovermode = NULL) {\n  myPlot <- plot_ly(type=\"image\", z=image, name=name, hoverlabel=name, text=name, \n            hovertext=name, hoverinfo=\"name+x+y\") %>% \n    layout(hovermode = hovermode, xaxis = list(hoverformat = '.1f'), yaxis = list(hoverformat = '.1f'))\n  return(myPlot)\n}\n\n# Training Case 20\nimg_and_mask <- train_ds[20]\nimg <- img_and_mask[[1]]  # 3-channel image\nimg <- img_and_mask[[1]]$permute(c(2, 3, 1)) %>% as.array()  # 3-channel image\nmask <- img_and_mask[[2]]$squeeze() %>% as.array() # tumor mask\nmask <- EBImage::rgbImage(255*mask, 255*mask, 255*mask)  # manually generate a gray scale mask image\n# plot_ly(z=255*bird_images[i+ (j-1)*10,,,], type=\"image\", showscale=FALSE)\n\np1 <- rasterPlotly(image=255*img, name = \"RGB Image\", hovermode = \"y unified\")\np2 <- rasterPlotly(mask, name = \"Tumor Mask\", hovermode = \"y unified\")\nsubplot(p1,p2, shareY = TRUE) %>% layout(title=\"Training Case 20: 3-Channel Image (Left) & Tumor Mask (Right)\")\n\n# Validation Case 18\nimg_and_mask <- valid_ds[18]\nimg <- img_and_mask[[1]]\nmask <- img_and_mask[[2]]\nimg <- img_and_mask[[1]]$permute(c(2, 3, 1)) %>% as.array()  # 3-channel image\nmask <- img_and_mask[[2]]$squeeze() %>% as.array() # tumor mask\nmask <- EBImage::rgbImage(255*mask, 255*mask, 255*mask)  # manually generate a gray scale mask image\n\np1 <- rasterPlotly(image=255*img, name = \"RGB Image\", hovermode = \"y unified\")\np2 <- rasterPlotly(mask, name = \"Tumor Mask\", hovermode = \"y unified\")\nsubplot(p1,p2, shareY = TRUE) %>% layout(title=\"Validation Case 18: 3-Channel Image (Left) & Tumor Mask (Right)\")",
      "line_count": 37
    },
    {
      "section": "Transfer Learning",
      "code": "N <- 7*4\nimg_and_mask <- valid_ds[77]\nimg <- img_and_mask[[1]]\nmask <- img_and_mask[[2]]\n\nimgs <- map (1:N, function(i) {\n  # spatial-scale factor\n  c(img, mask) %<-% train_ds$resize(img, mask, 0.25) \n  c(img, mask) %<-% train_ds$flip(img, mask, 0.3)\n  c(img, mask) %<-% train_ds$rotate(img, mask, 45) \n  \n  img %>%\n    transform_rgb_to_grayscale() %>%\n    as.array() %>%\n    plot_ly(z=., type=\"heatmap\", showscale = FALSE, name=paste0(\"AugmImg=\", i)) %>% \n    layout(showlegend=FALSE,  hovermode = \"y unified\") #,\n          # yaxis = list(scaleratio = 1, scaleanchor = 'x'))\n})\n\n# imgs[[2]] \nimgs %>%\n  subplot(nrows = 7, shareX = TRUE, shareY = TRUE, which_layout=1) %>%\n  layout(title=\"Validation Case 77: Random Rotation/Flop/Scale Image Augmentation\")",
      "line_count": 23
    },
    {
      "section": "Transfer Learning",
      "code": "batch_size <- 25\n# train_dl <- dataloader(train_ds, batch_size)\n# valid_dl <- dataloader(valid_ds, batch_size)\n\ntrain_dl <- train_ds %>% dataloader(batch_size = batch_size, shuffle = TRUE)\nvalid_dl <- valid_ds %>% dataloader(batch_size = batch_size, shuffle = FALSE)",
      "line_count": 6
    },
    {
      "section": "Transfer Learning",
      "code": "# forward(), keeps track of layer outputs seen going “down,” to be added back in going “up.”\nunet <- nn_module(name=\"unet\",\n  initialize = function(channels_in = 3, n_classes = 1, depth = 5, n_filters = 6) {\n    self$down_path <- nn_module_list()\n    prev_channels <- channels_in\n    for (i in 1:depth) {\n      self$down_path$append(down_block(prev_channels, 2^(n_filters+i-1)))\n      prev_channels <- 2^(n_filters+i-1)\n    }\n    \n    self$up_path <- nn_module_list()\n    \n    for (i in ((depth - 1):1)) {\n      self$up_path$append(up_block(prev_channels, 2^(n_filters+i-1)))\n      prev_channels <- 2^(n_filters+i-1)\n    }\n    \n    self$last = nn_conv2d(prev_channels, n_classes, kernel_size = 1)\n  },\n  \n  forward = function(x) {\n    blocks <- list()\n    for (i in 1:length(self$down_path)) {\n      x <- self$down_path[[i]](x)\n      if (i != length(self$down_path)) {\n        blocks <- c(blocks, x)\n        x <- nnf_max_pool2d(x, 2)\n      }\n    }\n    \n    for (i in 1:length(self$up_path)) {  \n      x <- self$up_path[[i]](x, blocks[[length(blocks)-i+1]]$to(device=device))\n    }\n    \n    torch_sigmoid(self$last(x))\n  }\n)\n\n# unet utilizes `down_block` and `up_block`\n# down_block delegates to its own workhorse, conv_block, and up_block “bridges” the UNET\n\ndown_block <- nn_module(\n  classname=\"down_block\",\n  initialize = function(in_size, out_size) {\n    self$conv_block <- conv_block(in_size, out_size)\n  },\n  \n  forward = function(x) {   self$conv_block(x)  }\n)\n\nup_block <- nn_module(\n  classname=\"up_block\",\n  initialize = function(in_size, out_size) {\n    self$up = nn_conv_transpose2d(in_size, out_size, kernel_size=2, stride=2)\n    self$conv_block = conv_block(in_size, out_size)\n  },\n  \n  forward = function(x, bridge) {\n    up <- self$up(x)\n    torch_cat(list(up, bridge), 2) %>% self$conv_block()\n  }\n)\n\nconv_block <- nn_module( \n  classname=\"conv_block\",\n  initialize = function(in_size, out_size) {\n    self$conv_block <- nn_sequential(\n      nn_conv2d(in_size, out_size, kernel_size = 3, padding = 1),\n      nn_relu(),\n      nn_dropout(0.6),\n      nn_conv2d(out_size, out_size, kernel_size = 3, padding = 1),\n      nn_relu()\n    )\n  },\n  \n  forward = function(x){\n    self$conv_block(x)\n  }\n)",
      "line_count": 79
    },
    {
      "section": "Transfer Learning",
      "code": "# Initialize the model with appropriate CPU/GPU\ndevice <- torch_device(if(cuda_is_available()) \"cuda\" else \"cpu\")\ndevice <-\"cpu\"\nmodel <- unet(depth = 5)$to(device = device)\n\n# OPTIMIZATION\n\n# DCNN model training using cross_entropy and dice_loss.\ncalc_dice_loss <- function(y_pred, y_true) {\n  smooth <- 1\n  y_pred <- y_pred$view(-1)\n  y_true <- y_true$view(-1)\n  intersection <- (y_pred * y_true)$sum()\n  1 - ((2*intersection+smooth)/(y_pred$sum()+y_true$sum()+smooth))\n}\n\ndice_weight <- 0.3\n#     learning_rate = 0.1\noptimizer <- optim_sgd(model$parameters, lr = 0.1, momentum = 0.9)",
      "line_count": 19
    },
    {
      "section": "Transfer Learning",
      "code": "num_epochs <- 1  # for knitting, otherwise increase to 5+\n\nscheduler <- lr_one_cycle(optimizer, max_lr = 0.1, steps_per_epoch = length(train_dl), epochs = num_epochs)\n\n# TRAINING\ntrain_batch <- function(b) {\n  optimizer$zero_grad()\n  output <- model(b[[1]]$to(device = device))\n  target <- b[[2]]$to(device = device)\n  \n  bce_loss <- nnf_binary_cross_entropy(output, target)\n  dice_loss <- calc_dice_loss(output, target)\n  loss <-  dice_weight*dice_loss + (1-dice_weight)*bce_loss\n  \n  loss$backward()\n  optimizer$step()\n  scheduler$step()\n\n  list(bce_loss$item(), dice_loss$item(), loss$item())\n}\n\nvalid_batch <- function(b) {\n  output <- model(b[[1]]$to(device = device))\n  target <- b[[2]]$to(device = device)\n\n  bce_loss <- nnf_binary_cross_entropy(output, target)\n  dice_loss <- calc_dice_loss(output, target)\n  loss <-  dice_weight * dice_loss + (1-dice_weight)*bce_loss\n  \n  list(bce_loss$item(), dice_loss$item(), loss$item())\n}",
      "line_count": 31
    },
    {
      "section": "Transfer Learning",
      "code": "\nfor (epoch in 1:num_epochs) {\n  model$train()\n  train_bce <- c()\n  train_dice <- c()\n  train_loss <- c()\n  \n  coro::loop(for (b in train_dl) {\n    c(bce_loss, dice_loss, loss) %<-% train_batch(b)\n    train_bce <- c(train_bce, bce_loss)\n    train_dice <- c(train_dice, dice_loss)\n    train_loss <- c(train_loss, loss)\n  })\n  \n  torch_save(model, paste0(getwd(),\"/model_\", epoch, \".pt\"))\n  \n  cat(sprintf(\"\\nEpoch %d, training: loss:%3f, bce: %3f, dice: %3f\\n\",\n              epoch, mean(train_loss), mean(train_bce), mean(train_dice)))\n  \n  model$eval()\n  valid_bce <- c()\n  valid_dice <- c()\n  valid_loss <- c()\n  \n  i <- 0\n  coro::loop(for (b in valid_dl) {\n    \n    i <<- i + 1\n    c(bce_loss, dice_loss, loss) %<-% valid_batch(b)\n    valid_bce <- c(valid_bce, bce_loss)\n    valid_dice <- c(valid_dice, dice_loss)\n    valid_loss <- c(valid_loss, loss)\n    \n  })\n  \n  cat(sprintf(\"\\n Epoch %d, validation: loss: %3f, bce: %3f, dice: %3f\\n\",\n              epoch, mean(valid_loss), mean(valid_bce), mean(valid_dice)))\n}\n\n# note that DCNN model mask prediction will be based on the model complexity!\n\n# Epoch 1, training: loss:0.495716, bce: 0.307674, dice: 0.934480\n# Epoch 1, validation: loss: 0.336556, bce: 0.070743, dice: 0.956785\n# \n# Epoch 2, training: loss:0.290850, bce: 0.114878, dice: 0.701452\n# Epoch 2, validation: loss: 0.213417, bce: 0.046690, dice: 0.602447\n# \n# Epoch 3, training: loss:0.204054, bce: 0.102973, dice: 0.439909\n# Epoch 3, validation: loss: 0.218209, bce: 0.051383, dice: 0.607468\n# \n# Epoch 4, training: loss:0.199831, bce: 0.101564, dice: 0.429123\n# Epoch 4, validation: loss: 0.243201, bce: 0.068757, dice: 0.650236\n# \n# Epoch 5, training: loss:0.201025, bce: 0.101525, dice: 0.433192\n# Epoch 5, validation: loss: 0.258278, bce: 0.077821, dice: 0.679345\n# \n# Epoch 6, training: loss:0.188058, bce: 0.094279, dice: 0.406877\n# Epoch 6, validation: loss: 0.206198, bce: 0.038769, dice: 0.596865\n# \n# Epoch 7, training: loss:0.187285, bce: 0.094894, dice: 0.402866\n# Epoch 7, validation: loss: 0.216684, bce: 0.050536, dice: 0.604361\n# \n# Epoch 8, training: loss:0.184097, bce: 0.093609, dice: 0.395237\n# Epoch 8, validation: loss: 0.235675, bce: 0.060247, dice: 0.645006\n# \n# Epoch 9, training: loss:0.179406, bce: 0.090458, dice: 0.386951\n# Epoch 9, validation: loss: 0.238004, bce: 0.055283, dice: 0.664353\n# \n# Epoch 10, training: loss:0.175083, bce: 0.089144, dice: 0.375608\n# Epoch 10, validation: loss: 0.258206, bce: 0.080033, dice: 0.673942\n# \n# Epoch 11, training: loss:0.175821, bce: 0.089795, dice: 0.376549\n# Epoch 11, validation: loss: 0.213895, bce: 0.037936, dice: 0.624464\n# \n# Epoch 12, training: loss:0.174915, bce: 0.087026, dice: 0.379987\n# Epoch 12, validation: loss: 0.264673, bce: 0.083884, dice: 0.686514\n# \n# Epoch 13, training: loss:0.171973, bce: 0.087210, dice: 0.369754\n# Epoch 13, validation: loss: 0.236396, bce: 0.065432, dice: 0.635311\n# \n# Epoch 14, training: loss:0.167253, bce: 0.084660, dice: 0.359970\n# Epoch 14, validation: loss: 0.210641, bce: 0.047418, dice: 0.591495\n# \n# Epoch 15, training: loss:0.170835, bce: 0.083572, dice: 0.374449\n# Epoch 15, validation: loss: 0.246905, bce: 0.067056, dice: 0.666552\n# \n# Epoch 16, training: loss:0.167938, bce: 0.083285, dice: 0.365460\n# Epoch 16, validation: loss: 0.228558, bce: 0.057135, dice: 0.628546\n# \n# Epoch 17, training: loss:0.161383, bce: 0.080367, dice: 0.350421\n# Epoch 17, validation: loss: 0.221012, bce: 0.055709, dice: 0.606719\n# \n# Epoch 18, training: loss:0.158193, bce: 0.078068, dice: 0.345150\n# Epoch 18, validation: loss: 0.222881, bce: 0.052606, dice: 0.620188\n# \n# Epoch 19, training: loss:0.158190, bce: 0.078865, dice: 0.343280\n# Epoch 19, validation: loss: 0.223159, bce: 0.054643, dice: 0.616361\n# \n# Epoch 20, training: loss:0.161496, bce: 0.079807, dice: 0.352102\n# Epoch 20, validation: loss: 0.221487, bce: 0.051793, dice: 0.617438\n\n# > proc.time()  # In Seconds! About 2,154,523 sec ~ 598 hours\n#      user    system   elapsed\n# 2154523.7  776791.3  141279.2",
      "line_count": 104
    },
    {
      "section": "Transfer Learning",
      "code": "# EVALUATION\n# without random sampling, we'd mainly see lesion-free patches\nN <- 10 # number of cases to predict the masks for\n\neval_ds <- brain_dataset(valid_dir, augmentation_params = NULL, random_sampling = TRUE)\neval_dl <- dataloader(eval_ds, batch_size = N)\n\nbatch <- eval_dl %>% dataloader_make_iter() %>% dataloader_next()\n\n# Load a previously save torch model\n# epoch = 1\n# torch_load(model, paste0(\"model_\", epoch, \".pt\"))\n\n# torch_save(model, \"C:/Users/Dinov/Desktop/model_epoch_1.pt\")\n\n##### Requirements for loading a pre-trained model .....\n# load torch packages above\n# The pre-computed model files are available on Canvas:\n# https://umich.instructure.com/courses/38100/files/folder/Case_Studies/36_TCGA_MRI_Segmentation_Data_Phenotypes\n#  localModelsFolder <- \"C:/Users/IvoD/Desktop/Ivo.dir/Research/UMichigan/Publications_Books/2023/DSPA_Springer_2nd_Edition_2023/Rmd_HTML/appendix/\"\n\nlocalModelsFolder <-getwd()\n\nmodel <- torch_load(paste0(localModelsFolder, \"/appendix/model_6.pt\"))\n# train_dir <- \"/data/data\"\n# valid_dir <- \"/data/mri_valid\"\n# brain_dataset ...\n# train_ds; valid_ds\n# eval_ds <- brain_dataset(valid_dir,augmentation_params=NULL,random_sampling=TRUE)\n# eval_dl <- dataloader(eval_ds, batch_size = 8)\n# batch <- eval_dl %>% dataloader_make_iter() %>% dataloader_next()\n# device <- torch_device(if(cuda_is_available()) \"cuda\" else \"cpu\")\n# calc_dice_loss\nlibrary(plotly)\n\nimgsTruePred <- map (1:N, function(i) {\n  # Get the 3 images\n  img <- batch[[1]][i, .., drop = FALSE]                            # Image to predict the tumor mask for\n  inferred_mask <- model(img$to(device = device))                   # Predicted MASK\n  true_mask <- batch[[2]][i, .., drop = FALSE]$to(device = device)  # True manual mask delineation\n  \n  # compute/report the BCE/Dice performance metrics\n  bce <- nnf_binary_cross_entropy(inferred_mask, true_mask)$to(device = \"cpu\") %>% as.numeric()\n  dc <- calc_dice_loss(inferred_mask, true_mask)$to(device = \"cpu\") %>% as.numeric()\n  cat(sprintf(\"\\nSample %d, bce: %3f, dice: %3f\\n\", i, bce, dc))\n  \n  # extract the inferred predicted mask as a 2D image/array of probability values per voxel!\n  inferred_mask <- inferred_mask$to(device = \"cpu\") %>% as.array() %>% .[1, 1, , ]\n  # Binarize the probability tumor prediction to binary mask\n  inferred_mask <- ifelse(inferred_mask > 0.48, 1, 0)  # In a real run, use \"inferred_mask > 0.5, 1, 0\"\n  # hist(as.matrix(inferred_mask[1,1,,]))\n  \n  imgs <- img[1, 1, ,] %>% as.array() %>% as.array() %>% \n    plot_ly(z=., type=\"heatmap\", showscale = FALSE, name=\"Image\")  %>% \n      layout(showlegend=FALSE,  yaxis = list(scaleanchor = \"x\", scaleratio = 1))    # hovermode = \"y unified\"\n  masks <- true_mask$to(device = \"cpu\")[1, 1, ,] %>% as.array() %>% as.array() %>% \n    plot_ly(z=., type=\"heatmap\", showscale = FALSE, name=\"True Mask\") %>% \n      layout(showlegend=FALSE,  yaxis = list(scaleanchor = \"x\", scaleratio = 1))    # hovermode = \"y unified\",\n  predMasks <- inferred_mask %>% as.array() %>% \n    plot_ly(z=., type=\"heatmap\", showscale = FALSE, name=\"Unet-Derived Mask\") %>% \n        layout(showlegend=FALSE,  yaxis = list(scaleanchor = \"x\", scaleratio = 1))  # hovermode = \"y unified\",\n  rowSubPlots <- subplot(imgs, masks, predMasks, nrows = 1, shareY = TRUE) %>%\n            # , widths = c(0.3, 0.3, 0.3))\n    layout(hovermode = \"y unified\") #, yaxis = list(scaleanchor = \"x\", scaleratio = 1))\n})",
      "line_count": 65
    },
    {
      "section": "Transfer Learning",
      "code": "# imgsTruePred[[2]] \n# p1 <- imgsTruePred[c(1:2)] %>% subplot(nrows = 2)\n# p2 <- imgsTruePred[c(3:4)] %>% subplot(nrows = 2)\n# p3 <- imgsTruePred[c(5:6)] %>% subplot(nrows = 2)\n# p4 <- imgsTruePred[c(7:8)] %>% subplot(nrows = 2)\n# p5 <- imgsTruePred[c(9:10)] %>% subplot(nrows = 2)\n# subplot(p1, p2, p3, p4, p5, nrows = 5) %>%  layout(title=\"Model Validation using N=10 Cases\")\n\nimgsTruePred %>% subplot(nrows = N) %>%  layout(title=\"Model Validation using N=10 Cases\")",
      "line_count": 9
    },
    {
      "section": "Transfer Learning",
      "code": "reparametrize <- function(mu, logvar){\n    std = torch_exp(0.5*logvar) \n    eps = torch_randn_like(std)\n    z = mu + std * eps\n    return (z)\n}",
      "line_count": 6
    },
    {
      "section": "Transfer Learning",
      "code": "h_dim <- c(32, 64, 128, 256, 512)\n\nnet_encoder <- nn_module(\n        initialize = function(latent_size=1000){\n        \n        self$latent_size <- latent_size  # Z\n\n        # h_dim <- c(32, 64, 128, 256, 512)\n        in_channels = 3\n        \n        # Encoder\n        \n        self$encoder <- nn_sequential(\n                nn_conv2d(in_channels, out_channels=h_dim[1],\n                          kernel_size= 3, stride= 2, padding = 1),\n                nn_batch_norm2d(h_dim[1]),\n                nn_leaky_relu(),\n                \n                nn_conv2d(h_dim[1], out_channels=h_dim[2],\n                          kernel_size= 3, stride= 2, padding = 1),\n                nn_batch_norm2d(h_dim[2]),\n                nn_leaky_relu(),\n                \n                nn_conv2d(h_dim[2], out_channels=h_dim[3],\n                          kernel_size= 3, stride= 2, padding = 1),\n                nn_batch_norm2d(h_dim[3]),\n                nn_leaky_relu(),\n                \n                nn_conv2d(h_dim[3], out_channels=h_dim[4],\n                          kernel_size= 3, stride= 2, padding = 1),\n                nn_batch_norm2d(h_dim[4]),\n                nn_leaky_relu(),\n                \n                nn_conv2d(h_dim[4], out_channels=h_dim[5],\n                          kernel_size= 3, stride= 2, padding = 1),\n                nn_batch_norm2d(h_dim[5]),\n                nn_leaky_relu()\n                )\n        \n        self$mu_layer <- nn_linear(h_dim[5]*64, latent_size)\n        self$logvar_layer <- nn_linear(h_dim[5]*64, latent_size)\n        },\n\n        forward = function(x){\n            \n            list_output = c()\n            hidden = self$encoder(x)\n            hidden = torch_flatten(hidden, start_dim=2)\n            mu = self$mu_layer(hidden)\n            logvar = self$logvar_layer(hidden)\n            z = reparametrize(mu, logvar)\n            list_output = append(list_output, z)\n            list_output = append(list_output, mu)\n            list_output = append(list_output, logvar)\n            \n            return (list_output)\n        }\n)",
      "line_count": 58
    },
    {
      "section": "Transfer Learning",
      "code": "net_decoder <- nn_module(\n        initialize = function(latent_size=1000){\n        \n        self$latent_size <- latent_size  # Z\n\n        self$decoder_input <- nn_linear(latent_size, h_dim[5]*64)\n        \n        hidden_dims = c(32, 64, 128, 256, 512)\n        \n        # decoder\n        self$decoder <- nn_sequential(\n                nn_conv_transpose2d(hidden_dims[5],\n                                   hidden_dims[4],\n                                   kernel_size=3,\n                                   stride = 2,\n                                   padding=1,\n                                   output_padding=1),\n                nn_batch_norm2d(hidden_dims[4]),\n                nn_leaky_relu(),\n                \n                nn_conv_transpose2d(hidden_dims[4],\n                                   hidden_dims[3],\n                                   kernel_size=3,\n                                   stride = 2,\n                                   padding=1,\n                                   output_padding=1),\n                nn_batch_norm2d(hidden_dims[3]),\n                nn_leaky_relu(),\n                \n                nn_conv_transpose2d(hidden_dims[3],\n                                   hidden_dims[2],\n                                   kernel_size=3,\n                                   stride = 2,\n                                   padding=1,\n                                   output_padding=1),\n                nn_batch_norm2d(hidden_dims[2]),\n                nn_leaky_relu(),\n                \n                nn_conv_transpose2d(hidden_dims[2],\n                                   hidden_dims[1],\n                                   kernel_size=3,\n                                   stride = 2,\n                                   padding=1,\n                                   output_padding=1),\n                nn_batch_norm2d(hidden_dims[1]),\n                nn_leaky_relu()\n                )\n\n        self$final_layer <- nn_sequential(\n                            nn_conv_transpose2d(hidden_dims[1],\n                                               hidden_dims[1],\n                                               kernel_size=3,\n                                               stride=2,\n                                               padding=1,\n                                               output_padding=1),\n                            nn_batch_norm2d(hidden_dims[1]),\n                            nn_leaky_relu(),\n                            nn_conv2d(hidden_dims[1], out_channels= 3,\n                                      kernel_size= 3, padding= 1),\n                            nn_sigmoid())\n        },\n\n        forward = function(z){\n            \n            z = self$decoder_input(z)\n            z = z$view(c(-1, 512, 8, 8))\n            x_hat = self$final_layer(self$decoder(z))\n            \n            return (x_hat)\n        }\n)",
      "line_count": 71
    },
    {
      "section": "Transfer Learning",
      "code": "loss_function <- function(x_hat, x, mu, logvar){\n    N = mu$shape[1]\n    Z = mu$shape[2]\n    loss = nnf_binary_cross_entropy(x_hat, x, reduction='sum') -0.5*torch_sum(logvar-mu^2-torch_exp(logvar))-0.5*Z*N\n    return (loss/N)\n}",
      "line_count": 6
    },
    {
      "section": "Transfer Learning",
      "code": "model_encoder = net_encoder()\nmodel_decoder = net_decoder()\n# model = model$to(device='cuda')\noptimizer <- optim_adam(model_decoder$parameters)\n# optimizer <- optim_adam(model$parameters)\n# train_data <- train_data / 255 # torch tensor with shape (N, C, H, W)\n\n# torch_model$cuda()\n\n# Epochs\ncapture.output(     # Capture/Suppress Pytorch output, which overwhelms the knitted HTML report\n  for (epoch in 1:5) {   # could increase the number of epochs for better results\n    l <- c()\n    coro::loop(for (b in train_dl) {\n      optimizer$zero_grad()\n      gnd = b[[1]]\n      list_output <- model_encoder(gnd)\n      z = list_output[[1]]\n      mu = list_output[[2]]\n      logvar = list_output[[3]]\n      output <- model_decoder(z)\n      \n      loss <- loss_function(output, gnd, mu, logvar)\n      print(loss)\n      loss$backward()\n      optimizer$step()\n      l <- c(l, loss$item())\n    })\n  \n    cat(sprintf(\"Loss at epoch %d: %3f\\n\", epoch, mean(l)))\n  })\n\n# capture.output(     # Capture/Suppress Pytorch output, which overwhelms the knitted HTML report\n#   for (epoch in 1:5) {   # could increase the number of epochs for better results\n#     l <- c()\n#     coro::loop(for (b in train_dl) {\n#       # optimizer$zero_grad()\n#       encoderOptimizer$zero_grad()\n#       decoderOptimizer$zero_grad()\n#       gnd = b[[1]]\n#       list_output <- model_encoder(gnd)\n#       z = list_output[[1]]\n#       mu = list_output[[2]]\n#       logvar = list_output[[3]]\n#       output <- model_decoder(z)\n#       \n#       loss <- loss_function(output, gnd, mu, logvar)\n#       print(loss)\n#       loss$backward()\n#       # optimizer$step()\n#       encoderOptimizer$step()\n#       decoderOptimizer$step()\n#       l <- c(l, loss$item())\n#     })\n#   \n#     cat(sprintf(\"Loss at epoch %d: %3f\\n\", epoch, mean(l)))\n#   })",
      "line_count": 57
    },
    {
      "section": "Transfer Learning",
      "code": "img <- (train_ds[1][1]$img)$view(c(1, 3, 256, 256))\nz = (model_encoder(img))[[1]]\nreconstructed <-  model_decoder(z)\nreconstructed <- (reconstructed$view(c(3, 256, 256)))$permute(c(2, 3, 1)) %>% as.array()\n\n# Generate a random tensor of numbers in the Latent space using a uniform distribution on the interval [0,1)\n# these will be used to seed the VAE decoder branch of the Unet and synthetically generate 2D brain images\nz <- torch_rand(c(1, 1000)) \ngenerated_images <- model_decoder(z)\ngenerated_images <- (generated_images$view(c(3, 256, 256)))$permute(c(2, 3, 1)) %>% as.array()",
      "line_count": 10
    },
    {
      "section": "Transfer Learning",
      "code": "library (plotly)\nrasterPlotly <- function (image, name=\"\", hovermode = NULL) {\n  myPlot <- plot_ly(type=\"image\", z=image, name=name, hoverlabel=name, text=name, \n            hovertext=name, hoverinfo=\"name+x+y+z\") %>% \n    layout(title=name, hovermode = hovermode, xaxis = list(hoverformat = '.1f'), yaxis = list(hoverformat = '.1f'))\n  return(myPlot)\n}\n\np1 <- rasterPlotly(image=255*reconstructed, name = \"DNN-reconstructed RGB Image\")\n# rasterPlotly(image=255*generated_images, name = \"Synthetic DNN-generated RGB Image\")\np2 <- rasterPlotly(image=20/(0.1+generated_images), name = \"Synthetic DNN-generated RGB Image\")\n# subplot(p1, p2) %>% layout(title=\"DNN (Unet) Image Reconstruction and Synthetic Generation\")\np1\np2",
      "line_count": 14
    },
    {
      "section": "Transfer Learning",
      "code": "# clean environment\nrm(list = ls())\ngc()\n\nvenv_name <- \"r-tensorflow\"\nreticulate::use_virtualenv(virtualenv = venv_name, required = TRUE)\nlibrary(reticulate)\n\nlibrary(tensorflow)\nlibrary(tfdatasets)\nlibrary(rsample)  # for training() method\n# library(reticulate)\nlibrary(purrr)\nlibrary(keras)\nlibrary(unet)\nlibrary(tibble)\nlibrary(plotly)",
      "line_count": 17
    },
    {
      "section": "Transfer Learning",
      "code": "train_dir <- \"/data/data\"\nvalid_dir <- \"/data/mri_valid\"\n\n# Load PNG images\ndata_train <- tibble(\n  img = grep(list.files(train_dir, full.names = TRUE, pattern = \"\\\\.png$\", recursive = TRUE), # or \"tif\"\n        pattern = 'mask', invert = TRUE, value = TRUE),\n  mask = grep(list.files(train_dir, full.names = TRUE, pattern = \"\\\\.png$\", recursive = TRUE),\n        pattern = 'mask', value = TRUE)\n)\nlength(data_train$mask)  # [1] 2520\ndata_train$img[[1]]  # [1] \"/data/data/TCGA_CS_4941_19960909/TCGA_CS_4941_19960909_1.tif\"\ndata_train$img[[2520]]; data_train$mask[[2520]]\n\n# # Or Load the TIFF images\n# data_train <- tibble(\n#   img = grep(list.files(train_dir, full.names = TRUE, pattern = \"*\\\\d\\\\.tif$\", recursive = TRUE),\n#              pattern = 'mask', invert = TRUE, value = TRUE),\n#   mask = grep(list.files(train_dir, full.names = TRUE, pattern = \"*mask\\\\.tif$\", recursive = TRUE),\n#             pattern = 'mask', value = TRUE)\n# )\n# length(data_train$mask)  # [1] 3216\n# data_train$img[[1]]  # [1] \"/data/data/TCGA_CS_4941_19960909/TCGA_CS_4941_19960909_1.tif\"\n# data_train$img[[3216]]; data_train$mask[[3216]]\n\ndata_train_valid <- initial_split(data_train, prop = 0.8)\n\n# data_train_valid$data$img[1111];  data_train_valid$data$mask[1111]\n# # \"/data/data/TCGA_DU_7299_19910417/TCGA_DU_7299_19910417_17_mask.png\"\n# tarfile <- 'C:/Users/Dinov/Desktop/BrainTumorImagingDataZipArchive.tgz'\n# tar(tarfile,'/data/',compression='gzip')\n# untar(tarfile,'/data/',compression='gzip')\n\n# Check the tensor shape\n# tf$image$decode_png(tf$io$read_file(data_train$img[[1]]))\n# Inspect the structure of  data_train_valid\n# str(data_train_valid)\n\ntraining_dataset <- training(data_train_valid) %>%  \n  tensor_slices_dataset() %>% \n  dataset_map(~.x %>% list_modify(\n    # decode_jpeg yields a 3d tensor of shape (256, 256, 3)\n    # Check tensor shapes!\n    img = tf$image$decode_png(tf$io$read_file(.x$img), channels = 3),\n    # img = ifelse(as.character(tf$image$decode_png(tf$io$read_file(.x$img)))$shape==\"(256, 256, 1)\",\n    #                    fix3ChannelImg(tf$image$decode_png(tf$io$read_file(.x$img))),\n    #                    tf$image$decode_png(tf$io$read_file(.x$img))),\n    # Note that decode_gif yields a 4d tensor of shape (1, 256, 256, 3),\n    # so we remove the unneeded batch dimension and all but one \n    # of the 3 (identical) channels: tf$image$decode_gif(tf$io$read_file(.x$mask))[1,,,][,,1,drop=FALSE]\n    mask = tf$image$decode_png(tf$io$read_file(.x$mask))\n    # wrong_tensor_shape = (as.character(.x$shape) ==\"(256, 256, 1)\")\n    # if (as.character(img$shape) == \"(256, 256, 1)\") \n    #   img = tf$image$grayscale_to_rgb(img)\n  )) \n  # %>%\n  # tfdatasets::dataset_filter(\n  #      function(record) {\n  #         tf$equal(as.character(record$img$shape), \"(256, 256, 3)\")\n  #      }\n  #   )\n\ntesting_dataset <- testing(data_train_valid) %>%  \n  tensor_slices_dataset() %>% \n  dataset_map(~.x %>% list_modify(\n    # decode_jpeg yields a 3d tensor of shape (256, 256, 3)\n    # Check tensor shapes!\n    img = tf$image$decode_png(tf$io$read_file(.x$img), channels = 3),\n    # img = ifelse(as.character(tf$image$decode_png(tf$io$read_file(.x$img)))$shape==\"(256, 256, 1)\",\n    #                    fix3ChannelImg(tf$image$decode_png(tf$io$read_file(.x$img))),\n    #                    tf$image$decode_png(tf$io$read_file(.x$img))),\n    # Note that decode_gif yields a 4d tensor of shape (1, 256, 256, 3),\n    # so we remove the unneeded batch dimension and all but one \n    # of the 3 (identical) channels: tf$image$decode_gif(tf$io$read_file(.x$mask))[1,,,][,,1,drop=FALSE]\n    mask = tf$image$decode_png(tf$io$read_file(.x$mask))\n  )) \n\n# Check the size of the entire (training & testing) TF datasets\ntf$data$experimental$cardinality(training_dataset)$numpy()  # [1] 2572\ntf$data$experimental$cardinality(testing_dataset)$numpy()   # [1] 644\n\nexample <- training_dataset %>% reticulate::as_iterator() %>% reticulate::iter_next(); example\n\n# Check to confirm all brain-images (tensors) are of the same RGB 3-channel shape (256, 256, 3)\ncapture.output(\n  tryCatch({\n    ind2 <- list(); i <- 1\n    iter <- make_iterator_one_shot(training_dataset)\n    until_out_of_range({\n        case <- iterator_get_next(iter)\n        ind2[[i]] <- ifelse (as.character(case[[1]]$shape)==\"(256, 256, 1)\", \"Incorrect\", \"Correct\")\n        if (ind2[[i]] ==\"Incorrect\") print(\".\")\n        i <- i+1 \n        # print(\".\"); # str(case)\n    })\n    print(\"Check if any brain-images (tensors) are NOT of the correct RGB 3-channel shape (256, 256, 3)\")\n    table(unlist(ind2))\n  }, error = function(e) e, finally = print(\"Done!\")))",
      "line_count": 98
    },
    {
      "section": "Transfer Learning",
      "code": "# For data augmentation - contrast, brightness & saturation perturbations\nrandom_bsh <- function(img) {\n  img %>% \n    tf$image$random_brightness(max_delta = 0.2) %>% \n    tf$image$random_contrast(lower = 0.3, upper = 0.6) %>% \n    tf$image$random_saturation(lower = 0.5, upper = 0.6) %>% \n    # ensure image intensities are between 0 and 1\n    tf$clip_by_value(0, 1) \n}\n# Test Brightness-Saturation-Contrast Hue intensity augmentation\nmyIterator <- training_dataset %>% reticulate::as_iterator() \nexample <- myIterator$get_next(); example <- myIterator$get_next(); example <- myIterator$get_next() # example\nbshExample <- random_bsh(tf$image$convert_image_dtype(example$img, dtype = tf$float32))\n\narr1 <- array(as.numeric(unlist(example$img)), dim=c(256, 256, 3))\np1 <- plot_ly(type=\"heatmap\", z=~arr1[,,1], name=\"Image\")  \narr2 <- array(as.numeric(unlist(example$mask)), dim=c(256, 256, 1))\np2 <- plot_ly(type=\"heatmap\", z=~arr2[,,1], name=\"Mask\") \narr3 <- 255*array(as.numeric(unlist(bshExample)), dim=c(256, 256, 3))\np3 <- plot_ly(type=\"heatmap\", z=~arr3[,,1], name=\"BSC-Image\")  \nsubplot(p1, p2, p3, nrows=1) %>% layout(title=\"Brightness-Saturation-Contrast Hue Image Intensity Augmentation\") %>% hide_colorbar()\n\n# Random Rotation\n# Rotation requires TF-Addon package: https://www.tensorflow.org/addons/overview \n\n# reticulate::py_install(c('tensorflow-addons'), pip = TRUE)\n# tfaddons::install_tfaddons() \n# devtools::install_github('henry090/tfaddons')\n\nlibrary(tfaddons)\n# random_rotate = function(img, mask, rot_param=15) {\n#     rnd_rot <- runif(1, -rot_param, rot_param)  # random rotation in degrees +/- rot_param\n#     img  <- img_rotate(img, angle = rnd_rot)    # tfa$image$rotate(img, angle = rnd_rot)\n#     mask <- img_rotate(mask, angle = rnd_rot)   # tfa$image$rotate(mask, angle = rnd_rot)\n#     # c(img, mask)\n#     return (list(img=img, mask=mask))\n# }\n\n#### This is a work-around for the data-augmentation rotation problem \n#### related to the zeallot right operator `%->%` and the `magrittr` pipe operator `%>%`\nrot_param <- 15 # degrees of rotation\nrnd_rot <- runif(1000, -rot_param, rot_param)\nrandomRotationPaired <- c(rbind(rnd_rot, rnd_rot)) # double the random rotations\ncurrentRotationIndex <- 1\n\nrandom_rotate = function(img, mask) {\n    img  <- img_rotate(img, angle=randomRotationPaired[currentRotationIndex])    # tfa$image$rotate(img, angle = rnd_rot)\n    mask <- img_rotate(mask, angle=randomRotationPaired[currentRotationIndex])   # tfa$image$rotate(mask, angle = rnd_rot)\n    # c(img, mask)\n    currentRotationIndex <- (currentRotationIndex + 1) %% 1000\n    return (list(img=img, mask=mask))\n}\n# tesingRot = img_rotate(example$img, angle=10) \n\n# Test rotator\nmyIterator <- training_dataset %>% reticulate::as_iterator() \nexample <- myIterator$get_next(); example <- myIterator$get_next(); example <- myIterator$get_next() # example\narr1 <- array(as.numeric(unlist(example$img)), dim=c(256, 256, 3))\np1 <- plot_ly(type=\"heatmap\", z=~arr1[,,1], name=\"Raw Img\")  \narr2 <- array(as.numeric(unlist(example$mask)), dim=c(256, 1, 256))\np2 <- plot_ly(type=\"heatmap\", z=~arr2[,1,], name=\"Raw Mask\") \nsubplot(p1, p2, nrows=1) %>% layout(title=\"Original Image + Mask\") %>% hide_colorbar()\n\nrotExample <- random_rotate(example$img, example$mask)\nrotExample$img$shape; rotExample$mask$shape\narr1 <- array(as.numeric(unlist(rotExample$img)), dim=c(256, 256, 3))\np1 <- plot_ly(type=\"heatmap\", z=~arr1[,, 1], name=\"Rotated Img\")  \narr2 <- array(as.numeric(unlist(rotExample$mask)), dim=c(256, 256, 1))\np2 <- plot_ly(type=\"heatmap\", z=~arr2[,, 1], name=\"Rotated Mask\") \nsubplot(p1, p2, nrows=1) %>% layout(title=\"Augmented/Rotated Image + Mask\") %>% hide_colorbar()\n\ncurrentRotationIndex <- 1 # reset the currentRotationIndex\n\n# c(img, mask) %<-% random_rotate(example$img, example$mask)\n# img$shape; mask$shape\n# arr1 <- array(as.numeric(unlist(img)), dim=c(256, 256, 3))\n# p1 <- plot_ly(type=\"heatmap\", z=~arr1[,, 1])  \n# arr2 <- array(as.numeric(unlist(mask)), dim=c(256, 256, 1))\n# p2 <- plot_ly(type=\"heatmap\", z=~arr2[,, 1]) \n# subplot(p1, p2, nrows=1) %>% layout(title=\"Augmented/Rotated Image + Mask\") %>% hide_colorbar()\n\n# Inspect one case\n# example <- training_dataset %>% reticulate::as_iterator() %>% reticulate::iter_next()\n# example$img %>% as.array() %>% as.raster() %>% plot()",
      "line_count": 84
    },
    {
      "section": "Transfer Learning",
      "code": "library(zeallot)   # for the reverse-piping assignment operator: %<-%\n\ncreate_dataset <- function(data, train, batch_size = 32L) {\n  dataset <- data %>%   # load all PNG files as images\n    tensor_slices_dataset() %>% \n    dataset_map(~.x %>% list_modify(\n      img = tf$image$decode_png(tf$io$read_file(.x$img), channels = 3),\n      mask = tf$image$decode_png(tf$io$read_file(.x$mask))\n    )) %>%     # convert image intensities from int8 to 32-bit float\n    dataset_map(~.x %>% list_modify(\n      img = tf$image$convert_image_dtype(.x$img, dtype = tf$float32),\n      mask = tf$image$convert_image_dtype(.x$mask, dtype = tf$float32)\n    )) %>%     # reshape all tensor-shape to (256 * 256) to ensure spatial-index homologies\n    dataset_map(~.x %>% list_modify(\n      img = tf$image$resize(.x$img, size = shape(256, 256)),\n      mask = tf$image$resize(.x$mask, size = shape(256, 256))\n    ))\n  \n  # data augmentation performed on training set only\n  if (train) {\n    dataset <- dataset %>%\n      dataset_map(~.x %>% list_modify(\n        # random_rotate(img=.x$img, mask=.x$mask) %->% c(img=img, mask=mask) \n        # c(img=img, mask=mask) %<-% random_rotate(img=.x$img, mask=.x$mask) # <- Check this issue, it should work like this:\n          # example <- myIterator$get_next(); example <- myIterator$get_next(); example <- myIterator$get_next()\n          # c(img, mask) %<-% random_rotate(example[[1]], example[[2]])\n          # random_rotate(img=example[[1]], mask=example[[2]]) %->% c(img, mask)\n          # img$shape; mask$shape\n          # \n          # Alternative Solutions\n          # c(img, mask) %<-% random_rotate(.x)\n          # Syntax: ListOfLists <- c(a, b) %<-% list(a=list(1,2,3), b=list(4,5,6,7)); ListOfLists$b\n          # c(img, mask) %<-% random_rotate(.x$img, .x$mask)\n          #\n          # This works, but we need joint, not separate, rotation of img + mask\n          img = random_rotate(img=.x$img, mask=.x$mask)$img,\n          mask= random_rotate(img=.x$img, mask=.x$mask)$mask\n          # c(img, mask) %<-% unlist(random_rotate(img=.x$img, mask=.x$mask))\n          # # mask = random_rotate(.x$img, .x$mask)[[2]]\n      )) %>%\n      dataset_map(~.x %>% list_modify(\n        img = random_bsh(.x$img)\n      ))\n  }\n  \n  # shuffling on training set only\n  if (train) {\n    dataset <- dataset %>% \n      dataset_shuffle(buffer_size = batch_size*4)\n  }\n  \n  # train in batches; batch size might need to be adapted depending on\n  # available memory\n  dataset <- dataset %>% \n    dataset_batch(batch_size)\n  \n  dataset %>% \n    # output needs to be unnamed as required by Keras\n    dataset_map(unname) # makes example$img -> example[[1]]\n}\n\n# Generate the Training and Testing data at iterated TF-Data objects\ntraining_dataset <- create_dataset(training(data_train_valid), train = TRUE)\nvalidation_dataset <- create_dataset(testing(data_train_valid), train = FALSE)\n# tf$data$experimental$cardinality(training_dataset)$numpy()\nmyIterator <- training_dataset %>% reticulate::as_iterator() \nexample <- myIterator$get_next()  # ; example <- myIterator$get_next()  # shape=(32, 256, 256, 3 or 1)\nc(img,mask) %<-% random_rotate(img=example[[1]][1,,,1], mask=example[[2]][1,,,1])\nimg$shape; mask$shape\n\narr1 <- array(as.numeric(img), dim=c(256, 256))\np1 <- plot_ly(type=\"heatmap\", z=~arr1, name=\"Rotated Img\")\narr2 <- array(as.numeric(mask), dim=c(256, 256))\np2 <- plot_ly(type=\"heatmap\", z=~arr2, name=\"Rotated Mask\")\nsubplot(p1, p2, nrows=1) %>% layout(title=\"Augmented/Rotated Image + Mask\") %>% hide_colorbar()",
      "line_count": 75
    },
    {
      "section": "Transfer Learning",
      "code": "# Model Training - Starting with a pre-trained U-net model and then expanding it with Transfer-learning\nlibrary(unet)\nmodel <- unet::unet(input_shape = c(256, 256, 3))  # for RGB use 3-channels: input_shape = c(256, 256, 3)\nsummary(model)\n\n# define a custom loss function (dice coefficient)\ndice <- custom_metric(\"dice\", function(y_true, y_pred, smooth = 1.0) {\n  y_true_f <- k_flatten(y_true)\n  y_pred_f <- k_flatten(y_pred)\n  intersection <- k_sum(y_true_f * y_pred_f)\n  (2 * intersection + smooth) / (k_sum(y_true_f) + k_sum(y_pred_f) + smooth)\n})\n\n# Compile the DCNN model, packaging an optimizer, loss and performance metrics\nmodel %>% compile(\n  optimizer = optimizer_rmsprop(learning_rate = 1e-5),\n  loss = \"binary_crossentropy\",\n  metrics = list(dice, metric_binary_accuracy)\n)\n\n# Naive Prediction using the default model (prior to Re-Training or Transfer Learning)\nbatch <- validation_dataset %>% reticulate::as_iterator() %>% reticulate::iter_next()\npredictions <- predict(model, batch[[1]])\nimages <- tibble(\n  image = batch[[1]] %>% array_branch(1),\n  predicted_mask = predictions[,,,1] %>% array_branch(1),\n  mask = batch[[2]][,,,1]  %>% array_branch(1)\n) \n\n# Check performance of the default base model on one case (# 22)\ni=22\nz1 <- ifelse(as.matrix(as.data.frame(images$predicted_mask[i])) > 0.5, 1, 0)\npl1 <- plot_ly(z = ~ 255*as.matrix(as.data.frame(images$mask[i])[,1:256]), type=\"heatmap\", name=paste0(\"Tumor Mask \", i))\npl2 <- plot_ly(z = ~ 255*as.matrix(as.data.frame(images$image[i])[,1:256]), type=\"heatmap\", name=paste0(\"Brain Image \", i))\npl3 <- plot_ly(z = ~ z1, type=\"heatmap\", name=paste0(\"Pred Mask \", i))\nsubplot(pl1, pl2, pl3, nrows=1) %>% hide_colorbar()\n\n# training_dataset <- create_dataset(training(data_train_valid), train = TRUE)\n# validation_dataset <- create_dataset(testing(data_train_valid), train = FALSE)\n# \n# library(unet)\n# \n# model <- unet::unet(input_shape = c(256, 256, 3))  # for RGB use 3-channels: input_shape = c(256, 256, 3)\n# # summary(model)\n# \n# library(keras)\n# dice <- custom_metric(\"dice\", function(y_true, y_pred, smooth = 1.0) {\n#   y_true_f <- k_flatten(y_true)\n#   y_pred_f <- k_flatten(y_pred)\n#   intersection <- k_sum(y_true_f * y_pred_f)\n#   (2 * intersection + smooth) / (k_sum(y_true_f) + k_sum(y_pred_f) + smooth)\n# })\n# \n# model %>% compile(\n#   optimizer = optimizer_rmsprop(learning_rate = 1e-5),\n#   loss = \"binary_crossentropy\",\n#   metrics = list(dice, metric_binary_accuracy)\n# )",
      "line_count": 58
    },
    {
      "section": "Transfer Learning",
      "code": "# MODEL FITTING\nepochs = 1\nhistory <- model %>% fit(training_dataset, epochs = epochs, validation_data = validation_dataset)\n\n# ASSESSMENT - Actual Model Evaluation (after Transfer-learning retraining)\n# Naive Prediction\nbatch <- validation_dataset %>% reticulate::as_iterator() %>% reticulate::iter_next()\npredictions <- predict(model, batch[[1]])\nimages <- tibble(\n  image = batch[[1]] %>% array_branch(1),\n  predicted_mask = predictions[,,,1] %>% array_branch(1),\n  mask = batch[[2]][,,,1]  %>% array_branch(1)\n) \ni=22\npl1 <- plot_ly(z = ~ 255*as.matrix(as.data.frame(images$mask[i])[,1:256]), type=\"heatmap\", name=paste0(\"Tumor Mask \", i))\npl2 <- plot_ly(z = ~ 255*as.matrix(as.data.frame(images$image[i])[,1:256]), type=\"heatmap\", name=paste0(\"Brain Image \", i))\npl3 <- plot_ly(z = ~ 255*as.matrix(as.data.frame(images$predicted_mask[i])[,1:256]), type=\"heatmap\", name=paste0(\"Pred Mask \", i))\nsubplot(pl1, pl2, pl3, nrows=1)\n\nlibrary(keras)\ndice <- custom_metric(\"dice\", function(y_true, y_pred, smooth = 1.0) {\n  y_true_f <- k_flatten(y_true)\n  y_pred_f <- k_flatten(y_pred)\n  intersection <- k_sum(y_true_f * y_pred_f)\n  (2 * intersection + smooth) / (k_sum(y_true_f) + k_sum(y_pred_f) + smooth)\n})\n\nmodel %>% compile(\n  optimizer = optimizer_rmsprop(learning_rate = 1e-5),\n  loss = \"binary_crossentropy\",\n  metrics = list(dice, metric_binary_accuracy)\n)",
      "line_count": 32
    },
    {
      "section": "Transfer Learning",
      "code": "# MODEL FITTING\nhistory <- model %>% fit(training_dataset, epochs = 1, validation_data = validation_dataset, verbose = 2)\n\n# 81/81 [==============================] - 3313s 41s/step - \n# loss: 0.3121 - dice: 0.0106 - binary_accuracy: 0.9604 - val_loss: 0.1762 - val_dice: 1.7162e-04 - val_binary_accuracy: 0.9900\n\n# EVALUATION\npl_loss <- plot_ly(x = ~c(1:history$params$epochs),  y = ~history$metrics$loss,\n        type = \"scatter\", mode=\"markers+lines\", name=\"Loss\") %>% \n  add_trace(x = ~c(1:history$params$epochs),  y = ~history$metrics$val_loss,\n        type = \"scatter\", mode=\"markers+lines\", name=\"Validation Loss\") %>%\n  layout(title=\"DNN Training/Validation Performance\", xaxis=list(title=\"epoch\"),\n         yaxis=list(title=\"Metric Value\"), legend = list(orientation='h'))\n\npl_acc <- plot_ly(x = ~c(1:history$params$epochs),  y = ~history$metrics$binary_accuracy,\n        type = \"scatter\", mode=\"markers+lines\", name=\"Accuracy\") %>% \n  add_trace(x = ~c(1:history$params$epochs),  y = ~history$metrics$binary_accuracy,\n        type = \"scatter\", mode=\"markers+lines\", name=\"Validation Binary Accuracy\") %>%\n  layout(title=\"DNN Training/Validation Performance\", xaxis=list(title=\"epoch\"),\n         yaxis=list(title=\"Metric Value\"), legend = list(orientation='h'))\n\nsubplot(pl_loss, pl_acc, nrows=2, shareX = TRUE, titleX = TRUE)\n\n# model %>% evaluate(training_dataset %>% dataset_batch(25), verbose = 0)\nmodel %>% evaluate(validation_dataset, verbose = 0)\n#           loss            dice    binary_accuracy \n#   0.1762175262    0.0001716204        0.9899647236 \n\n# Save/Load the pretrained model in HDF5 format\nsave_model_hdf5(model, \"C:/Users/IvoD/Desktop/model_TF_Brain_epoch_1.h5\", \n                overwrite = TRUE, include_optimizer = TRUE)\n# Mind that loading a model with custom layers/functions, e.g., dice() method, requires special import using a list\n# https://github.com/rstudio/keras/issues/1240",
      "line_count": 33
    },
    {
      "section": "Transfer Learning",
      "code": "# # This HDF5 model is available on Canvas: \n# # https://umich.instructure.com/courses/38100/files/folder/Case_Studies/36_TCGA_MRI_Segmentation_Data_Phenotypes\n# # https://umich.instructure.com/files/22559456/download?download_frd=1\n# mod1 <- \n#   load_model_hdf5(\"E:/Ivo.dir/Research/UMichigan/Proposals/2014/UMich_MINDS_DataSciInitiative_2014/2016/MIDAS_HSXXX_DataScienceAnalyticsCourse_Porposal/MOOC_Implementation/appendix/model_TF_Brain_epoch_50.h5\", \n#                         custom_objects = list(\"dice\" = dice), compile = TRUE)\n# \n# # Update the model's last layer: https://tensorflow.rstudio.com/guide/keras/faq/ \n# # mod2 <- mod1 %>% \n# #   # get_layer(index=33) %>%\n# #   pop_layer() %>%  # remove the output layer first, then plug in a new output layer\n# #   # layer_conv_2d(filters = 64, kernel_size = c(3, 3), padding = \"same\") \n# #   layer_conv_2d(filters = 64, kernel_size = c(3,3), activation = \"relu\")\n# input <- mod1$input                            # UNet input layer\n# base <- (mod1 %>% get_layer(index=33))$output  # Get the last output layer of \"mod1\"\n# target <- base %>%                             # Replace the output layer by a new conv2D layer outputting a 3-channel 2D brain image\n#   layer_conv_2d(filters = 3, kernel_size = c(1,1), activation = \"relu\")\n# transfer_model <- keras_model(input, target)   # Update mod1 for transfer learning \n# summary(transfer_model)                        \n# # Mind the final layer change: \n# # Layer (type)        Output Shape         Param #    Connected to  \n# # conv2d_23 (Conv2D)  (None, 256, 256, 3)  6          conv2d_18[0][0] \n\n# # Define the Dice coefficient\n# dice <- custom_metric(\"dice\", function(y_true, y_pred, smooth = 1.0) {\n#   y_true_f <- k_flatten(y_true)\n#   y_pred_f <- k_flatten(y_pred)\n#   intersection <- k_sum(y_true_f * y_pred_f)\n#   (2 * intersection + smooth) / (k_sum(y_true_f) + k_sum(y_pred_f) + smooth)\n# })\n# \n# # Recompile the model with our  custom dice() loss function\n# mod1 %>% compile(\n#   optimizer = optimizer_rmsprop(learning_rate = 1e-5),\n#   loss = \"binary_crossentropy\",\n#   metrics = list(dice, metric_binary_accuracy)\n# )\n# # Check re-loaded mod1 model and evaluate performance metrics on validation dataset\n# # summary(mod1)\n# mod1 %>% evaluate(validation_dataset)\n# \n# # Finally display some of the results -- ASSESSMENT -- Actual Model Evaluation (after Transfer-learning retraining)\n# batch <- validation_dataset %>% reticulate::as_iterator() %>% reticulate::iter_next()\n# predictions <- predict(mod1, batch[[1]])\n# images <- tibble(\n#   image = batch[[1]] %>% array_branch(1),\n#   predicted_mask = predictions[,,,1] %>% array_branch(1),\n#   mask = batch[[2]][,,,1]  %>% array_branch(1)\n# ) \n# i=16\n# pl1 <- plot_ly(z = ~ 255*as.matrix(as.data.frame(images$mask[i])[,1:256]), type=\"heatmap\", name=paste0(\"Tumor Mask \", i)) %>% \n#     layout(hovermode = \"y unified\", xaxis = list(hoverformat = '.1f'), yaxis = list(hoverformat = '.1f'))\n# pl2 <- plot_ly(z = ~ 255*as.matrix(as.data.frame(images$image[i])[,1:256]), type=\"heatmap\", name=paste0(\"Brain Image \", i)) %>% \n#     layout(hovermode = \"y unified\", xaxis = list(hoverformat = '.1f'), yaxis = list(hoverformat = '.1f'))\n# pl3 <- plot_ly(z = ~ 255*as.matrix(as.data.frame(images$predicted_mask[i])[,1:256]), type=\"heatmap\", name=paste0(\"Pred Mask \", i)) %>% \n#     layout(hovermode = \"y unified\", xaxis = list(hoverformat = '.1f'), yaxis = list(hoverformat = '.1f'))\n# subplot(pl1, pl2, pl3, nrows=1, shareY = TRUE) %>%\n#   layout(title=paste0(\"Case \", i))\n\n# batch <- validation_dataset %>% reticulate::as_iterator() %>% reticulate::iter_next()\n# predictions <- predict(mod1, batch)\n# str(predictions)  # num [1:32, 1:256, 1:256, 1] 0.466 0.463 0.48 0.449 0.494 ...\n# hist(predictions)\n#  \n# images <- tibble(\n#   image = batch[[1]] %>% array_branch(1),\n#   predicted_mask = predictions[,,,1] %>% array_branch(1),\n#   mask = batch[[2]][,,,1]  %>% array_branch(1)\n# )\n\n# Display the Transfer-Learning Model Performance across epochs\n# These metrics are precomputed on SOCR-Lighthouse server, as the transfer-learning fine-tuning training\n# takes days to go through 50 epochs and dozens of iterations per epoch \n## https://umich.instructure.com/courses/38100/files/folder/Case_Studies/36_TCGA_MRI_Segmentation_Data_Phenotypes\n## \n# epochs <- 48\n# # Import the metrics: Loss,\tDice,\tBinary_Accuracy,\tValidation_Loss,\tValidation_Dice,\tValidation_Binary_Accuracy\n# historyMetrics_epochs48 <- read.csv(\"https://umich.instructure.com/files/22559501/download?download_frd=1\", stringsAsFactors = F)\t\n# hist_df <- data.frame(epoch=historyMetrics_epochs48$Epoch, loss=historyMetrics_epochs48$Loss, \n#                       dice=historyMetrics_epochs48$Dice, binAccuracy=historyMetrics_epochs48$Binary_Accuracy,\n#                       valid_loss=historyMetrics_epochs48$Validation_Loss, valid_dice=historyMetrics_epochs48$Validation_Dice,\n#                       valid_binAccuracy=historyMetrics_epochs48$Validation_Binary_Accuracy)\n# \n# p_loss <- plot_ly(hist_df, x = ~epoch)  %>%\n#   add_trace(y = ~loss, name = 'Training Loss', type=\"scatter\", mode = 'lines+markers') %>%\n#   add_trace(y = ~valid_loss, name = 'Validation Loss', type=\"scatter\", mode = 'lines+markers') \n# p_acc <- plot_ly(hist_df, x = ~epoch)  %>%\n#   add_trace(y = ~dice, name = 'Training Dice', type=\"scatter\", mode = 'lines+markers') %>%       # DICE\n#   add_trace(y = ~valid_dice, name = 'Validation Accuracy', type=\"scatter\", mode = 'lines+markers') %>% \n#   add_trace(y = ~binAccuracy, name = 'Training Binary-Accuracy', type=\"scatter\", mode = 'lines+markers') %>%    # ACCURACY\n#   add_trace(y = ~valid_binAccuracy, name = 'Validation Binary-Accuracy', type=\"scatter\", mode = 'lines+markers')\n# subplot(p_loss, p_acc, nrows=2) %>%\n#   layout(legend = list(orientation = 'h'), title=\"Tensorflow Transfer-Learning Performance (Brain Imaging), Epochs=48\")\n\n# # MODEL FITTING on Lighthouse SOCR Compute Server\n# epochs = 100\n# history <- model %>% fit(training_dataset, epochs = epochs, validation_data = validation_dataset)\n# \n# # ASSESSMENT - Actual Model Evaluation (after Transfer-learning retraining)\n# # Naive Prediction\n# batch <- validation_dataset %>% reticulate::as_iterator() %>% reticulate::iter_next()\n# predictions <- predict(model, batch[[1]])\n# images <- tibble(\n#   image = batch[[1]] %>% array_branch(1),\n#   predicted_mask = predictions[,,,1] %>% array_branch(1),\n#   mask = batch[[2]][,,,1]  %>% array_branch(1)\n# ) \n# # i=22\n# # pl1 <- plot_ly(z = ~ 255*as.matrix(as.data.frame(images$mask[i])[,1:256]), type=\"heatmap\", name=paste0(\"Tumor Mask \", i))\n# # pl2 <- plot_ly(z = ~ 255*as.matrix(as.data.frame(images$image[i])[,1:256]), type=\"heatmap\", name=paste0(\"Brain Image \", i))\n# # pl3 <- plot_ly(z = ~ 255*as.matrix(as.data.frame(images$predicted_mask[i])[,1:256]), type=\"heatmap\", name=paste0(\"Pred Mask \", i))\n# # subplot(pl1, pl2, pl3, nrows=1)\n# \n# \n# # MODEL FITTING\n# # history <- model %>% fit(training_dataset, epochs = 1, validation_data = validation_dataset, verbose = 2)\n# \n# # 81/81 [==============================] - 3313s 41s/step - \n# # loss: 0.3121 - dice: 0.0106 - binary_accuracy: 0.9604 - val_loss: 0.1762 - val_dice: 1.7162e-04 - val_binary_accuracy: 0.9900\n# \n# # EVALUATION\n# # pl_loss <- plot_ly(x = ~c(1:history$params$epochs),  y = ~history$metrics$loss,\n# #                    type = \"scatter\", mode=\"markers+lines\", name=\"Loss\") %>% \n# #   add_trace(x = ~c(1:history$params$epochs),  y = ~history$metrics$val_loss,\n# #             type = \"scatter\", mode=\"markers+lines\", name=\"Validation Loss\") %>%\n# #   layout(title=\"DNN Training/Validation Performance\", xaxis=list(title=\"epoch\"),\n# #          yaxis=list(title=\"Metric Value\"), legend = list(orientation='h'))\n# # \n# # pl_acc <- plot_ly(x = ~c(1:history$params$epochs),  y = ~history$metrics$binary_accuracy,\n# #                   type = \"scatter\", mode=\"markers+lines\", name=\"Accuracy\") %>% \n# #   add_trace(x = ~c(1:history$params$epochs),  y = ~history$metrics$binary_accuracy,\n# #             type = \"scatter\", mode=\"markers+lines\", name=\"Validation Binary Accuracy\") %>%\n# #   layout(title=\"DNN Training/Validation Performance\", xaxis=list(title=\"epoch\"),\n# #          yaxis=list(title=\"Metric Value\"), legend = list(orientation='h'))\n# # \n# # subplot(pl_loss, pl_acc, nrows=2, shareX = TRUE, titleX = TRUE)\n# \n# # model %>% evaluate(training_dataset %>% dataset_batch(25), verbose = 0)\n# model %>% evaluate(validation_dataset, verbose = 0)\n# #           loss            dice    binary_accuracy \n# #   0.1762175262    0.0001716204        0.9899647236 \n# \n# # Save/Load the pretrained model in HDF5 format\n# save_model_hdf5(model, \"/home/dinov/DSPA/test_code/Chap22_DCNN_UNet_modeling/model_TF_Brain_epoch_100.h5\", \n#                 overwrite = TRUE, include_optimizer = TRUE)\n# # Save History object tracking model performance across epochs, \n# # see https://cran.r-project.org/web/packages/keras/vignettes/training_visualization.html\n# history_df <- as.data.frame(history)\n# # str(history_df)\n# # 'data.frame':   120 obs. of  4 variables:\n# #   $ epoch : int  1 2 3 4 5 6 7 8 9 10 ...\n# # $ value : num  0.87 0.941 0.954 0.962 0.965 ...\n# # $ metric: Factor w/ 2 levels \"acc\",\"loss\": 1 1 1 1 1 1 1 1 1 1 ...\n# # $ data  : Factor w/ 2 levels \"training\",\"validation\": 1 1 1 1 1 1 1 1 1 1 ...\n# save(history_df, file=\"/home/dinov/DSPA/test_code/Chap22_DCNN_UNet_modeling/historyModel_TF_Brain_Epochs50.Rda\")\n# # Then load it with:\n# #\n\n# REPORT Training and Validation Performance: load the performance metrics (history_df) over 100 epochs\n# https://umich.instructure.com/courses/38100/files/folder/Case_Studies/36_TCGA_MRI_Segmentation_Data_Phenotypes | historyModel_TF_Brain_Epochs100.Rda\nload(url(\"https://umich.instructure.com/files/22647027/download?download_frd=1\"))\nlineWidth <- ifelse(history_df$data=='training', 1, 4)\nlineNames <- paste0(history_df$data, \" \", history_df$metric)\nplot_ly(history_df, x = ~epoch, y=~value, color=~metric, type=\"scatter\", mode=\"lines+markers\", name=~lineNames,\n        line = list(color = ~metric, width = lineWidth))  %>%\n  layout(legend = list(orientation = 'h'), title=\"Tensorflow Transfer-Learning Performance (Brain Imaging), Epochs=100\")\n\n# PREDICTION\n# Mind that loading a model with custom layers/functions, e.g., dice() method, requires special import using a list\n# https://github.com/rstudio/keras/issues/1240\n# Once we have trained (`history <- model %>% fit(()`) and saved (`save_model_hdf5()`) the model (`model`), we can load it back as `mod1`  the interactive session and use it for prediction.\n# Define the Dice coefficient\ndice <- custom_metric(\"dice\", function(y_true, y_pred, smooth = 1.0) {\n  y_true_f <- k_flatten(y_true)\n  y_pred_f <- k_flatten(y_pred)\n  intersection <- k_sum(y_true_f * y_pred_f)\n  (2 * intersection + smooth) / (k_sum(y_true_f) + k_sum(y_pred_f) + smooth)\n})\n\n# The pre-computed model_TF_Brain_epoch_100.h5 model file is available in Canvas:\n# https://umich.instructure.com/courses/38100/files/folder/Case_Studies/36_TCGA_MRI_Segmentation_Data_Phenotypes\n# localModelsFolder <- \"C:/Users/IvoD/Desktop/Ivo.dir/Research/UMichigan/Proposals/2014/UMich_MINDS_DataSciInitiative_2014/2016/MIDAS_HSXXX_DataScienceAnalyticsCourse_Porposal/MOOC_Implementation/appendix/\"\n\nlocalModelsFolder <- getwd()\n\nmod1 <- load_model_hdf5(paste0(localModelsFolder, \"/appendix/model_TF_Brain_epoch_100.h5\"), compile = FALSE)\n                        #  custom_objects = list(\"dice\" = dice), compile = TRUE)\n\n# # Recompile the model with our  custom dice() loss function\nmod1 %>% compile(\n  optimizer = optimizer_rmsprop(learning_rate = 1e-5),\n  loss = \"binary_crossentropy\",\n  metrics = list(dice, metric_binary_accuracy)\n)\n# Check re-loaded mod1 model and evaluate performance metrics on validation dataset\n# summary(mod1)\nmod1 %>% evaluate(validation_dataset)\n# 16/16 [==============================] - 180s 11s/step - loss: 0.0213 - dice: 0.6842 - binary_accuracy: 0.9932\n#           loss            dice binary_accuracy \n#     0.02131428      0.68422282      0.99317247 \n\n# Finally display some of the results -- ASSESSMENT -- Actual Model Evaluation (after Transfer-learning retraining)\nbatch <- validation_dataset %>% reticulate::as_iterator() %>% reticulate::iter_next()\npredictions <- predict(mod1, batch[[1]])\nimages <- tibble(\n  image = batch[[1]] %>% array_branch(1),\n  predicted_mask = predictions[,,,1] %>% array_branch(1),\n  mask = batch[[2]][,,,1]  %>% array_branch(1)\n) \n# i=16\n# pl1 <- plot_ly(z = ~ 255*as.matrix(as.data.frame(images$mask[i])[,1:256]), type=\"heatmap\", name=paste0(\"Tumor Mask \", i)) %>% \n#   layout(hovermode = \"y unified\", xaxis = list(hoverformat = '.1f'), yaxis = list(hoverformat = '.1f'))\n# pl2 <- plot_ly(z = ~ 255*as.matrix(as.data.frame(images$image[i])[,1:256]), type=\"heatmap\", name=paste0(\"Brain Image \", i)) %>%\n#   layout(hovermode = \"y unified\", xaxis = list(hoverformat = '.1f'), yaxis = list(hoverformat = '.1f'))\n# pl3 <- plot_ly(z = ~ 255*as.matrix(as.data.frame(images$predicted_mask[i])[,1:256]), type=\"heatmap\", name=paste0(\"Pred Mask \", i)) %>%\n#   layout(hovermode = \"y unified\", xaxis = list(hoverformat = '.1f'), yaxis = list(hoverformat = '.1f'))\n# subplot(pl1, pl2, pl3, nrows=1, shareY = TRUE) %>%\n#   layout(title=paste0(\"DCNN HDF5 Model (epochs=100) Validation on Case \", i))\n\npl_list <- list()\nn = 10\nfor (i in 1:n) {    # to limit to only 1-channel, restrict the column range to 1:256: images$mask[i])[,1:256]\n  pl1 <- plot_ly(z = ~ 255*as.matrix(as.data.frame(images$mask[i])), type=\"heatmap\", name=paste0(\"Tumor Mask \", i)) %>% \n  layout(hovermode = \"y unified\", xaxis = list(hoverformat = '.1f'), yaxis = list(hoverformat = '.1f'))\npl2 <- plot_ly(z = ~ 255*as.matrix(as.data.frame(images$image[i])), type=\"heatmap\", name=paste0(\"Brain Image \", i)) %>%\n  layout(hovermode = \"y unified\", xaxis = list(hoverformat = '.1f'), yaxis = list(hoverformat = '.1f'))\npl3 <- plot_ly(z = ~ 255*as.matrix(as.data.frame(images$predicted_mask[i])), type=\"heatmap\", name=paste0(\"Pred Mask \", i)) %>%\n  layout(hovermode = \"y unified\", xaxis = list(hoverformat = '.1f'), yaxis = list(hoverformat = '.1f'))\npl4 <- plot_ly(z = ~ 255*as.matrix(as.data.frame(images$mask[i+n])), type=\"heatmap\", name=paste0(\"Tumor Mask \", i+n)) %>% \n  layout(hovermode = \"y unified\", xaxis = list(hoverformat = '.1f'), yaxis = list(hoverformat = '.1f'))\npl5 <- plot_ly(z = ~ 255*as.matrix(as.data.frame(images$image[i+n])), type=\"heatmap\", name=paste0(\"Brain Image \", i+n)) %>%\n  layout(hovermode = \"y unified\", xaxis = list(hoverformat = '.1f'), yaxis = list(hoverformat = '.1f'))\npl6 <- plot_ly(z = ~ 255*as.matrix(as.data.frame(images$predicted_mask[i+n])), type=\"heatmap\", name=paste0(\"Pred Mask \", i+n)) %>%\n  layout(hovermode = \"y unified\", xaxis = list(hoverformat = '.1f'), yaxis = list(hoverformat = '.1f'))\npl_list[[i]] <- subplot(pl1, pl2, pl3, pl4, pl5, pl6, nrows=1, shareY = TRUE) %>%\n  layout(title=paste0(\"DCNN HDF5 Model (epochs=100) Validation on Case \", i)) %>% hide_colorbar()\n}\npl_list %>%\n  subplot(nrows = length(pl_list)) %>%\n     layout(title=paste0(\"DCNN HDF5 Model (epochs=100) Predictions (N=\", 2*n, \" Cases)\"))\n\n\n# batch <- validation_dataset %>% reticulate::as_iterator() %>% reticulate::iter_next()\n# predictions <- predict(mod1, batch)\n# str(predictions)  # num [1:32, 1:256, 1:256, 1] 0.466 0.463 0.48 0.449 0.494 ...\n# hist(predictions)\n#  \n# images <- tibble(\n#   image = batch[[1]] %>% array_branch(1),\n#   predicted_mask = predictions[,,,1] %>% array_branch(1),\n#   mask = batch[[2]][,,,1]  %>% array_branch(1)\n# )\n\n# Save Predictions on validation data\n# batch <- validation_dataset %>% reticulate::as_iterator() %>% reticulate::iter_next()\n# predictions <- predict(mod1, batch[[1]])\nPredictedMasks <- list(predictions=predictions, images=images)\nsave(PredictedMasks, file=\"C:/Users/IvoD/Desktop/predictionsModel_TF_Brain_Epochs100.Rda\")\n# Then load it with:\n# load(\"C:/Users/Dinov/Desktop/predictionsModel_TF_Brain_Epochs100.Rda\")\n# https://umich.instructure.com/courses/38100/files/folder/Case_Studies/36_TCGA_MRI_Segmentation_Data_Phenotypes\n# load(url(\"https://umich.instructure.com/files/22648924/download?download_frd=1\"))",
      "line_count": 262
    },
    {
      "section": "Transfer Learning",
      "code": "# This HDF5 model (model_TF_Brain_epoch_100.h5) is available on Canvas: \n# https://umich.instructure.com/courses/38100/files/folder/Case_Studies/36_TCGA_MRI_Segmentation_Data_Phenotypes\n# https://umich.instructure.com/files/22647026/download?download_frd=1\nmod2 <- load_model_hdf5(paste0(localModelsFolder, \"/appendix/model_TF_Brain_epoch_100.h5\"), compile=FALSE)\n          # custom_objects = list(\"dice\" = dice), compile = TRUE)\n\n#  mod2 <- load_model_hdf5(\"E:/Ivo.dir/Research/UMichigan/Proposals/2014/UMich_MINDS_DataSciInitiative_2014/2016/MIDAS_HSXXX_DataScienceAnalyticsCourse_Porposal/MOOC_Implementation/appendix/model_TF_Brain_epoch_100.h5\", custom_objects = list(\"dice\" = dice), compile = TRUE)\n\n# Freeze the first 32 layers and inspect the number of trainable and non-trainable (frozen DCNN parameters)\nfor (layer in mod2$layers) layer$trainable <- FALSE\n\n# summary(mod2); length(mod2$layers)\n# Update the model's last layer: https://tensorflow.rstudio.com/guide/keras/faq/ \n# More about Keras layers: https://keras.rstudio.com/reference/index.html#section-core-layers \n# mod2 <- mod1 %>% \n#   # get_layer(index=33) %>%\n#   pop_layer() %>%  # remove the output layer first, then plug in a new output layer\n#   # layer_conv_2d(filters = 64, kernel_size = c(3, 3), padding = \"same\") \n#   layer_conv_2d(filters = 64, kernel_size = c(3,3), activation = \"relu\")\ninput <- mod2$input                            # Pretrained UNet input layer\nbase <- (mod2 %>% get_layer(index=32))$output  # Get the prior-to-last output layer of \"mod2\", total #layers =33\ntarget <- base %>%                             # Replace the output layer by a new conv2D layer outputting a 3-channel 2D brain image, not a mask\n  layer_conv_2d(filters = 64, kernel_size = c(1,1), activation = \"relu\") %>% \n  layer_max_pooling_2d(pool_size = c(2,2)) %>% \n  layer_conv_2d(filters = 64, kernel_size = c(1,1), activation = \"relu\") %>% \n  layer_max_pooling_2d(pool_size = c(2,2)) %>% \n  layer_conv_2d_transpose(filters = 32, kernel_size = c(2,2), strides = 2, padding = \"same\", activation = \"relu\") %>%  # deconvolution layers\n  layer_conv_2d_transpose(filters = 3, kernel_size = c(2,2), strides = 2, padding = \"same\", activation = \"relu\")\nmodTransferLearning <- keras_model(input, target)   # Update mod2 for transfer learning \nsummary(modTransferLearning); length(modTransferLearning$layers) \n\n# 31M parameters are fixed and we are only estimating 16K parameters in the Transfer-Learning tuning.\n\n# Inspect the number of trainable and non-trainable (frozen DCNN parameters)\n# ....\n# ...\n# conv2d_17 (Conv2D)    (None, 256, 256, 64)              36928              conv2d_16[0][0]   # Last Layers of base model mod2   \n# ___________________________________________________________________________________________\n# conv2d_44 (Conv2D)    (None, 256, 256, 64)              4160               conv2d_17[0][0]   # First new TF layer                                 \n# ___________________________________________________________________________________________\n# max_pooling2d_25 (MaxPooling2D)   (None, 128, 128, 64)    0                 conv2d_44[0][0]                                    \n# ___________________________________________________________________________________________\n# conv2d_43 (Conv2D)    (None, 128, 128, 64)              4160         max_pooling2d_25[0][0]                             \n# ___________________________________________________________________________________________\n# max_pooling2d_24 (MaxPooling2D)  (None, 64, 64, 64)       0                  conv2d_43[0][0]                                    \n# ___________________________________________________________________________________________\n# conv2d_transpose_17 (Conv2DTranspose)  (None, 128, 128, 32) 8224      max_pooling2d_24[0][0]                             \n# ____________________________________________________________________________________________\n# conv2d_transpose_16 (Conv2DTranspose)  (None, 256, 256, 3)  387    v2d_transpose_17[0][0]   # New Last Output Layer of TL model  modTransferLearning                      \n# ============================================================================================\n# Total params: 31,048,611\n# Trainable params: 16,931\n# Non-trainable params: 31,031,680\n# ________________________________\n# [1] 38 # Layers of new modTransferLearning model\n\n\n## MODEL RE-TRAINING (for Transfer Learning)\n# Compile the DCNN model, packaging an optimizer, loss and performance metrics\nmodTransferLearning %>% compile(\n  optimizer = optimizer_rmsprop(learning_rate = 1e-5),\n  # loss = 'loss_kullback_leibler_divergence', \n  loss = 'mse',   # as we are looking at minimizing ||OrigImage - SynthImage||, i.e., the RMSE\n  metrics = list(metric_mean_absolute_error, metric_poisson)\n)\n\ncurrentRotationIndex <- 1 # reset\n\n### PREP New Data (replace masks by the native brain images)\ncreate_TL_dataset <- function(data, train, batch_size = 32L) {\n  dataset <- data %>%   # load all PNG files as images\n    tensor_slices_dataset() %>% \n    dataset_map(~.x %>% list_modify(\n      img = tf$image$decode_png(tf$io$read_file(.x$img), channels = 3),  # <------ IMG\n      mask= tf$image$decode_png(tf$io$read_file(.x$img), channels = 3)   # <------ MASK == IMG\n    )) %>%     # convert image intensities from int8 to 32-bit float\n    dataset_map(~.x %>% list_modify(\n      img = tf$image$convert_image_dtype(.x$img, dtype = tf$float32),\n      mask= tf$image$convert_image_dtype(.x$mask, dtype = tf$float32)\n    )) %>%     # reshape all tensor-shape to (256 * 256) to ensure spatial-index homologies\n    dataset_map(~.x %>% list_modify(\n      img = tf$image$resize(.x$img, size = shape(256, 256)),\n      mask= tf$image$resize(.x$mask, size = shape(256, 256))\n    ))\n  \n  # data augmentation performed on training set only\n  if (train) {\n    dataset <- dataset %>% \n      dataset_map(~.x %>% list_modify(\n        img  = random_bsh(.x$img) # ,\n        # mask = img\n      )) %>%\n      dataset_map(~.x %>% list_modify(  # see discussion in create_dataset()\n        img = random_rotate(img=.x$img, mask=.x$mask)$img,\n        mask= random_rotate(img=.x$img, mask=.x$mask)$mask\n      ))\n  }\n  \n  # shuffling on training set only\n  if (train) {\n    dataset <- dataset %>% \n      dataset_shuffle(buffer_size = batch_size*4)\n  }\n  \n  # train in batches; batch size might need to be adapted depending on\n  # available memory\n  dataset <- dataset %>% \n    dataset_batch(batch_size)\n  \n  dataset %>% \n    # output needs to be unnamed\n    dataset_map(unname) \n}\n\n# Generate the Transfer Learning (TL) Training and Testing data at iterated TF-Data objects\ntraining_TL_dataset <- create_TL_dataset(training(data_train_valid), train = TRUE)\nvalidation_TL_dataset <- create_TL_dataset(testing(data_train_valid), train = FALSE)\n# tf$data$experimental$cardinality(training_TL_dataset)$numpy()\n\n# testing_TL_dataset <- testing(data_train_valid) %>%  \n#   tensor_slices_dataset() %>% \n#   dataset_map(~.x %>% list_modify(\n#     # decode_jpeg yields a 3d tensor of shape (256, 256, 3)\n#     # Check tensor shapes!\n#     img = tf$image$decode_png(tf$io$read_file(.x$img), channels = 3),\n#     mask =tf$image$decode_png(tf$io$read_file(.x$img), channels = 3)\n#   )) \n\nexample_TL <- training_TL_dataset %>% reticulate::as_iterator() %>% reticulate::iter_next()\n# example_TL\n\nrasterPlotly <- function (image, name=\"\", hovermode = NULL) {\n  myPlot <- plot_ly(type=\"image\", z=image, name=name, hoverlabel=name, text=name, \n            hovertext=name, hoverinfo=\"name+x+y\") %>% \n    layout(hovermode = hovermode, xaxis = list(hoverformat = '.1f'), yaxis = list(hoverformat = '.1f'))\n  return(myPlot)\n}\n\n# Training Case\nimg_and_mask <- training_TL_dataset %>% \n      reticulate::as_iterator() %>% reticulate::iter_next()  # shape=(batch=32, 256, 256, channel=3)\nimg <- img_and_mask[[1]][1,,,1]  %>% as.array()  # 3-channel Input image\ntarget<- img_and_mask[[2]][1,,,1]  %>% as.array()  # 3-channel Output image\np1 <- plot_ly(z=~255*img, type=\"heatmap\", name = \"Input Image\") %>% hide_colorbar()\np2 <- plot_ly(z=~255*target, type=\"heatmap\", name = \"Output Image\") %>% hide_colorbar()\nsubplot(p1,p2, shareY = TRUE) %>% layout(title=\"Training Case: 3-Channel Input Image (Left) & Output Image (Right)\")\n\n\n# MODEL FITTING - uncomment this fragment to run 6-epochs (2+ hrs)\n# modTransferLearning_History_6Epochs <- modTransferLearning %>% fit(training_TL_dataset, epochs = 6, validation_data = validation_TL_dataset, verbose = 2)\n# 63/63 - 1009s - loss: 1.2179 - mean_absolute_error: 0.4255 - poisson: 1.1990 - kullback_leibler_divergence: 2.0313 - val_loss: 0.4258 - val_mean_absolute_error: 0.3001 - val_poisson: 1.0742 - val_kullback_leibler_divergence: 2.0180\n# Save model HDF5\n# save_model_hdf5(modTransferLearning, \"C:/Users/Dinov/Desktop/model_TF_TL_SynthBrainImages_epoch_6.h5\", \n#                 overwrite = TRUE, include_optimizer = TRUE)\n# Model is on Canvas: https://umich.instructure.com/courses/38100/files/folder/Case_Studies/36_TCGA_MRI_Segmentation_Data_Phenotypes\n# mod3_TL <- \n#  load_model_hdf5(\"E:/Ivo.dir/Research/UMichigan/Proposals/2014/UMich_MINDS_DataSciInitiative_2014/2016/MIDAS_HSXXX_DataScienceAnalyticsCourse_Porposal/MOOC_Implementation/appendix/model_TF_TL_SynthBrainImages_epoch_6.h5\", compile = FALSE)",
      "line_count": 157
    },
    {
      "section": "Transfer Learning",
      "code": "# mod3_TL <- modTransferLearning\n# mod3_TL <- load_model_hdf5(\"E:/Ivo.dir/Research/UMichigan/Proposals/2014/UMich_MINDS_DataSciInitiative_2014/2016/MIDAS_HSXXX_DataScienceAnalyticsCourse_Porposal/MOOC_Implementation/appendix/model_TF_TL_SynthBrainImages_epoch_6.h5\", compile = F)\n# Load the h5 model from Canvas: https://umich.instructure.com/courses/38100/files/folder/Case_Studies/36_TCGA_MRI_Segmentation_Data_Phenotypes\nmod3_TL <- load_model_hdf5(paste0(localModelsFolder,\n                  \"/appendix/model_TF_TL_SynthBrainImages_epoch_6.h5\"), compile = FALSE)\n\n# Recompile the model with our  custom dice() loss function\nmod3_TL %>% compile(\n  optimizer = optimizer_rmsprop(learning_rate = 1e-5),\n  # loss = 'loss_kullback_leibler_divergence', \n  loss = 'mse',   # as we are looking at minimizing ||OrigImage - SynthImage||, i.e., the RMSE\n  metrics = list(metric_mean_absolute_error, metric_poisson)\n)\n\n# Load the performance metrics of pre-computed 6-epoch model(modTransferLearning_History_6Epochs_DF.csv)\nmodTransferLearning_History_6Epochs_DF <- read.csv(\"https://umich.instructure.com/files/22825191/download?download_frd=1\", header = T)\n# modTransferLearning_History_6Epoc_DF <- as.data.frame(modTransferLearning_History_6Epochs$metrics)\n# \n# modTransferLearning_History_6Epochs_DF <- data.frame(\n#   epoch = c(1:dim(modTransferLearning_History_6Epoc_DF)[1]),\n#   loss = modTransferLearning_History_6Epoc_DF$loss,\n#   mean_absolute_error=modTransferLearning_History_6Epoc_DF$mean_absolute_error,\n#   poisson=modTransferLearning_History_6Epoc_DF$poisson,\n#   val_loss = modTransferLearning_History_6Epoc_DF$val_loss,\n#   val_mean_absolute_error = modTransferLearning_History_6Epoc_DF$val_mean_absolute_error,\n#   val_poisson = modTransferLearning_History_6Epoc_DF$val_poisson)\n\nhead(modTransferLearning_History_6Epochs_DF)\n# write.csv(modTransferLearning_History_6Epochs_DF, \"C:/Users/Dinov/Desktop/modTransferLearning_History_6Epochs_DF.csv\")\n# modTransferLearning_History_6Epochs_DF <- read.csv(\"https://umich.instructure.com/files/22825191/download?download_frd=1\", header = T)\n# modTransferLearning_History_4Epochs_DF <- read.csv(\"https://umich.instructure.com/files/22704304/download?download_frd=1\", header = T)\n\n# EVALUATION\nplot_ly(data=modTransferLearning_History_6Epochs_DF, x = ~epoch,  \n                   y = ~loss, type = \"scatter\", mode=\"markers+lines\", name=\"Loss\") %>% \n  add_trace(x = ~epoch, y = ~mean_absolute_error, type = \"scatter\", mode=\"markers+lines\", name=\"Mean Abs Error\") %>%\n  add_trace(x = ~epoch, y = ~poisson, type = \"scatter\", mode=\"markers+lines\", name=\"Poisson\") %>% \n  add_trace(x = ~epoch, y = ~val_loss, type = \"scatter\", mode=\"markers+lines\", name=\"Valid Loss\") %>%\n  add_trace(x = ~epoch, y = ~val_mean_absolute_error, type = \"scatter\", mode=\"markers+lines\", name=\"Valid MAE\") %>%\n  add_trace(x = ~epoch, y = ~val_poisson, type = \"scatter\", mode=\"markers+lines\", name=\"Valid Poisson\") %>% \n  layout(title=\"Transfer-Learning Validation Synth Image Generation Performance\", xaxis=list(title=\"epoch\"),\n         yaxis=list(title=\"Metric Value\"), legend = list(orientation='h'))\n\n# mod3_TL %>% evaluate(training_TL_dataset %>% dataset_batch(25), verbose = 0)\nmod3_TL %>% evaluate(validation_TL_dataset, verbose = 0)\n#  Epoch4 loss         mean_absolute_error   poisson      kullback_leibler_divergence\n#         0.1845085    0.2612749             0.8180779    1.2870733  \n# Epoch6       loss       mean_absolute_error             poisson \n#              0.02177707          0.08500605          1.05714786 \n                  \n# TL Model Prediction using the default (prior to Transfer Learning) model\nbatch <- validation_TL_dataset %>% reticulate::as_iterator() %>% reticulate::iter_next()\npredictions <- predict(mod3_TL, batch[[1]])\nimages <- tibble(\n  image     = batch[[1]][,,,1]  %>% array_branch(1),\n  synth_img = predictions[,,,1] %>% array_branch(1),\n  target    = batch[[2]][,,,1]  %>% array_branch(1)\n) \n\n# Check performance of the Transfer-Learning model on one case (# 22)\ni=22\npl1 <- plot_ly(z = ~ 255*as.matrix(as.data.frame(images$image[i])[,1:256]), type=\"heatmap\", name=paste0(\"Input Image \", i))\npl2 <- plot_ly(z = ~ 255*as.matrix(as.data.frame(images$target[i])[,1:256]), type=\"heatmap\", name=paste0(\"Target \", i))\npl3 <- plot_ly(z = ~ 255*as.matrix(as.data.frame(images$synth_img[i])[,1:256]), type=\"heatmap\", name=paste0(\"Synth Image \", i))\nsubplot(pl1, pl2, pl3, nrows=1) %>% hide_colorbar()\n\npl_list <- list()\nfor (i in 1:10) {\n  image = as.matrix(as.data.frame(images$image[i])[,1:256])\n  synth_img = as.matrix(as.data.frame(images$synth_img[i])[,1:256])\n  target = as.matrix(as.data.frame(images$target[i])[,1:256])\n  \n  p1 <- plot_ly(z=~255*image, type=\"heatmap\", name=paste0(\"Image \", i))\n  p2 <- plot_ly(z=~255*target, type=\"heatmap\", name=paste0(\"Target=Image \", i))\n  p3 <- plot_ly(z=~255*synth_img, type=\"heatmap\", name=paste0(\"Synth Img \", i))\n  pl_list[[i]] <- subplot(p1,p2, p3, nrows=1) %>% hide_colorbar() # %>% \n    # layout(yaxis=list(scaleanchor = \"x\",  scaleratio = 1),  hovermode = \"y unified\")\n    # layout(hovermode = \"y unified\")\n}\npl_list %>%\n  subplot(nrows = length(pl_list)) %>%\n     layout(title=\"Input Brain Images, Targets, and Synth Reconstructions for N=10 Cases\")",
      "line_count": 82
    },
    {
      "section": "Transfer Learning",
      "code": "# library(reticulate)\n# example <- training_dataset %>% reticulate::as_iterator() %>% reticulate::iter_next()\n# ex_img <- example$img %>% as.array()  #  %>% as.raster()\n# plot_ly(type=\"image\", z=255*ex_img)       #  255*EBImage::Image(t(ex_img)))\n\n# display one brain image\nbatch <- training_dataset %>% reticulate::as_iterator()\n\npl_list <- list()\nfor (i in 1:10) {\n  record <- reticulate::iter_next(batch)\n  image = record[[1]] %>% as.array()\n  mask = record[[2]] %>% as.array()\n  p1 <- plot_ly(z=~image[i,,,3], type=\"heatmap\", name=paste0(\"Image \", i))\n  p2 <- plot_ly(z=~mask[i,,,1], type=\"heatmap\", name=paste0(\"Mask \", i))\n  pl_list[[i]] <- subplot(p1,p2, nrows=1) %>% hide_colorbar() # %>% \n    # layout(yaxis=list(scaleanchor = \"x\",  scaleratio = 1),  hovermode = \"y unified\")\n    # layout(hovermode = \"y unified\")\n}\npl_list %>%\n  subplot(nrows = length(pl_list)) %>%\n     layout(title=\"Brain Images and Masks for N=10 Cases\")",
      "line_count": 22
    },
    {
      "section": "Transfer Learning",
      "code": "sobelX = matrix(c(1,2,1, 0,0,0, -1,-2,-1), nrow = 3, ncol = 3); sobelX\nsobelY=t(sobelX); sobelY\n\nlibrary(jpeg)\t\nlibrary(magick)\n\nimg_url <- \"https://umich.instructure.com/files/1627149/download?download_frd=1\"\t\t\nf <- image_read(img_url)\t\nplot(f)\n# To apply the convolution process manually, we use a convolve() function of the 'magick' package.\n\nimgX <- image_convolve(f, sobelX)\nimgY <- image_convolve(f, sobelY)\n# plot(imgX, imgY)\n\n# Rotate 90 degrees\nF <- imager::mirror(imager::imrotate(imager::magick2cimg(f), 90), \"x\")\nImgX <- imager::mirror(imager::imrotate(imager::magick2cimg(imgX), 90), \"x\")\nImgY <- imager::mirror(imager::imrotate(imager::magick2cimg(imgY), 90), \"x\")\np1 <- plot_ly(z=~255*(ImgX)[,,1,], type=\"image\", name=\"(f*SobelX)\")\np2 <- plot_ly(z=~255*(F)[,,1,], type=\"image\", name=\"f\")\np3 <- plot_ly(z=~255*(ImgY)[,,1,], type=\"image\", name=\"(f*SobelY)\")\nsubplot(p1, p2, p3, nrows=1) %>% \n  layout(title=\"Image convolution with Sobel Kernel Filters (Left=f*SobelX, Middle=f, Right=f*SobelY)\")",
      "line_count": 24
    }
  ]
}